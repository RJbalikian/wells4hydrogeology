{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{Fill in with information about this notebook}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np #Data manipulation\n",
    "import pandas as pd #Point data manipulation and organization\n",
    "import xarray as xr #Raster data manipulation and organization\n",
    "\n",
    "import pathlib  #For filepaths, io, etc.\n",
    "import os       #For several system-based commands\n",
    "import datetime #For manipulation of time data, including file creation/modification times\n",
    "import json     #For dictionary io, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt #For plotting and data vizualization\n",
    "import geopandas as gpd         #For organization and manipulation of vector data in space (study area and some data points)\n",
    "import rioxarray as rxr         #For orgnaization and manipulation of raster data\n",
    "from scipy import interpolate\n",
    "import shapely                  #For converting coordinates to point geometry\n",
    "#Not sure if this cell is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scripts with functions made for this specific application\n",
    "import w4h\n",
    "import pathlib\n",
    "import os\n",
    "#Variables needed throughout, best to just assign now\n",
    "todayDate, dateSuffix = w4h.getCurrentDate() \n",
    "repoDir = pathlib.Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "Most Recent version of this file is : ISGS_HEADER_2023-01-06.txt\n",
      "Most Recent version of this file is : xyzData.csv\n",
      "Using the following files:\n",
      "\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_HEADER_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\xyzData.csv\n",
      "Downhole Data has 3054409 valid well records.\n",
      "Header Data has 636855 unique wells with valid location information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:145: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:,i] = dfIN.iloc[:,i].astype(dtypes[dfIN.iloc[:,i].name])\n",
      "c:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\geopandas\\array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2998078 records removed without location information.\n",
      "56331 wells remain from 7188 located wells in study area.\n",
      "Well records removed: 0\n",
      "Number of rows before dropping those without surface elevation information: 8150\n",
      "Number of rows after dropping those without surface elevation information: 8150\n",
      "Number of rows before dropping those without record depth information: 56331\n",
      "Number of rows after dropping those without record depth information: 55747\n",
      "Number of well records without formation information deleted: 584\n",
      "Number of rows before dropping those with obviously bad depth information: 56331\n",
      "Number of rows after dropping those with obviously bad depth information: 55725\n",
      "Well records deleted: 606\n",
      "Number of rows before dropping those without FORMATION information: 56331\n",
      "Number of rows after dropping those without FORMATION information: 56331\n",
      "Well records deleted: 0\n",
      "Most Recent version of this file is : SearchTerms-Specific_2022-11-16_essCols.csv\n",
      "Most Recent version of this file is : SearchTerms-Start.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:210: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  d.iloc[:,i] = d.iloc[:,i].astype(dict_termDtypes[d.iloc[:,i].name])\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:210: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  d.iloc[:,i] = d.iloc[:,i].astype(dict_termDtypes[d.iloc[:,i].name])\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:210: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  d.iloc[:,i] = d.iloc[:,i].astype(dict_termDtypes[d.iloc[:,i].name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                clay brown\n",
      "1                     clay dark brown, wood\n",
      "2                     clay gray sandy, soft\n",
      "3                         clay gray, sticky\n",
      "4                 sandrock gray hard, dirty\n",
      "                        ...                \n",
      "56326               brown silt (levee fill)\n",
      "56327                             gray clay\n",
      "56328    gray clay (with thin sand streaks)\n",
      "56329                       gray, fine sand\n",
      "56330         gray, mottled with brown clay\n",
      "Name: FORMATION, Length: 56331, dtype: object\n",
      "0                                clay brown\n",
      "1                     clay dark brown, wood\n",
      "2                     clay gray sandy, soft\n",
      "3                         clay gray, sticky\n",
      "4                 sandrock gray hard, dirty\n",
      "                        ...                \n",
      "56326               brown silt (levee fill)\n",
      "56327                             gray clay\n",
      "56328    gray clay (with thin sand streaks)\n",
      "56329                       gray, fine sand\n",
      "56330         gray, mottled with brown clay\n",
      "Name: FORMATION, Length: 56331, dtype: object\n",
      "0                                clay brown\n",
      "1                     clay dark brown, wood\n",
      "2                     clay gray sandy, soft\n",
      "3                         clay gray, sticky\n",
      "4                 sandrock gray hard, dirty\n",
      "                        ...                \n",
      "56326               brown silt (levee fill)\n",
      "56327                             gray clay\n",
      "56328    gray clay (with thin sand streaks)\n",
      "56329                       gray, fine sand\n",
      "56330         gray, mottled with brown clay\n",
      "Name: FORMATION, Length: 56331, dtype: object\n",
      "Records Classified with full search term: 31582\n",
      "Records Classified with full search term: 56.07% of data\n",
      "Start Term process should be done by 17:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].where(~df['FORMATION'].str.startswith(s,na=False),4,inplace=True)\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['INTERPRETATION'].where(~df['FORMATION'].str.startswith(s,na=False),starterms.loc[i,'INTERPRETATION'],inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records classified with start search term: 3586\n",
      "Records classified with start search term: 14.49% of remaining data\n",
      "Records classified as bedrock that were deeper than 550': 359\n",
      "This represents 1.7% of the unclassified data in this dataframe.\n",
      "Number of unique wells in downholeData: 7188\n",
      "BEDROCK_ELEV_FT sampling should be done by 17:39\n",
      "SURFACE_ELEV_FT sampling should be done by 17:39\n",
      "BEDROCK_DEPTH_FT sampling should be done by 17:39\n",
      "LAYER_THICK_FT sampling should be done by 17:39\n",
      "API_NUMBER\n",
      "LATITUDE\n",
      "REMOVING LATITUDE\n",
      "LONGITUDE\n",
      "REMOVING LONGITUDE\n",
      "BEDROCK_ELEV_FT\n",
      "SURFACE_ELEV_FT\n",
      "BEDROCK_DEPTH_FT\n",
      "LAYER_THICK_FT\n",
      "ELEV_FT\n",
      "REMOVING ELEV_FT\n",
      "LONGITUDE_PROJ\n",
      "LATITUDE_PROJ\n",
      "DEPTH_FT_LAYER1\n",
      "DEPTH_FT_LAYER2\n",
      "DEPTH_FT_LAYER3\n",
      "DEPTH_FT_LAYER4\n",
      "DEPTH_FT_LAYER5\n",
      "DEPTH_FT_LAYER6\n",
      "DEPTH_FT_LAYER7\n",
      "DEPTH_FT_LAYER8\n",
      "DEPTH_FT_LAYER9\n",
      "ELEV_FT_LAYER1\n",
      "ELEV_FT_LAYER2\n",
      "ELEV_FT_LAYER3\n",
      "ELEV_FT_LAYER4\n",
      "ELEV_FT_LAYER5\n",
      "ELEV_FT_LAYER6\n",
      "ELEV_FT_LAYER7\n",
      "ELEV_FT_LAYER8\n",
      "ELEV_FT_LAYER9\n",
      "geometry\n",
      "REMOVING geometry\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
      "       'TOTAL_DEPTH', 'SECTION', 'TWP', 'TDIR', 'RNG', 'RDIR', 'MERIDIAN',\n",
      "       'QUARTERS', 'ELEVATION', 'ELEVREF', 'COUNTY_CODE', 'ELEVSOURCE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ELEV_FT', 'geometry', 'INTERPRETATION',\n",
      "       'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'BEDROCK_ELEV_FT',\n",
      "       'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT',\n",
      "       'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
      "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
      "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
      "       'DEPTH_FT_LAYER9', 'ELEV_FT_LAYER1', 'ELEV_FT_LAYER2', 'ELEV_FT_LAYER3',\n",
      "       'ELEV_FT_LAYER4', 'ELEV_FT_LAYER5', 'ELEV_FT_LAYER6', 'ELEV_FT_LAYER7',\n",
      "       'ELEV_FT_LAYER8', 'ELEV_FT_LAYER9', 'TOP_ELEV_FT', 'BOT_ELEV_FT',\n",
      "       'TARG_THICK_FT'],\n",
      "      dtype='object')\n",
      "Completed interpolation for Layer 1\n",
      "Completed interpolation for Layer 2\n",
      "Completed interpolation for Layer 3\n",
      "Completed interpolation for Layer 4\n",
      "Completed interpolation for Layer 5\n",
      "Completed interpolation for Layer 6\n",
      "Completed interpolation for Layer 7\n",
      "Completed interpolation for Layer 8\n",
      "Completed interpolation for Layer 9\n"
     ]
    }
   ],
   "source": [
    "directoryDir = r'\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\\\'[:-1]\n",
    "downholeDataPATH, headerDataPATH, xyzInPATH  = w4h.filesSetup(db_dir=directoryDir)\n",
    "headerDataIN, downholeDataIN = w4h.readRawTxtData(downholefile=downholeDataPATH, headerfile=headerDataPATH) #Functions to read data into dataframes. Also excludes extraneous columns, and drops header data with no location information\n",
    "xyzDataIN = w4h.readXYZData(xyzfile=xyzInPATH)\n",
    "downholeData = w4h.defineDataTypes(downholeDataIN, dtypeFile='downholeDataTypes.txt') #Define datatypes of each column of the new dataframes\n",
    "headerData = w4h.defineDataTypes(headerDataIN, dtypeFile='headerDataTypes.txt')#Define datatypes of each column of the new dataframes\n",
    "xyzData = w4h.defineDataTypes(xyzDataIN, dtypeFile='xyzDataTypes.txt')\n",
    "studyAreaPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESL_StudyArea_5mi.shp\"\n",
    "studyAreaIN = w4h.read_study_area(studyAreaPath)\n",
    "modelGridPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\grid_625_raster.tif\"\n",
    "surfaceElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ILStateLidar_ClipExtentESL.tif\"\n",
    "bedrockElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESLBedrock.tif\"\n",
    "modelGrid = w4h.read_grid(datapath=modelGridPath, grid_type='model', studyArea=studyAreaIN,  read_grid=True, clip2SA=True)#, gridcrs='EPSG:26715', studyAreacrs='EPSG:26715')\n",
    "surfaceElevGridIN = w4h.read_grid(datapath=surfaceElevPath, grid_type='surface', studyArea=studyAreaIN, use_service=False, clip2SA=True)\n",
    "bedrockElevGridIN = w4h.read_grid(datapath=bedrockElevPath, grid_type='bedrock', studyArea=studyAreaIN, use_service=False, clip2SA=True)\n",
    "#Code here for adding in control points\n",
    "headerData = w4h.addElevtoHeader(xyzData, headerData) #This probably needs to be updated\n",
    "headerData = w4h.coords2Geometry(df=headerData, xCol='LONGITUDE', yCol='LATITUDE', crs='EPSG:4269')\n",
    "headerData = w4h.clipHeader2StudyArea(studyarea=studyAreaIN, headerdata=headerData, headerCRS='EPSG:4269')\n",
    "downholeData = w4h.removeNonlocatedData(downholeData, headerData)\n",
    "headerData = w4h.removenotopo(df=headerData, printouts=True)\n",
    "donwholeData = w4h.dropnodepth(downholeData, printouts=True) #Drop records with no depth information\n",
    "donwholeData = w4h.dropbaddepth(downholeData, printouts=True)#Drop records with bad depth information (i.e., top depth > bottom depth) (Also calculates thickness of each record)\n",
    "downholeData = w4h.dropnoformation(downholeData, printouts=True)\n",
    "downholeData.reset_index(inplace=True,drop=True) #These may not be necessary\n",
    "headerData.reset_index(inplace=True,drop=True) #These may not be necessary\n",
    "downholeData = pd.merge(left = downholeData, right = headerData, on='API_NUMBER')\n",
    "specTermsPATH, startTermsPATH = w4h.searchTermFilePaths(dictdir=str(repoDir)+'/resources/', specStartPattern='*SearchTerms-Specific*', startGlobPattern = '*SearchTerms-Start*')\n",
    "specTerms = w4h.read_dictionary_terms(dict_file=specTermsPATH)\n",
    "startTerms = w4h.read_dictionary_terms(dict_file=startTermsPATH)\n",
    "oldDictPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\WellData\\Dictionaries\\DICTIONARY_Updated-06-2018.csv\"\n",
    "oldDict = w4h.read_dictionary_terms(dict_file=oldDictPath, cols={'DESCRIPTION':'FORMATION', 'LITHOLOGY':'INTERPRETATION'}, class_flag=1)\n",
    "specTerms = pd.concat([specTerms, oldDict])\n",
    "specTerms.drop_duplicates(subset='FORMATION', inplace=True)\n",
    "specTerms.reset_index(inplace=True, drop=True)\n",
    "downholeData = w4h.specificDefine(downholeData, specTerms, printouts=True)\n",
    "classifedDF, searchDF = w4h.splitDefined(downholeData)\n",
    "searchDF = w4h.startDefine(df=searchDF, starterms=startTerms, printouts=True)\n",
    "downholeData = w4h.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "classifedDF, searchDF = w4h.splitDefined(downholeData)\n",
    "searchDF = w4h.depthDefine(searchDF, thresh=550, printouts=True)\n",
    "downholeData = w4h.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = w4h.fillUnclassified(downholeData)\n",
    "#dictDir = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\WellDataAutoClassification\\\\SupportingDocs\\\\\"\n",
    "targetInterpDF = w4h.readLithologies()\n",
    "downholeData = w4h.mergeLithologies(downholedata=downholeData, targinterps=targetInterpDF)\n",
    "wellsDF = w4h.get_unique_wells(downholeData)\n",
    "downholeData = w4h.sort_dataframe(df=downholeData, sort_cols=['API_NUMBER','TOP'], remove_nans=True)\n",
    "inGrids = [bedrockElevGridIN, surfaceElevGridIN]\n",
    "bedrockGrid, surfaceGrid = w4h.alignRasters(unalignedGrids=inGrids, modelgrid=modelGrid)\n",
    "driftThickGrid, layerThickGrid = w4h.get_drift_thick(surface=surfaceGrid, bedrock=bedrockGrid, noLayers=9, plotData=False)\n",
    "headerData = w4h.sample_raster_points(raster=bedrockGrid, ptDF=headerData, newColName='BEDROCK_ELEV_FT')\n",
    "headerData = w4h.sample_raster_points(raster=surfaceGrid, ptDF=headerData, newColName='SURFACE_ELEV_FT')\n",
    "headerData = w4h.sample_raster_points(raster=driftThickGrid, ptDF=headerData, newColName='BEDROCK_DEPTH_FT')\n",
    "headerData = w4h.sample_raster_points(raster=layerThickGrid, ptDF=headerData, newColName='LAYER_THICK_FT')\n",
    "headerData = w4h.get_layer_depths(well_metadata=headerData, no_layers=9)\n",
    "downholeData_layerInfo = w4h.merge_tables(data_df=downholeData,  data_cols=None, header_cols=None, header_df=headerData,on='API_NUMBER', how='inner', auto_pick_cols=True)\n",
    "#downholeData = downholeData_layerInfo.copy()\n",
    "resdf = w4h.layer_target_thick(downholeData_layerInfo, layers=9, outfile_prefix='CoarseFine')\n",
    "layers_data = w4h.layer_interp(points=resdf, layers=9, grid=modelGrid, method='lin')\n",
    "out_dir = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\ProcessedData\"\n",
    "w4h.export_grids(layers_data, out_path=out_dir)\n",
    "#downholeData.to_csv(str(repoDir)+'/out/downholeData_cleaned'+dateSuffix+'.csv',index_label='ID')\n",
    "#headerData.to_csv(str(repoDir)+'/out/headerData_cleaned'+dateSuffix+'.csv',index_label='ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "1eab39f8790fa4ef06ab4ebada9c1405c2ef16219adfedb21e90bf3fb356ecb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
