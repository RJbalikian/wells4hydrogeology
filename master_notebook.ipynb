{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{Fill in with information about this notebook}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np #Data manipulation\n",
    "import pandas as pd #Point data manipulation and organization\n",
    "import xarray as xr #Raster data manipulation and organization\n",
    "\n",
    "import pathlib  #For filepaths, io, etc.\n",
    "import os       #For several system-based commands\n",
    "import datetime #For manipulation of time data, including file creation/modification times\n",
    "import json     #For dictionary io, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt #For plotting and data vizualization\n",
    "import geopandas as gpd         #For organization and manipulation of vector data in space (study area and some data points)\n",
    "import rioxarray as rxr         #For orgnaization and manipulation of raster data\n",
    "import shapely                  #For converting coordinates to point geometry\n",
    "\n",
    "#Scripts with functions made for this specific application\n",
    "from lib import readData    #For reading data \n",
    "from lib import mapping     #For geospatial data manipulation\n",
    "from lib import cleanData   #For cleaning well data\n",
    "from lib import classify    #For classifying well data\n",
    "from lib import exportData  #For exporting data\n",
    "\n",
    "#Variables needed throughout, best to just assign now\n",
    "todayDate, dateSuffix = readData.getCurrentDate() \n",
    "repoDir = pathlib.Path(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set up filepaths\n",
    "- Read in data from:\n",
    "    - downholeData table (from database)\n",
    "    - headerData table (from database)\n",
    "    - xyzData file (from previously carried out work) (will eventually make this updateable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "Most Recent version of this file is : ISGS_HEADER_2023-01-06.txt\n",
      "Most Recent version of this file is : xyzData.csv\n",
      "Using the following files:\n",
      "\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_HEADER_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\xyzData.csv\n",
      "Downhole Data has 3054409 valid well records.\n",
      "Header Data has 636855 unique wells with valid location information.\n"
     ]
    }
   ],
   "source": [
    "directoryDir = r'\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\\\'[:-1]\n",
    "downholeDataPATH, headerDataPATH, xyzInPATH  = readData.filesSetup(db_dir=directoryDir)\n",
    "\n",
    "#Functions to read data into dataframes. Also excludes extraneous columns, and drops header data with no location information\n",
    "headerDataIN, downholeDataIN = readData.readRawTxtData(downholefile=downholeDataPATH, headerfile=headerDataPATH) \n",
    "xyzDataIN = readData.readXYZData(xyzfile=xyzInPATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define datatypes (doing this during the read in process has presented issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\readData.py:125: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:,i] = dfIN.iloc[:,i].astype(dtypes[dfIN.iloc[:,i].name])\n"
     ]
    }
   ],
   "source": [
    "#Define datatypes, to read into defineDataTypes() function\n",
    "##EVENTUALLY, MAKE THIS A FILE IN THE RES FOLDER TO READ IN\n",
    "#downholeDataDTYPES = {'ID':np.uint32, \"API_NUMBER\":np.uint64,\"TABLE_NAME\":str,\"WHO\":str,\"INTERPRET_DATE\":str,\"FORMATION\":str,\"THICKNESS\":np.float64,\"TOP\":np.float64,\"BOTTOM\":np.float64}\n",
    "#headerDataDTYPES = {'ID':np.uint32,'API_NUMBER':np.uint64,\"TDFORMATION\":str,\"PRODFORM\":str,\"TOTAL_DEPTH\":np.float64,\"SECTION\":np.float64,\"TWP\":np.float64,\"TDIR\":str,\"RNG\":np.float64,\"RDIR\":str,\"MERIDIAN\":np.float64,\"FARM_NAME\":str,\"NSFOOT\":np.float64,\"NSDIR\":str,\"EWFOOT\":np.float64,\"EWDIR\":str,\"QUARTERS\":str,\"ELEVATION\":np.float64,\"ELEVREF\":str,\"COMP_DATE\":str,\"STATUS\":str,\"FARM_NUM\":str,\"COUNTY_CODE\":np.float64,\"PERMIT_NUMBER\":str,\"COMPANY_NAME\":str,\"COMPANY_CODE\":str,\"PERMIT_DATE\":str,\"CORNER\":str,\"LATITUDE\":np.float64,\"LONGITUDE\":np.float64,\"ENTERED_BY\":str,\"UPDDATE\":str,\"ELEVSOURCE\":str, \"ELEV_FT\":np.float64}\n",
    "#xyzDataDTYPES = {'ID':np.uint64, 'API_NUMBER':np.uint64, \"LATITUDE\":np.float64, \"LONGITUDE\":np.float64, \"ELEV_FT\":np.float64}\n",
    "\n",
    "#Define datatypes of each column of the new dataframes\n",
    "downholeDataIN = readData.defineDataTypes(downholeDataIN, dtypeFile='downholeDataTypes.txt')\n",
    "headerDataIN = readData.defineDataTypes(headerDataIN, dtypeFile='headerDataTypes.txt')\n",
    "xyzDataIN = readData.defineDataTypes(xyzDataIN, dtypeFile='xyzDataTypes.txt')\n",
    "\n",
    "#Make a copy of the data so raw data is preserved while we work with the rest of the data\n",
    "downholeData = downholeDataIN.copy()\n",
    "headerData = headerDataIN.copy()\n",
    "xyzData = xyzDataIN.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in Control points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED CODE HERE FOR ADDING IN CONTROL Wells MANUALLY\n",
    "#Add control headerInfo\n",
    "#Add control description info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Elevation Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract elevation data from consistent elevation dataset for all wells (lidar or other statewide DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, get wells with updated xyz info\n",
    "    #Check first if xyzData needs to be updated with locations (?)\n",
    "    #Check which wells in headerData don't have associated lidar data\n",
    "\n",
    "#statewideLidar =  ow\n",
    "#mapping.rastertoPoints_extract()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge elevation data with headerData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWells = headerData['API_NUMBER'].unique()\n",
    "#xyzData['UniqueWells'] = uniqueWells\n",
    "\n",
    "headerData = mapping.addElevtoHeader(xyzData, headerData)\n",
    "##NEED TO UPDATE THIS TO WORK WITH DATA WITH NO XYZ ELEVATION DATA FROM LIDAR\n",
    "#Change xyz column name to indicate lidar\n",
    "#Use order of preference: lidar, headerData table?/30/10m DEM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's clean up records in the data without the necessary information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip data from outside Study Area"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "studyAreaPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESL_StudyArea_5mi.shp\"\n",
    "studyAreaIN, saExtent = mapping.readStudyArea(studyAreaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\geopandas\\array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>201.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NE NW NW</td>\n",
       "      <td>591.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.733337</td>\n",
       "      <td>-89.933357</td>\n",
       "      <td>580.419373</td>\n",
       "      <td>POINT (-89.93336 38.73334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930917112</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>537.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.930069</td>\n",
       "      <td>-90.030655</td>\n",
       "      <td>529.981140</td>\n",
       "      <td>POINT (-90.03065 38.93007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930921712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>532.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.941998</td>\n",
       "      <td>-90.045364</td>\n",
       "      <td>530.172913</td>\n",
       "      <td>POINT (-90.04536 38.94200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930921812</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N2 SW NW</td>\n",
       "      <td>526.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.918377</td>\n",
       "      <td>-90.038200</td>\n",
       "      <td>520.954590</td>\n",
       "      <td>POINT (-90.03820 38.91838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930921912</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>507.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.870552</td>\n",
       "      <td>-89.955078</td>\n",
       "      <td>507.976868</td>\n",
       "      <td>POINT (-89.95508 38.87055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>1374073512</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.520279</td>\n",
       "      <td>-90.058060</td>\n",
       "      <td>555.110840</td>\n",
       "      <td>POINT (-90.05806 38.52028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>1374073812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SW NE SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.575832</td>\n",
       "      <td>-90.105003</td>\n",
       "      <td>409.501556</td>\n",
       "      <td>POINT (-90.10500 38.57583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1374073912</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>413.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.528660</td>\n",
       "      <td>-90.244118</td>\n",
       "      <td>410.597595</td>\n",
       "      <td>POINT (-90.24412 38.52866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>427.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.640568</td>\n",
       "      <td>-90.051552</td>\n",
       "      <td>431.323914</td>\n",
       "      <td>POINT (-90.05155 38.64057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1378559712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>562.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Interpolated by C. Abert from the 30 meter DEM</td>\n",
       "      <td>38.635914</td>\n",
       "      <td>-89.938217</td>\n",
       "      <td>565.456055</td>\n",
       "      <td>POINT (-89.93822 38.63591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       13626212        201.0     15.0  2.0    N   5.0    W       3.0   \n",
       "1      930917112         73.0     31.0  6.0    N   8.0    W       3.0   \n",
       "2      930921712         75.0     25.0  6.0    N   9.0    W       3.0   \n",
       "3      930921812        295.0      6.0  5.0    N   8.0    W       3.0   \n",
       "4      930921912       2195.0     23.0  5.0    N   8.0    W       3.0   \n",
       "...          ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "8145  1374073512         52.0     23.0  1.0    N   9.0    W       3.0   \n",
       "8146  1374073812         70.0     33.0  2.0    N   9.0    W       3.0   \n",
       "8147  1374073912         31.0     19.0  1.0    N  10.0    W       3.0   \n",
       "8148  1374794512         61.0     12.0  2.0    N   9.0    W       3.0   \n",
       "8149  1378559712          NaN     12.0  2.0    N   8.0    W       3.0   \n",
       "\n",
       "      QUARTERS  ELEVATION ELEVREF  COUNTY_CODE  \\\n",
       "0     NE NW NW      591.0     nan         27.0   \n",
       "1          nan      537.0      GL        119.0   \n",
       "2           SE      532.0      GL        119.0   \n",
       "3     N2 SW NW      526.0      GL        119.0   \n",
       "4           SE      507.0      GL        119.0   \n",
       "...        ...        ...     ...          ...   \n",
       "8145       nan        NaN     nan        163.0   \n",
       "8146  SW NE SW        NaN     nan        163.0   \n",
       "8147       nan      413.0      DM        163.0   \n",
       "8148        NW      427.0      GL        163.0   \n",
       "8149       nan      562.0      DM        163.0   \n",
       "\n",
       "                                          ELEVSOURCE   LATITUDE  LONGITUDE  \\\n",
       "0                                                nan  38.733337 -89.933357   \n",
       "1                                                nan  38.930069 -90.030655   \n",
       "2                                                nan  38.941998 -90.045364   \n",
       "3                                                nan  38.918377 -90.038200   \n",
       "4                                                nan  38.870552 -89.955078   \n",
       "...                                              ...        ...        ...   \n",
       "8145                                             nan  38.520279 -90.058060   \n",
       "8146                                             nan  38.575832 -90.105003   \n",
       "8147                                             nan  38.528660 -90.244118   \n",
       "8148                                             nan  38.640568 -90.051552   \n",
       "8149  Interpolated by C. Abert from the 30 meter DEM  38.635914 -89.938217   \n",
       "\n",
       "         ELEV_FT                    geometry  \n",
       "0     580.419373  POINT (-89.93336 38.73334)  \n",
       "1     529.981140  POINT (-90.03065 38.93007)  \n",
       "2     530.172913  POINT (-90.04536 38.94200)  \n",
       "3     520.954590  POINT (-90.03820 38.91838)  \n",
       "4     507.976868  POINT (-89.95508 38.87055)  \n",
       "...          ...                         ...  \n",
       "8145  555.110840  POINT (-90.05806 38.52028)  \n",
       "8146  409.501556  POINT (-90.10500 38.57583)  \n",
       "8147  410.597595  POINT (-90.24412 38.52866)  \n",
       "8148  431.323914  POINT (-90.05155 38.64057)  \n",
       "8149  565.456055  POINT (-89.93822 38.63591)  \n",
       "\n",
       "[8150 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData = mapping.coords2Geometry(df=headerData, xCol='LONGITUDE', yCol='LATITUDE', crs='EPSG:4269')\n",
    "#headerData['geometry']=headerData['GEOMETRY'].copy() #old code\n",
    "studyArea_4269 = studyAreaIN.to_crs('EPSG:4269').copy()\n",
    "headerDataClip = gpd.clip(headerData, studyArea_4269) #Data from table is in EPSG:4269, easier to just project study area to ensure data fit\n",
    "headerDataClip.reset_index(inplace=True, drop=True)\n",
    "headerData = headerDataClip.copy()\n",
    "headerData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove data from downholeData table that does not have location information (Since we would not know where to put it anyway)\n",
    "\n",
    "This should also essentially \"clip\" the downholeData to the study area, since only study area wells remain in headerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2998078 records removed without location information.\n",
      "56331 wells remain from 7188 located wells in study area.\n"
     ]
    }
   ],
   "source": [
    "downholeData = cleanData.removeNonlocatedData(downholeData, headerData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove headerData rows without surface elevation information (this currently clips data from outside Illinois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>201.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NE NW NW</td>\n",
       "      <td>591.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.733337</td>\n",
       "      <td>-89.933357</td>\n",
       "      <td>580.419373</td>\n",
       "      <td>POINT (-89.93336 38.73334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930917112</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>537.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.930069</td>\n",
       "      <td>-90.030655</td>\n",
       "      <td>529.981140</td>\n",
       "      <td>POINT (-90.03065 38.93007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930921712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>532.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.941998</td>\n",
       "      <td>-90.045364</td>\n",
       "      <td>530.172913</td>\n",
       "      <td>POINT (-90.04536 38.94200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930921812</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N2 SW NW</td>\n",
       "      <td>526.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.918377</td>\n",
       "      <td>-90.038200</td>\n",
       "      <td>520.954590</td>\n",
       "      <td>POINT (-90.03820 38.91838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930921912</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>507.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.870552</td>\n",
       "      <td>-89.955078</td>\n",
       "      <td>507.976868</td>\n",
       "      <td>POINT (-89.95508 38.87055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>1374073512</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.520279</td>\n",
       "      <td>-90.058060</td>\n",
       "      <td>555.110840</td>\n",
       "      <td>POINT (-90.05806 38.52028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>1374073812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SW NE SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.575832</td>\n",
       "      <td>-90.105003</td>\n",
       "      <td>409.501556</td>\n",
       "      <td>POINT (-90.10500 38.57583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1374073912</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>413.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.528660</td>\n",
       "      <td>-90.244118</td>\n",
       "      <td>410.597595</td>\n",
       "      <td>POINT (-90.24412 38.52866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>427.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.640568</td>\n",
       "      <td>-90.051552</td>\n",
       "      <td>431.323914</td>\n",
       "      <td>POINT (-90.05155 38.64057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1378559712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>562.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Interpolated by C. Abert from the 30 meter DEM</td>\n",
       "      <td>38.635914</td>\n",
       "      <td>-89.938217</td>\n",
       "      <td>565.456055</td>\n",
       "      <td>POINT (-89.93822 38.63591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       13626212        201.0     15.0  2.0    N   5.0    W       3.0   \n",
       "1      930917112         73.0     31.0  6.0    N   8.0    W       3.0   \n",
       "2      930921712         75.0     25.0  6.0    N   9.0    W       3.0   \n",
       "3      930921812        295.0      6.0  5.0    N   8.0    W       3.0   \n",
       "4      930921912       2195.0     23.0  5.0    N   8.0    W       3.0   \n",
       "...          ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "8145  1374073512         52.0     23.0  1.0    N   9.0    W       3.0   \n",
       "8146  1374073812         70.0     33.0  2.0    N   9.0    W       3.0   \n",
       "8147  1374073912         31.0     19.0  1.0    N  10.0    W       3.0   \n",
       "8148  1374794512         61.0     12.0  2.0    N   9.0    W       3.0   \n",
       "8149  1378559712          NaN     12.0  2.0    N   8.0    W       3.0   \n",
       "\n",
       "      QUARTERS  ELEVATION ELEVREF  COUNTY_CODE  \\\n",
       "0     NE NW NW      591.0     nan         27.0   \n",
       "1          nan      537.0      GL        119.0   \n",
       "2           SE      532.0      GL        119.0   \n",
       "3     N2 SW NW      526.0      GL        119.0   \n",
       "4           SE      507.0      GL        119.0   \n",
       "...        ...        ...     ...          ...   \n",
       "8145       nan        NaN     nan        163.0   \n",
       "8146  SW NE SW        NaN     nan        163.0   \n",
       "8147       nan      413.0      DM        163.0   \n",
       "8148        NW      427.0      GL        163.0   \n",
       "8149       nan      562.0      DM        163.0   \n",
       "\n",
       "                                          ELEVSOURCE   LATITUDE  LONGITUDE  \\\n",
       "0                                                nan  38.733337 -89.933357   \n",
       "1                                                nan  38.930069 -90.030655   \n",
       "2                                                nan  38.941998 -90.045364   \n",
       "3                                                nan  38.918377 -90.038200   \n",
       "4                                                nan  38.870552 -89.955078   \n",
       "...                                              ...        ...        ...   \n",
       "8145                                             nan  38.520279 -90.058060   \n",
       "8146                                             nan  38.575832 -90.105003   \n",
       "8147                                             nan  38.528660 -90.244118   \n",
       "8148                                             nan  38.640568 -90.051552   \n",
       "8149  Interpolated by C. Abert from the 30 meter DEM  38.635914 -89.938217   \n",
       "\n",
       "         ELEV_FT                    geometry  \n",
       "0     580.419373  POINT (-89.93336 38.73334)  \n",
       "1     529.981140  POINT (-90.03065 38.93007)  \n",
       "2     530.172913  POINT (-90.04536 38.94200)  \n",
       "3     520.954590  POINT (-90.03820 38.91838)  \n",
       "4     507.976868  POINT (-89.95508 38.87055)  \n",
       "...          ...                         ...  \n",
       "8145  555.110840  POINT (-90.05806 38.52028)  \n",
       "8146  409.501556  POINT (-90.10500 38.57583)  \n",
       "8147  410.597595  POINT (-90.24412 38.52866)  \n",
       "8148  431.323914  POINT (-90.05155 38.64057)  \n",
       "8149  565.456055  POINT (-89.93822 38.63591)  \n",
       "\n",
       "[8150 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData =headerDataClip.copy()\n",
    "headerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well records removed: 0\n",
      "Number of rows before dropping those without surface elevation information: 8150\n",
      "Number of rows after dropping those without surface elevation information: 8150\n"
     ]
    }
   ],
   "source": [
    "headerData = cleanData.removenotopo(df=headerData, printouts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows from downholeData with no depth information and where depth information is obviously bad (i.e., top depth > bottom depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without record depth information: 56331\n",
      "Number of rows after dropping those without record depth information: 55747\n",
      "Number of well records without formation information deleted: 584\n",
      "Number of rows before dropping those with obviously bad depth information: 56331\n",
      "Number of rows after dropping those with obviously bad depth information: 55725\n",
      "Well records deleted: 606\n"
     ]
    }
   ],
   "source": [
    "#Drop records with no depth information\n",
    "donwholeData = cleanData.dropnodepth(downholeData, printouts=True)\n",
    "#Drop records with bad depth information (i.e., top depth > bottom depth) (Also calculates thickness of each record)\n",
    "donwholeData = cleanData.dropbaddepth(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records with no FORMATION information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without FORMATION information: 56331\n",
      "Number of rows after dropping those without FORMATION information: 56331\n",
      "Well records deleted: 0\n"
     ]
    }
   ],
   "source": [
    "downholeData = cleanData.dropnoformation(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to export this data, to have record of cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData.reset_index(inplace=True,drop=True)\n",
    "headerData.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#downholeData.to_csv(str(repoDir)+'/out/downholeData_cleaned'+dateSuffix+'.csv',index_label='ID')\n",
    "#headerData.to_csv(str(repoDir)+'/out/headerData_cleaned'+dateSuffix+'.csv',index_label='ID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following flags are used to mark the classification method:\n",
    "- 0: Not classified\n",
    "- 1: Specific Search Term Match\n",
    "- 2: Wildcard match (startTerm) - no context\n",
    "- 3: Bedrock classification for obvious bedrock\n",
    "- 4: Wildcard match (startTerm) - with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : SearchTerms-Specific_2022-11-16_essCols.csv\n",
      "Most Recent version of this file is : SearchTerms-Start.csv\n"
     ]
    }
   ],
   "source": [
    "#Read in dictionary files for downhole data\n",
    "specTermsPATH, startTermsPATH = readData.searchTermFilePaths(dictdir=str(repoDir)+'/res/', specStartPattern='*SearchTerms-Specific*', startGlobPattern = '*SearchTerms-Start*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\readData.py:155: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  specTerms.iloc[:,i] = specTerms.iloc[:,i].astype(specTermsDtypes[specTerms.iloc[:,i].name])\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\readData.py:156: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  startTerms.iloc[:,i] = startTerms.iloc[:,i].astype(startTermsDtypes[startTerms.iloc[:,i].name])\n"
     ]
    }
   ],
   "source": [
    "specTerms, startTerms = readData.readSearchTerms(specfile=specTermsPATH, startfile=startTermsPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the dataframes--for the specific search terms, this is the same as classifying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Classified with full search term: 25280\n",
      "Records Classified with full search term: 44.88% of data\n"
     ]
    }
   ],
   "source": [
    "downholeData_spec = classify.specificDefine(downholeData, specTerms, printouts=True)\n",
    "downholeData = downholeData_spec.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with only the records already classified (using the specific search terms in this case, classifiedDF), and one that still needs to be searched (searchDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31051"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifedDF, searchDF = classify.splitDefined(downholeData)\n",
    "searchDF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do the classification routine on the searchDF database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Term process should be done by 11:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].where(~df['FORMATION'].str.startswith(s,na=False),4,inplace=True)\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['INTERPRETATION'].where(~df['FORMATION'].str.startswith(s,na=False),starterms.loc[i,'INTERPRETATION'],inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records classified with start search term: 3876\n",
      "Records classified with start search term: 12.48% of remaining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEDROCK_FLAG'] = df[\"INTERPRETATION\"] == 'BEDROCK'\n"
     ]
    }
   ],
   "source": [
    "searchDF = classify.startDefine(df=searchDF, starterms=startTerms, printouts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge specDF and searchDF back together all back in single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData_Terms = classify.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Terms.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export terms that still need to be defined to csv (along with their counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The outdir should be changed so it doesn't clog up the repository\n",
    "#classify.export_toBeDefined(df=downholeData, outdir=str(repoDir)+'/out/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify all  data under depth threshold (default is 550') as bedrock (should not be an issue, but just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    500\n",
      "Name: CLASS_FLAG, dtype: int64\n",
      "test\n",
      "Records classified as bedrock that were deeper than 550': 500\n",
      "This represents 1.84% of the unclassified data in this dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].mask(df['TOP']>thresh, 3 ,inplace=True) #Add a Classification Flag of 3 (bedrock b/c it's deepter than 550') to all records where the top of the interval is >550'\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEDROCK_FLAG'].mask(df['TOP']>thresh, True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "classifedDF, searchDF = classify.splitDefined(downholeData)\n",
    "searchDF = classify.depthDefine(searchDF, thresh=550, printouts=True)\n",
    "downholeData_Class = classify.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Class.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add '0' flag for data still not classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = classify.fillUnclassified(downholeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    26675\n",
       "1.0    25280\n",
       "4.0     3876\n",
       "3.0      500\n",
       "Name: CLASS_FLAG, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['CLASS_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add \"Flag\" for target interpratations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictDir = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\WellDataAutoClassification\\\\SupportingDocs\\\\\"\n",
    "targetInterpDF = readData.readLithologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = classify.mergeLithologies(downholedata=downholeData, targinterps=targetInterpDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags used for target classification purposes:\n",
    "- -2: No classification \n",
    "- -1: Classified, not used/not definitive\n",
    "- 0: Classified, not target material\n",
    "- 1: Classified as target material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2    27217\n",
       "-1    14452\n",
       "0     10637\n",
       "1      4025\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all unique wells in downhole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique wells in downholeData: 7188\n"
     ]
    }
   ],
   "source": [
    "#Get Unique well APIs\n",
    "wellsDF = classify.getUniqueWells(downholeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort dataset by API Number and Depth of top of record (will be easier to do data analysis with records in the correct order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>THICKNESS</th>\n",
       "      <th>TOP</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>INTERPRETATION</th>\n",
       "      <th>CLASS_FLAG</th>\n",
       "      <th>BEDROCK_FLAG</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>MUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay brown</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>CLAY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAND AND CLAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay gray sandy, soft</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay gray, sticky</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay dark brown, wood</td>\n",
       "      <td>6.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>shale gray sandy hard</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>BEDROCK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DIRT AND GRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56326</th>\n",
       "      <td>56324</td>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>brown and gray silty clay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>SILT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56327</th>\n",
       "      <td>56328</td>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray clay (with thin sand streaks)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56328</th>\n",
       "      <td>56322</td>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>blue-gray clay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56329</th>\n",
       "      <td>56329</td>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray, fine sand</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56330</th>\n",
       "      <td>56325</td>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>brown and gray, fine to coarse, sand</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56331 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  API_NUMBER     TABLE_NAME                             FORMATION  \\\n",
       "0          0    13626212    WFORMATIONS                            clay brown   \n",
       "1          2    13626212    WFORMATIONS                 clay gray sandy, soft   \n",
       "2          3    13626212    WFORMATIONS                     clay gray, sticky   \n",
       "3          1    13626212    WFORMATIONS                 clay dark brown, wood   \n",
       "4          7    13626212    WFORMATIONS                 shale gray sandy hard   \n",
       "...      ...         ...            ...                                   ...   \n",
       "56326  56324  1374794512  HWYBRIDGE_LOG             brown and gray silty clay   \n",
       "56327  56328  1374794512  HWYBRIDGE_LOG    gray clay (with thin sand streaks)   \n",
       "56328  56322  1374794512  HWYBRIDGE_LOG                        blue-gray clay   \n",
       "56329  56329  1374794512  HWYBRIDGE_LOG                       gray, fine sand   \n",
       "56330  56325  1374794512  HWYBRIDGE_LOG  brown and gray, fine to coarse, sand   \n",
       "\n",
       "       THICKNESS   TOP  BOTTOM INTERPRETATION  CLASS_FLAG  BEDROCK_FLAG  \\\n",
       "0           20.0   0.0    20.0           CLAY         1.0         False   \n",
       "1           20.0  20.0    40.0            NaN         0.0         False   \n",
       "2            4.0  40.0    44.0            NaN         0.0         False   \n",
       "3            6.0  44.0    50.0            NaN         0.0         False   \n",
       "4           64.0  50.0   114.0        BEDROCK         1.0          True   \n",
       "...          ...   ...     ...            ...         ...           ...   \n",
       "56326        5.0  21.5    26.5           SILT         1.0         False   \n",
       "56327        7.5  26.5    34.0            NaN         0.0         False   \n",
       "56328        5.0  34.0    39.0            NaN         0.0         False   \n",
       "56329        5.0  39.0    44.0            NaN         0.0         False   \n",
       "56330       17.0  44.0    61.0            NaN         0.0         False   \n",
       "\n",
       "      TARGET  Unnamed: 2              MUD  \n",
       "0          0         NaN    SAND AND CLAY  \n",
       "1         -2         NaN              NaN  \n",
       "2         -2         NaN              NaN  \n",
       "3         -2         NaN              NaN  \n",
       "4         -1         NaN  DIRT AND GRAVEL  \n",
       "...      ...         ...              ...  \n",
       "56326      0         NaN              NaN  \n",
       "56327     -2         NaN              NaN  \n",
       "56328     -2         NaN              NaN  \n",
       "56329     -2         NaN              NaN  \n",
       "56330     -2         NaN              NaN  \n",
       "\n",
       "[56331 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData_sorted = downholeData.sort_values(['API_NUMBER','TOP'])\n",
    "downholeData_sorted.reset_index(inplace=True)\n",
    "downholeData_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bedrock Depth and Layer Thickness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in/Define Model Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGridPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\grid_625_raster.tif\"\n",
    "modelGrid = mapping.readModelGrid(studyArea=studyAreaIN, gridpath=modelGridPath, nodataval=0, readGrid=True, clip2SA=True, gridcrs='EPSG:26715', studyAreacrs='EPSG:26715')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in surface elevation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaceElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ILStateLidar_ClipExtentESL.tif\"\n",
    "surfaceElevGridIN = mapping.readSurfaceGrid(surfaceelevpath=surfaceElevPath, useWCS=False, studyArea=studyAreaIN, clip2SA=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in bedrock elevation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrockElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESLBedrock.tif\"\n",
    "bedrockElevGridIN=mapping.readBedrockGrid(bedrockelevpath=bedrockElevPath, studyArea=studyAreaIN, clip2SA=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot just to see them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(ncols = 2, nrows=1)\n",
    "#bedrockElevGridIN.plot(ax=ax[0])\n",
    "#surfaceElevGridIN.plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject and align raster grids for surface elevation and bedrock topo (reproject well data too if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inGrids = [bedrockElevGridIN, surfaceElevGridIN]\n",
    "bedrockGrid, surfaceGrid = mapping.alignRasters(unalignedGrids=inGrids, modelgrid=modelGrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(ncols = 2, nrows=1)\n",
    "bedrockGrid.plot(ax=ax[0])\n",
    "surfaceGrid.plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the surface elevation raster and bedrock elevation raster to get depth to bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "driftThickGrid, layerThickGrid = mapping.getDriftThick(surface=surfaceGrid, bedrock=bedrockGrid, noLayers=9, plotData=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sample each well point (headerData) to get layer thickness, surface elevation, and bedrock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerData = mapping.rastertoPoints_sample(raster=bedrockGrid, ptDF=headerData, newColName='BEDROCK_ELEV_FT')\n",
    "headerData['BEDROCK_ELEV_M'] = headerData['BEDROCK_ELEV_FT']* 0.3048\n",
    "\n",
    "headerData = mapping.rastertoPoints_sample(raster=surfaceGrid, ptDF=headerData, newColName='SURFACE_ELEV_FT')\n",
    "headerData['SURFACE_ELEV_M'] = headerData['SURFACE_ELEV_FT']* 0.3048\n",
    "\n",
    "headerData = mapping.rastertoPoints_sample(raster=layerThickGrid, ptDF=headerData, newColName='LAYER_THICK_FT')\n",
    "headerData['LAYER_THICK_M'] = headerData['LAYER_THICK_FT']* 0.3048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate  all layer depths/elevations at all wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noLayers = 9\n",
    "for layer in range(0, noLayers): #For each layer\n",
    "    #Make column names\n",
    "    depthColName  = 'Depth_FT_LAYER'+str(layer)\n",
    "    depthMcolName = 'Depth_M_LAYER'+str(layer) \n",
    "\n",
    "    elevColName = 'ELEV_FT_LAYER'+str(layer)\n",
    "    elevMColName = 'ELEV_M_LAYER'+str(layer)\n",
    "    \n",
    "    #Calculate depth to each layer at each well, in feet and meters\n",
    "    headerData[depthColName]  = headerData['Layer_Thick_FT'] * layer\n",
    "    headerData[depthMcolName] = headerData[depthColName] * 0.3048\n",
    "    \n",
    "    headerData[elevColName]  = headerData['SURFACE_ELEV_FT'] - headerData['Layer_Thick_FT'] * layer\n",
    "    headerData[elevMColName]  = headerData['SURFACE_ELEV_M'] - headerData['Layer_Thick_M'] * layer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work here next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate target thickness in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS CELL MAY NEED TO BE UPDATED!!!!!\n",
    "\n",
    "\n",
    "#Define the function to export the result of thickness of target sediments in each layer\n",
    "def Layers_surfacedown(df, layer = 1):\n",
    "    \n",
    "    #Generate Column names based on (looped) integers\n",
    "    topCol = \"ESL_ModelTopoLyrs_\"+str(layer)\n",
    "    if layer != 9: #For all layers except the bottom layer....\n",
    "        botCol = \"ESL_ModelTopoLyrs_\"+str(layer+1) #use the layer below it to \n",
    "    else: #Otherwise, ...\n",
    "        botCol = \"BedrockCorr\" #Use the (corrected) bedrock depth\n",
    "\n",
    "    #Divide records into 4 separate categories for ease of calculation, to be joined back together later  \n",
    "        #Category 1: Well interval starts above layer top, ends within model layer\n",
    "        #Category 2: Well interval is entirely contained withing model layer\n",
    "        #Category 3: Well interval starts within model layer, continues through bottom of model layer\n",
    "        #Category 4: well interval begins and ends on either side of model layer (model layer is contained within well layer)\n",
    "\n",
    "    #records1 = intervals that go through the top of the layer and bottom is within layer\n",
    "    records1 = df.loc[(df['TOP_ELEV_ft'] > df[topCol]) & (df['BOT_ELEV_ft'] > df[botCol]) & (df['BOT_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records1['TARG_THICK'] = pd.DataFrame(np.round((records1.loc[:,topCol]-records1.loc[: , 'BOT_ELEV_ft']) * records1['Target'],3)).copy()\n",
    "    \n",
    "    #records2 = entire interval is within layer\n",
    "    records2 = df.loc[(df['TOP_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] >= df[botCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records2['TARG_THICK'] = pd.DataFrame(np.round((records2.loc[: , 'TOP_ELEV_ft'] - records2.loc[: , 'BOT_ELEV_ft']) * records2['Target'],3)).copy()\n",
    "\n",
    "    #records3 = intervals with top within layer and bottom of interval going through bottom of layer\n",
    "    records3 = df.loc[(df['TOP_ELEV_ft'] > df[botCol]) & (df['BOT_ELEV_ft'] < df[botCol]) & (df['TOP_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records3['TARG_THICK'] = pd.DataFrame(np.round((records3.loc[: , 'TOP_ELEV_ft'] - (records3.loc[:,botCol]))*records3['Target'],3)).copy()\n",
    "\n",
    "    #records4 = interval goes through entire layer\n",
    "    records4 = df.loc[(df['TOP_ELEV_ft'] > df[topCol]) & (df['BOT_ELEV_ft'] < df[botCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records4['TARG_THICK'] = pd.DataFrame(np.round((records4.loc[: , topCol]-records4.loc[: , botCol]) * records4['Target'],3)).copy()\n",
    "\n",
    "    \n",
    "    #Put the four calculated record categories back together into single dataframe\n",
    "    res = records1.append(records2).append(records3).append(records4)\n",
    "    \n",
    "    res_df = res.groupby(['API_NUMBER','LATITUDE','LONGITUDE'],as_index=False).sum()#calculate thickness for each well interval in the layer indicated (e.g., if there are two well intervals from same well in one model layer)\n",
    "\n",
    "    res_df['TARG_THICK_PER'] = pd.DataFrame(np.round(res_df['TARG_THICK']/res_df['LyrThick'],3)) #Calculate thickness as percent of total layer thickness\n",
    "    res_df[\"LAYER\"] = layer #Just to have as part of the output file, include the present layer in the file itself as a separate column\n",
    "    res_df = res_df[['API_NUMBER', 'LATITUDE', 'LONGITUDE', 'TOP', 'BOTTOM','SURF_ELEV_ft', 'TOP_ELEV_ft', 'BOT_ELEV_ft',topCol,botCol,'LyrThick','TARG_THICK', 'TARG_THICK_PER', 'LAYER']].copy() #Format dataframe for output\n",
    "    \n",
    "    return res, res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run that function over all the layers, looping through each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL WILL NEED TO BE UPDATED\n",
    "\n",
    "outDIR = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\MetroEast_HydroGeo\\\\CodeOutput\\\\\"+codeTarget+\"\\\\\"\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    res, res_df = Layers_surfacedown(df, layer = i)#Run the function defined above for each layer\n",
    "    outputname = codeTargShort+'Lyr'+str(i)+'.csv' #Create a filename based on the layer and target\n",
    "    res_df.to_csv(outDIR+outputname)  #Export the file to csv\n",
    "    #Could also potentially save these to variables for use in following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate thickness values in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each layer and interpolate (use same parameters (?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure rasters align (are co-registered) with grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data \n",
    "downhole_bedrockDepth_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\Downhole_BedrockPicks.csv',index_label=\"ID\")\n",
    "wPermits_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\wPermits_BedrockPicks.csv',index_label=\"ID\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "1eab39f8790fa4ef06ab4ebada9c1405c2ef16219adfedb21e90bf3fb356ecb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
