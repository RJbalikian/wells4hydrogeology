{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{Fill in with information about this notebook}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "#The rest of this is just for fun/quick dataviz at the end to map and ensure seems about right\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import geopandas\n",
    "\n",
    "from lib import readData\n",
    "from lib import mapping\n",
    "from lib import cleanData\n",
    "from lib import classify\n",
    "from lib import exportData\n",
    "\n",
    "todayDate, dateSuffix = readData.getCurrentDate()\n",
    "repoDir = pathlib.Path(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set up filepaths\n",
    "- Read in data from:\n",
    "    - downholeData table (from database)\n",
    "    - headerData table (from database)\n",
    "    - xyzData file (from previously carried out work) (will eventually make this updateable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "Most Recent version of this file is : ISGS_HEADER_2023-01-06.txt\n",
      "Most Recent version of this file is : xyzData.csv\n",
      "Using the following files:\n",
      "\n",
      "\\\\isgs-sinkhole\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "\\\\isgs-sinkhole\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_HEADER_2023-01-06.txt\n",
      "\\\\isgs-sinkhole\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\xyzData.csv\n",
      "Downhole Data has 3054409 valid well records.\n",
      "Header Data has 636855 unique wells with valid location information.\n"
     ]
    }
   ],
   "source": [
    "directoryDir = r'\\\\isgs-sinkhole\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\\\'[:-1]\n",
    "\n",
    "downholeDataPATH, headerDataPATH, xyzInPATH  = readData.filesSetup(db_dir=directoryDir)\n",
    "\n",
    "#Functions to read data into dataframes. Also excludes extraneous columns\n",
    "headerDataIN, downholeDataIN = readData.readRawTxtData(downholefile=downholeDataPATH, headerfile=headerDataPATH)\n",
    "xyzDataIN = readData.readXYZData(xyzfile=xyzInPATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define datatypes (doing this during the read in process has presented issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define datatypes, to read into defineDataTypes() function\n",
    "##EVENTUALLY, MAKE THIS A FILE IN THE RES FOLDER TO READ IN\n",
    "#downholeDataDTYPES = {'ID':np.uint32, \"API_NUMBER\":np.uint64,\"TABLE_NAME\":str,\"WHO\":str,\"INTERPRET_DATE\":str,\"FORMATION\":str,\"THICKNESS\":np.float64,\"TOP\":np.float64,\"BOTTOM\":np.float64}\n",
    "#headerDataDTYPES = {'ID':np.uint32,'API_NUMBER':np.uint64,\"TDFORMATION\":str,\"PRODFORM\":str,\"TOTAL_DEPTH\":np.float64,\"SECTION\":np.float64,\"TWP\":np.float64,\"TDIR\":str,\"RNG\":np.float64,\"RDIR\":str,\"MERIDIAN\":np.float64,\"FARM_NAME\":str,\"NSFOOT\":np.float64,\"NSDIR\":str,\"EWFOOT\":np.float64,\"EWDIR\":str,\"QUARTERS\":str,\"ELEVATION\":np.float64,\"ELEVREF\":str,\"COMP_DATE\":str,\"STATUS\":str,\"FARM_NUM\":str,\"COUNTY_CODE\":np.float64,\"PERMIT_NUMBER\":str,\"COMPANY_NAME\":str,\"COMPANY_CODE\":str,\"PERMIT_DATE\":str,\"CORNER\":str,\"LATITUDE\":np.float64,\"LONGITUDE\":np.float64,\"ENTERED_BY\":str,\"UPDDATE\":str,\"ELEVSOURCE\":str, \"ELEV_FT\":np.float64}\n",
    "#xyzDataDTYPES = {'ID':np.uint64, 'API_NUMBER':np.uint64, \"LATITUDE\":np.float64, \"LONGITUDE\":np.float64, \"ELEV_FT\":np.float64}\n",
    "\n",
    "#Define datatypes of each column of the new dataframes\n",
    "downholeDataIN = readData.defineDataTypes(downholeDataIN, dtypeFile='downholeDataTypes.txt')\n",
    "headerDataIN = readData.defineDataTypes(headerDataIN, dtypeFile='headerDataTypes.txt')\n",
    "xyzDataIN = readData.defineDataTypes(xyzDataIN, dtypeFile='xyzDataTypes.txt')\n",
    "\n",
    "#Make a copy of the data so raw data is preserved while we work with the rest of the data\n",
    "downholeData = downholeDataIN.copy()\n",
    "headerData = headerDataIN.copy()\n",
    "xyzData = xyzDataIN.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Elevation Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract elevation data from consistent elevation dataset for all wells (lidar or other statewide DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, get wells with updated xyz info\n",
    "    #Check first if xyzData needs to be updated with locations (?)\n",
    "    #Check which wells in headerData don't have associated lidar data\n",
    "\n",
    "#statewideLidar =  ow\n",
    "#mapping.rastertoPoints_extract()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge elevation data with headerData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWells = headerData['API_NUMBER'].unique()\n",
    "#xyzData['UniqueWells'] = uniqueWells\n",
    "\n",
    "headerData = mapping.addElevtoHeader(xyzData, headerData)\n",
    "##NEED TO UPDATE THIS TO WORK WITH DATA WITH NO XYZ ELEVATION DATA FROM LIDAR\n",
    "#Change xyz column name to indicate lidar\n",
    "#Use order of preference: lidar, headerData table?/30/10m DEM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's clean up records in the data without the necessary information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HeaderXYZ dataframe has headerdata with updated elevations (from lidar or other DEM)\n",
    "\n",
    "Now, remove data from downholeData table that does not have location information (Since we would not know where to put it anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13615 records removed without location information.\n"
     ]
    }
   ],
   "source": [
    "downholeData = cleanData.removeNonlocatedData(downholeData, headerData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip data from outside Illinois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not done yet, use geopandas clip (May need to generate geometry column first in headerData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4045883208</td>\n",
       "      <td>570.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SW SE</td>\n",
       "      <td>620.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>40.080723</td>\n",
       "      <td>-90.921097</td>\n",
       "      <td>616.728271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4045883308</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SE SE</td>\n",
       "      <td>590.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>40.079857</td>\n",
       "      <td>-90.913589</td>\n",
       "      <td>580.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4045883408</td>\n",
       "      <td>725.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>731.0</td>\n",
       "      <td>TM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>40.051773</td>\n",
       "      <td>-90.995911</td>\n",
       "      <td>679.606506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4045883508</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SE NE NW</td>\n",
       "      <td>732.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>40.059509</td>\n",
       "      <td>-90.963264</td>\n",
       "      <td>737.663574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4045883608</td>\n",
       "      <td>732.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>745.0</td>\n",
       "      <td>TM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>40.054066</td>\n",
       "      <td>-90.932716</td>\n",
       "      <td>741.997925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636850</th>\n",
       "      <td>3848631244</td>\n",
       "      <td>139.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>21.0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SW NE NW</td>\n",
       "      <td>817.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>59.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>42.522205</td>\n",
       "      <td>-88.064186</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636851</th>\n",
       "      <td>3848631344</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>19.0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SW SW SE</td>\n",
       "      <td>975.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>59.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>42.495945</td>\n",
       "      <td>-88.232162</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636852</th>\n",
       "      <td>3848657344</td>\n",
       "      <td>209.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>20.0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SE SE</td>\n",
       "      <td>780.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>59.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>42.526997</td>\n",
       "      <td>-88.128387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636853</th>\n",
       "      <td>3848658244</td>\n",
       "      <td>200.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>20.0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SE NE</td>\n",
       "      <td>840.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>59.0</td>\n",
       "      <td>TM</td>\n",
       "      <td>42.504860</td>\n",
       "      <td>-88.075172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636854</th>\n",
       "      <td>3848673144</td>\n",
       "      <td>176.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>20.0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SW SE</td>\n",
       "      <td>825.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>59.0</td>\n",
       "      <td>TM</td>\n",
       "      <td>42.496857</td>\n",
       "      <td>-88.095139</td>\n",
       "      <td>825.878113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636855 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       4045883208        570.0     12.0  1.0    N   5.0    W       4.0   \n",
       "1       4045883308         20.0     12.0  1.0    N   5.0    W       4.0   \n",
       "2       4045883408        725.0     20.0  1.0    N   5.0    W       4.0   \n",
       "3       4045883508       1129.0     22.0  1.0    N   5.0    W       4.0   \n",
       "4       4045883608        732.0     24.0  1.0    N   5.0    W       4.0   \n",
       "...            ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "636850  3848631244        139.0     30.0  1.0    N  21.0    E       0.0   \n",
       "636851  3848631344         50.0     34.0  1.0    N  19.0    E       0.0   \n",
       "636852  3848657344        209.0     21.0  1.0    N  20.0    E       0.0   \n",
       "636853  3848658244        200.0     36.0  1.0    N  20.0    E       0.0   \n",
       "636854  3848673144        176.0     35.0  1.0    N  20.0    E       0.0   \n",
       "\n",
       "        QUARTERS  ELEVATION ELEVREF  COUNTY_CODE ELEVSOURCE   LATITUDE  \\\n",
       "0          SW SE      620.0      GL          1.0        nan  40.080723   \n",
       "1          SE SE      590.0      GL          1.0        nan  40.079857   \n",
       "2             SE      731.0      TM          1.0        nan  40.051773   \n",
       "3       SE NE NW      732.0      GL          1.0        nan  40.059509   \n",
       "4             SW      745.0      TM          1.0        nan  40.054066   \n",
       "...          ...        ...     ...          ...        ...        ...   \n",
       "636850  SW NE NW      817.0     nan         59.0        GPS  42.522205   \n",
       "636851  SW SW SE      975.0     nan         59.0        nan  42.495945   \n",
       "636852     SE SE      780.0     nan         59.0        GPS  42.526997   \n",
       "636853     SE NE      840.0     nan         59.0         TM  42.504860   \n",
       "636854     SW SE      825.0     nan         59.0         TM  42.496857   \n",
       "\n",
       "        LONGITUDE     ELEV_FT  \n",
       "0      -90.921097  616.728271  \n",
       "1      -90.913589  580.442200  \n",
       "2      -90.995911  679.606506  \n",
       "3      -90.963264  737.663574  \n",
       "4      -90.932716  741.997925  \n",
       "...           ...         ...  \n",
       "636850 -88.064186         NaN  \n",
       "636851 -88.232162    0.000000  \n",
       "636852 -88.128387         NaN  \n",
       "636853 -88.075172    0.000000  \n",
       "636854 -88.095139  825.878113  \n",
       "\n",
       "[636855 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove headerData rows without surface elevation information (this currently clips data from outside Illinois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without surface elevation information: 636855\n",
      "Number of rows after dropping those without surface elevation information: 632702\n",
      "Well records deleted: 4153\n"
     ]
    }
   ],
   "source": [
    "headerData = cleanData.removenotopo(headerData, printouts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows from downholeData with no depth information and where depth information is obviously bad (i.e., top depth > bottom depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without record depth information: 3040794\n",
      "Number of rows after dropping those without record depth information: 2625120\n",
      "Number of well records without formation information deleted: 415674\n",
      "Number of rows before dropping those with obviously bad depth information: 3040794\n",
      "Number of rows after dropping those with obviously bad depth information: 2622533\n",
      "Well records deleted: 418261\n"
     ]
    }
   ],
   "source": [
    "#Drop records with no depth information\n",
    "donwholeData = cleanData.dropnodepth(downholeData, printouts=True)\n",
    "#Drop records with bad depth information (i.e., top depth > bottom depth) (Also calculates thickness of each record)\n",
    "donwholeData = cleanData.dropbaddepth(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records with no FORMATION information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without FORMATION information: 3040794\n",
      "Number of rows after dropping those without FORMATION information: 3040794\n",
      "Well records deleted: 0\n"
     ]
    }
   ],
   "source": [
    "downholeData = cleanData.dropnoformation(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to export this data, to have record of cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData.reset_index(inplace=True,drop=True)\n",
    "headerData.reset_index(inplace=True,drop=True)\n",
    "\n",
    "downholeData.to_csv(str(repoDir)+'/out/downholeData_cleaned'+dateSuffix+'.csv',index_label='ID')\n",
    "headerData.to_csv(str(repoDir)+'/out/headerData_cleaned'+dateSuffix+'.csv',index_label='ID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following flags are used to mark the classification method:\n",
    "- 0: Not classified\n",
    "- 1: Specific Search Term Match\n",
    "- 2: Wildcard match (startTerm) - no context\n",
    "- 3: Bedrock classification for obvious bedrock\n",
    "- 4: Wildcard match (startTerm) - with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : SearchTerms-Specific_2022-11-16_essCols.csv\n",
      "Most Recent version of this file is : SearchTerms-Start.csv\n"
     ]
    }
   ],
   "source": [
    "#Read in dictionary files for downhole data\n",
    "specTermsPATH, startTermsPATH = readData.searchTermFilePaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "specTerms, startTerms = readData.readSearchTerms(specfile=specTermsPATH, startfile=startTermsPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the dataframes--for the specific search terms, this is the same as classifying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Classified with full search term: 2138359\n",
      "Records Classified with full search term: 70.32% of data\n"
     ]
    }
   ],
   "source": [
    "downholeData_spec = classify.specificDefine(downholeData, specTerms, printouts=True)\n",
    "downholeData = downholeData_spec.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with only the records already classified (using the specific search terms in this case, classifiedDF), and one that still needs to be searched (searchDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902435"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifedDF, searchDF = classify.splitDefined(downholeData)\n",
    "searchDF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do the classification routine on the searchDF database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Term process should be done by 14:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\balikian\\OneDrive - University of Illinois - Urbana\\CodesandScripts\\Git\\wells4hydrogeology\\lib\\classify.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].where(~df['FORMATION'].str.startswith(s,na=False),4,inplace=True)\n",
      "c:\\Users\\balikian\\OneDrive - University of Illinois - Urbana\\CodesandScripts\\Git\\wells4hydrogeology\\lib\\classify.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['INTERPRETATION'].where(~df['FORMATION'].str.startswith(s,na=False),starterms.loc[i,'INTERPRETATION'],inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records classified with start search term: 107010\n",
      "Records classified with start search term: 11.86% of remaining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\balikian\\OneDrive - University of Illinois - Urbana\\CodesandScripts\\Git\\wells4hydrogeology\\lib\\classify.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEDROCK_FLAG'] = df[\"INTERPRETATION\"] == 'BEDROCK'\n"
     ]
    }
   ],
   "source": [
    "searchDF = classify.startDefine(df=searchDF, starterms=startTerms, printouts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge specDF and searchDF back together all back in single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData_Terms = classify.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Terms.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export terms that still need to be defined to csv (along with their counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify.export_toBeDefined(downholeData, str(repoDir)+'/out/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify all  data under depth threshold (default is 550') as bedrock (should not be an issue, but just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\balikian\\OneDrive - University of Illinois - Urbana\\CodesandScripts\\Git\\wells4hydrogeology\\lib\\classify.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].mask(df['TOP']>thresh, 3 ,inplace=True) #Add a Classification Flag of 3 (bedrock b/c it's deepter than 550') to all records where the top of the interval is >550'\n",
      "c:\\Users\\balikian\\OneDrive - University of Illinois - Urbana\\CodesandScripts\\Git\\wells4hydrogeology\\lib\\classify.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEDROCK_FLAG'].mask(df['TOP']>thresh, True, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records classified deeper than 550' :79219\n",
      "Records classified deeper than 550', as a percentage of remaining unclassified records: 11.06%\n",
      "Total bedrock records classified: 158438\n",
      "This is now a total of 19.92% of the data classified.\n"
     ]
    }
   ],
   "source": [
    "classifedDF, searchDF = classify.splitDefined(downholeData)\n",
    "searchDF = classify.depthDefine(searchDF, thresh=550, printouts=True)\n",
    "downholeData_Class = classify.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Class.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add '0' flag for data still not classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = classify.fillUnclassified(downholeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2138359\n",
       "0.0     716206\n",
       "4.0     107010\n",
       "3.0      79219\n",
       "Name: CLASS_FLAG, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['CLASS_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add \"Flag\" for target interpratations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lib.readData' has no attribute 'readLithologies'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#dictDir = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\WellDataAutoClassification\\\\SupportingDocs\\\\\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m targetInterpDF \u001b[39m=\u001b[39m readData\u001b[39m.\u001b[39;49mreadLithologies()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'lib.readData' has no attribute 'readLithologies'"
     ]
    }
   ],
   "source": [
    "#dictDir = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\WellDataAutoClassification\\\\SupportingDocs\\\\\"\n",
    "targetInterpDF = readData.readLithologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>THICKNESS</th>\n",
       "      <th>TOP</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>INTERPRETATION</th>\n",
       "      <th>CLASS_FLAG</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120010000300</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>Colchester No. 2 coal,Penn. carb</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120010000300</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>fire clay at</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120010000300</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>interval drift?</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120010000800</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>coal No. 2 possibly at</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120010000800</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>interval</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588272</th>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>red clay, firm</td>\n",
       "      <td>120.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588273</th>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>sand silt &amp; gravel</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588274</th>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>sandy blue clay, soft</td>\n",
       "      <td>85.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588275</th>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>stoney blue clay</td>\n",
       "      <td>18.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588276</th>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>yellow clay</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>CLAY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2588277 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           API_NUMBER   TABLE_NAME                         FORMATION  \\\n",
       "0        120010000300  WFORMATIONS  Colchester No. 2 coal,Penn. carb   \n",
       "1        120010000300  WFORMATIONS                      fire clay at   \n",
       "2        120010000300  WFORMATIONS                   interval drift?   \n",
       "3        120010000800  WFORMATIONS            coal No. 2 possibly at   \n",
       "4        120010000800  WFORMATIONS                          interval   \n",
       "...               ...          ...                               ...   \n",
       "2588272  480590043000  WFORMATIONS                    red clay, firm   \n",
       "2588273  480590043000  WFORMATIONS                sand silt & gravel   \n",
       "2588274  480590043000  WFORMATIONS             sandy blue clay, soft   \n",
       "2588275  480590043000  WFORMATIONS                  stoney blue clay   \n",
       "2588276  480590043000  WFORMATIONS                       yellow clay   \n",
       "\n",
       "         THICKNESS    TOP  BOTTOM INTERPRETATION  CLASS_FLAG TARGET  \n",
       "0              2.0   18.0    20.0            NaN         0.0     -2  \n",
       "1              0.0   20.0    20.0            NaN         0.0     -2  \n",
       "2             18.0    0.0    18.0            NaN         0.0     -2  \n",
       "3              0.0  175.0   175.0            NaN         0.0     -2  \n",
       "4            175.0    0.0   175.0            NaN         0.0     -2  \n",
       "...            ...    ...     ...            ...         ...    ...  \n",
       "2588272      120.0   45.0   165.0            NaN         0.0     -2  \n",
       "2588273      165.0    6.0   171.0            NaN         0.0     -2  \n",
       "2588274       85.0   35.0   120.0            NaN         0.0     -2  \n",
       "2588275       18.0   67.0    85.0            NaN         0.0     -2  \n",
       "2588276        0.0   18.0    18.0           CLAY         1.0      0  \n",
       "\n",
       "[2588277 rows x 9 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData = classify.mergeLithologies(downholedata=downholeData, targinterps=targetInterpDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags used for target classification purposes:\n",
    "- -2: No classification \n",
    "- -1: Classified, not used/not definitive\n",
    "- 0: Classified, not target material\n",
    "- 1: Classified as target material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2    1337019\n",
       "-1     722307\n",
       "0      336977\n",
       "1      191974\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all unique wells in downhole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Unique well APIs\n",
    "wellsDF = classify.getUniqueWells(downholeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort dataset by API Number and Depth of top of record (will be easier to do data analysis with records in the correct order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>THICKNESS</th>\n",
       "      <th>TOP</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>INTERPRETATION</th>\n",
       "      <th>CLASS_FLAG</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>120010000300</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>interval drift?</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>120010000300</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>Colchester No. 2 coal,Penn. carb</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>120010000300</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>fire clay at</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>120010000800</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>interval</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>120010000800</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>coal No. 2 possibly at</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588272</th>\n",
       "      <td>2588273</td>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>sand silt &amp; gravel</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588273</th>\n",
       "      <td>2588276</td>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>yellow clay</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>CLAY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588274</th>\n",
       "      <td>2588274</td>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>sandy blue clay, soft</td>\n",
       "      <td>85.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588275</th>\n",
       "      <td>2588272</td>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>red clay, firm</td>\n",
       "      <td>120.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588276</th>\n",
       "      <td>2588275</td>\n",
       "      <td>480590043000</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>stoney blue clay</td>\n",
       "      <td>18.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2588277 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index    API_NUMBER   TABLE_NAME                         FORMATION  \\\n",
       "0              2  120010000300  WFORMATIONS                   interval drift?   \n",
       "1              0  120010000300  WFORMATIONS  Colchester No. 2 coal,Penn. carb   \n",
       "2              1  120010000300  WFORMATIONS                      fire clay at   \n",
       "3              4  120010000800  WFORMATIONS                          interval   \n",
       "4              3  120010000800  WFORMATIONS            coal No. 2 possibly at   \n",
       "...          ...           ...          ...                               ...   \n",
       "2588272  2588273  480590043000  WFORMATIONS                sand silt & gravel   \n",
       "2588273  2588276  480590043000  WFORMATIONS                       yellow clay   \n",
       "2588274  2588274  480590043000  WFORMATIONS             sandy blue clay, soft   \n",
       "2588275  2588272  480590043000  WFORMATIONS                    red clay, firm   \n",
       "2588276  2588275  480590043000  WFORMATIONS                  stoney blue clay   \n",
       "\n",
       "         THICKNESS    TOP  BOTTOM INTERPRETATION  CLASS_FLAG TARGET  \n",
       "0             18.0    0.0    18.0            NaN         0.0     -2  \n",
       "1              2.0   18.0    20.0            NaN         0.0     -2  \n",
       "2              0.0   20.0    20.0            NaN         0.0     -2  \n",
       "3            175.0    0.0   175.0            NaN         0.0     -2  \n",
       "4              0.0  175.0   175.0            NaN         0.0     -2  \n",
       "...            ...    ...     ...            ...         ...    ...  \n",
       "2588272      165.0    6.0   171.0            NaN         0.0     -2  \n",
       "2588273        0.0   18.0    18.0           CLAY         1.0      0  \n",
       "2588274       85.0   35.0   120.0            NaN         0.0     -2  \n",
       "2588275      120.0   45.0   165.0            NaN         0.0     -2  \n",
       "2588276       18.0   67.0    85.0            NaN         0.0     -2  \n",
       "\n",
       "[2588277 rows x 10 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData_sorted = downholeData.sort_values(['API_NUMBER','TOP'])\n",
    "downholeData_sorted.reset_index(inplace=True)\n",
    "downholeData_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bedrock Depth and Layer Thickness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studyAreaPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESL_StudyArea_5mi.shp\"\n",
    "studyAreaIN, saExtent = mapping.readStudyArea(studyAreaPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in/Define Model Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGridPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\grid_625_raster.tif\"\n",
    "modelGrid = mapping.readModelGrid(saExtent=saExtent, gridpath=modelGridPath, readGrid=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in surface elevation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaceElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ILStateLidar_ClipExtentESL.tif\"\n",
    "surfaceElevGridIN = mapping.readSurfaceGrid(surfaceelevpath=surfaceElevPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in bedrock elevation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrockElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESLBedrock.tif\"\n",
    "bedrockElevGridIN=mapping.readBedrockGrid(bedrockelevpath=bedrockElevPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot just to see them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 2, nrows=1)\n",
    "bedrockElevGridIN.plot(ax=ax[0])\n",
    "surfaceElevGridIN.plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject and align raster grids for surface elevation and bedrock topo (reproject well data too if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrockGrid, surfaceGrid = mapping.alignRasters(bedrockgrid=bedrockElevGridIN, surfacegrid=surfaceElevGridIN, modelgrid=modelGrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(ncols = 2, nrows=1)\n",
    "bedrockGrid.plot(ax=ax[0])\n",
    "surfaceGrid.plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the surface elevation raster and bedrock elevation raster to get depth to bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driftThickGrid, layerThickGrid = mapping.getDriftThick(surface=surfaceGrid, bedrock=bedrockGrid, noLayers=9, plotData=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work here next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sample each well point (headerData) to get layer thickness, surface elevation, and bedrock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO\n",
    "#PRevious code that might be useful\n",
    "#xyzData = pd.read_csv(processDirectory+\"headerData__essCols_elev10mDTM.csv\",usecols = ['API_NUMBER', 'LONGITUDE','LATITUDE', '10mDTM_ft'])\n",
    "#downhole_XYZ = pd.merge(downholeData_sorted, xyzData.set_index('API_NUMBER'), on='API_NUMBER',how='left')\n",
    "#downhole_XYZ['TOP_ELEV_FT'] = downhole_XYZ['10mDTM_ft'] - downhole_XYZ['TOP']\n",
    "#downhole_XYZ['BOT_ELEV_FT'] = downhole_XYZ['10mDTM_ft'] - downhole_XYZ['BOTTOM']\n",
    "#downhole_XYZ['TOP_ELEV_M'] = downhole_XYZ['TOP_ELEV_FT'] * 0.3048\n",
    "#downhole_XYZ['BOT_ELEV_M'] = downhole_XYZ['BOT_ELEV_FT'] * 0.3048\n",
    "#downhole_XYZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate  all layer depths/elevations at all wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate target thickness in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS CELL MAY NEED TO BE UPDATED!!!!!\n",
    "\n",
    "\n",
    "#Define the function to export the result of thickness of target sediments in each layer\n",
    "def Layers_surfacedown(df, layer = 1):\n",
    "    \n",
    "    #Generate Column names based on (looped) integers\n",
    "    topCol = \"ESL_ModelTopoLyrs_\"+str(layer)\n",
    "    if layer != 9: #For all layers except the bottom layer....\n",
    "        botCol = \"ESL_ModelTopoLyrs_\"+str(layer+1) #use the layer below it to \n",
    "    else: #Otherwise, ...\n",
    "        botCol = \"BedrockCorr\" #Use the (corrected) bedrock depth\n",
    "\n",
    "    #Divide records into 4 separate categories for ease of calculation, to be joined back together later  \n",
    "        #Category 1: Well interval starts above layer top, ends within model layer\n",
    "        #Category 2: Well interval is entirely contained withing model layer\n",
    "        #Category 3: Well interval starts within model layer, continues through bottom of model layer\n",
    "        #Category 4: well interval begins and ends on either side of model layer (model layer is contained within well layer)\n",
    "\n",
    "    #records1 = intervals that go through the top of the layer and bottom is within layer\n",
    "    records1 = df.loc[(df['TOP_ELEV_ft'] > df[topCol]) & (df['BOT_ELEV_ft'] > df[botCol]) & (df['BOT_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records1['TARG_THICK'] = pd.DataFrame(np.round((records1.loc[:,topCol]-records1.loc[: , 'BOT_ELEV_ft']) * records1['Target'],3)).copy()\n",
    "    \n",
    "    #records2 = entire interval is within layer\n",
    "    records2 = df.loc[(df['TOP_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] >= df[botCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records2['TARG_THICK'] = pd.DataFrame(np.round((records2.loc[: , 'TOP_ELEV_ft'] - records2.loc[: , 'BOT_ELEV_ft']) * records2['Target'],3)).copy()\n",
    "\n",
    "    #records3 = intervals with top within layer and bottom of interval going through bottom of layer\n",
    "    records3 = df.loc[(df['TOP_ELEV_ft'] > df[botCol]) & (df['BOT_ELEV_ft'] < df[botCol]) & (df['TOP_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records3['TARG_THICK'] = pd.DataFrame(np.round((records3.loc[: , 'TOP_ELEV_ft'] - (records3.loc[:,botCol]))*records3['Target'],3)).copy()\n",
    "\n",
    "    #records4 = interval goes through entire layer\n",
    "    records4 = df.loc[(df['TOP_ELEV_ft'] > df[topCol]) & (df['BOT_ELEV_ft'] < df[botCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records4['TARG_THICK'] = pd.DataFrame(np.round((records4.loc[: , topCol]-records4.loc[: , botCol]) * records4['Target'],3)).copy()\n",
    "\n",
    "    \n",
    "    #Put the four calculated record categories back together into single dataframe\n",
    "    res = records1.append(records2).append(records3).append(records4)\n",
    "    \n",
    "    res_df = res.groupby(['API_NUMBER','LATITUDE','LONGITUDE'],as_index=False).sum()#calculate thickness for each well interval in the layer indicated (e.g., if there are two well intervals from same well in one model layer)\n",
    "\n",
    "    res_df['TARG_THICK_PER'] = pd.DataFrame(np.round(res_df['TARG_THICK']/res_df['LyrThick'],3)) #Calculate thickness as percent of total layer thickness\n",
    "    res_df[\"LAYER\"] = layer #Just to have as part of the output file, include the present layer in the file itself as a separate column\n",
    "    res_df = res_df[['API_NUMBER', 'LATITUDE', 'LONGITUDE', 'TOP', 'BOTTOM','SURF_ELEV_ft', 'TOP_ELEV_ft', 'BOT_ELEV_ft',topCol,botCol,'LyrThick','TARG_THICK', 'TARG_THICK_PER', 'LAYER']].copy() #Format dataframe for output\n",
    "    \n",
    "    return res, res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run that function over all the layers, looping through each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'codeTarget' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mgeophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\AutoClassification_OracleWellData.ipynb Cell 101'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell://isgs-sinkhole/geophysics/Balikian/ISWS_HydroGeo/WellDataAutoClassification/AutoClassification_OracleWellData.ipynb#ch0000129?line=0'>1</a>\u001b[0m \u001b[39m#THIS CELL WILL NEED TO BE UPDATED\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell://isgs-sinkhole/geophysics/Balikian/ISWS_HydroGeo/WellDataAutoClassification/AutoClassification_OracleWellData.ipynb#ch0000129?line=2'>3</a>\u001b[0m outDIR \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39misgs-sinkhole\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mgeophysics\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mBalikian\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mISWS_HydroGeo\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mMetroEast_HydroGeo\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mCodeOutput\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mcodeTarget\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell://isgs-sinkhole/geophysics/Balikian/ISWS_HydroGeo/WellDataAutoClassification/AutoClassification_OracleWellData.ipynb#ch0000129?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m,\u001b[39m10\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell://isgs-sinkhole/geophysics/Balikian/ISWS_HydroGeo/WellDataAutoClassification/AutoClassification_OracleWellData.ipynb#ch0000129?line=5'>6</a>\u001b[0m     res, res_df \u001b[39m=\u001b[39m Layers_surfacedown(df, layer \u001b[39m=\u001b[39m i)\u001b[39m#Run the function defined above for each layer\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'codeTarget' is not defined"
     ]
    }
   ],
   "source": [
    "#THIS CELL WILL NEED TO BE UPDATED\n",
    "\n",
    "outDIR = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\MetroEast_HydroGeo\\\\CodeOutput\\\\\"+codeTarget+\"\\\\\"\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    res, res_df = Layers_surfacedown(df, layer = i)#Run the function defined above for each layer\n",
    "    outputname = codeTargShort+'Lyr'+str(i)+'.csv' #Create a filename based on the layer and target\n",
    "    res_df.to_csv(outDIR+outputname)  #Export the file to csv\n",
    "    #Could also potentially save these to variables for use in following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate thickness values in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each layer and interpolate (use same parameters (?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure rasters align (are co-registered) with grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data \n",
    "downhole_bedrockDepth_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\Downhole_BedrockPicks.csv',index_label=\"ID\")\n",
    "wPermits_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\wPermits_BedrockPicks.csv',index_label=\"ID\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raster38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "eacfbd7833b09ac8bfcf3597a4f98d1ccaa412ac01c00d3f955e77aac9f1d08d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
