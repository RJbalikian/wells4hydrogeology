{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{Fill in with information about this notebook}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np #Data manipulation\n",
    "import pandas as pd #Point data manipulation and organization\n",
    "import xarray as xr #Raster data manipulation and organization\n",
    "\n",
    "import pathlib  #For filepaths, io, etc.\n",
    "import os       #For several system-based commands\n",
    "import datetime #For manipulation of time data, including file creation/modification times\n",
    "import json     #For dictionary io, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt #For plotting and data vizualization\n",
    "import geopandas as gpd         #For organization and manipulation of vector data in space (study area and some data points)\n",
    "import rioxarray as rxr         #For orgnaization and manipulation of raster data\n",
    "from scipy import interpolate\n",
    "import shapely                  #For converting coordinates to point geometry\n",
    "\n",
    "#Scripts with functions made for this specific application\n",
    "import w4h\n",
    "\n",
    "#Variables needed throughout, best to just assign now\n",
    "todayDate, dateSuffix = w4h.getCurrentDate() \n",
    "repoDir = pathlib.Path(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set up filepaths\n",
    "- Read in data from:\n",
    "    - downholeData table (from database)\n",
    "    - headerData table (from database)\n",
    "    - xyzData file (from previously carried out work) (will eventually make this updateable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "Most Recent version of this file is : ISGS_HEADER_2023-01-06.txt\n",
      "Most Recent version of this file is : xyzData.csv\n",
      "Using the following files:\n",
      "\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_HEADER_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\xyzData.csv\n",
      "Downhole Data has 3054409 valid well records.\n",
      "Header Data has 636855 unique wells with valid location information.\n"
     ]
    }
   ],
   "source": [
    "directoryDir = r'\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\\\'[:-1]\n",
    "downholeDataPATH, headerDataPATH, xyzInPATH  = w4h.filesSetup(db_dir=directoryDir)\n",
    "\n",
    "#Functions to read data into dataframes. Also excludes extraneous columns, and drops header data with no location information\n",
    "headerDataIN, downholeDataIN = w4h.readRawTxtData(downholefile=downholeDataPATH, headerfile=headerDataPATH) \n",
    "xyzDataIN = w4h.readXYZData(xyzfile=xyzInPATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define datatypes (doing this during the read in process has presented issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:145: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:,i] = dfIN.iloc[:,i].astype(dtypes[dfIN.iloc[:,i].name])\n"
     ]
    }
   ],
   "source": [
    "#Define datatypes, to read into defineDataTypes() function\n",
    "#Define datatypes of each column of the new dataframes\n",
    "downholeDataIN = w4h.defineDataTypes(downholeDataIN, dtypeFile='downholeDataTypes.txt')\n",
    "headerDataIN = w4h.defineDataTypes(headerDataIN, dtypeFile='headerDataTypes.txt')\n",
    "xyzDataIN = w4h.defineDataTypes(xyzDataIN, dtypeFile='xyzDataTypes.txt')\n",
    "\n",
    "#Make a copy of the data so raw data is preserved while we work with the rest of the data\n",
    "downholeData = downholeDataIN.copy()\n",
    "headerData = headerDataIN.copy()\n",
    "xyzData = xyzDataIN.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import w4h\n",
    "studyAreaPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESL_StudyArea_5mi.shp\"\n",
    "#studyAreaPath = r\"C:\\Users\\balikian\\OneDrive - University of Illinois - Urbana\\Data_OneDrive\\CodesScripts\\MahometBoreholesPolygon.zip\"\n",
    "#studyAreaPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\WellData\\ChicagoInset_Bndy_JFT.shp\"\n",
    "studyAreaIN = w4h.read_study_area(studyAreaPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in/Define Model Grid, surface elevation grid, and bedrock elevation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "readGrids=True\n",
    "\n",
    "if readGrids:\n",
    "    modelGridPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\grid_625_raster.tif\"\n",
    "    surfaceElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ILStateLidar_ClipExtentESL.tif\"\n",
    "    bedrockElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESLBedrock.tif\"\n",
    "\n",
    "    modelGrid = w4h.read_grid(datapath=modelGridPath, grid_type='model', studyArea=studyAreaIN,  read_grid=True, clip2SA=True)#, gridcrs='EPSG:26715', studyAreacrs='EPSG:26715')\n",
    "    surfaceElevGridIN = w4h.read_grid(datapath=surfaceElevPath, grid_type='surface', studyArea=studyAreaIN, use_service=False, clip2SA=True)\n",
    "    bedrockElevGridIN = w4h.read_grid(datapath=bedrockElevPath, grid_type='bedrock', studyArea=studyAreaIN, use_service=False, clip2SA=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in Control points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED CODE HERE FOR ADDING IN CONTROL Wells MANUALLY\n",
    "#Add control headerInfo\n",
    "#Add control description info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Elevation Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract elevation data from consistent elevation dataset for all wells (lidar or other statewide DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, get wells with updated xyz info\n",
    "    #Check first if xyzData needs to be updated with locations (?)\n",
    "    #Check which wells in headerData don't have associated lidar data\n",
    "\n",
    "#statewideLidar =  ow\n",
    "#mapping.rastertoPoints_extract()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge elevation data with headerData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWells = headerData['API_NUMBER'].unique()\n",
    "#xyzData['UniqueWells'] = uniqueWells\n",
    "\n",
    "headerData = w4h.addElevtoHeader(xyzData, headerData)\n",
    "##NEED TO UPDATE THIS TO WORK WITH DATA WITH NO XYZ ELEVATION DATA FROM LIDAR\n",
    "#Change xyz column name to indicate lidar\n",
    "#Use order of preference: lidar, headerData table?/30/10m DEM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's clean up records in the data without the necessary information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip data from outside Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\geopandas\\array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>201.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NE NW NW</td>\n",
       "      <td>591.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.733337</td>\n",
       "      <td>-89.933357</td>\n",
       "      <td>580.419373</td>\n",
       "      <td>POINT (-89.93336 38.73334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930917112</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>537.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.930069</td>\n",
       "      <td>-90.030655</td>\n",
       "      <td>529.981140</td>\n",
       "      <td>POINT (-90.03065 38.93007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930921712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>532.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.941998</td>\n",
       "      <td>-90.045364</td>\n",
       "      <td>530.172913</td>\n",
       "      <td>POINT (-90.04536 38.94200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930921812</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N2 SW NW</td>\n",
       "      <td>526.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.918377</td>\n",
       "      <td>-90.038200</td>\n",
       "      <td>520.954590</td>\n",
       "      <td>POINT (-90.03820 38.91838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930921912</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>507.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.870552</td>\n",
       "      <td>-89.955078</td>\n",
       "      <td>507.976868</td>\n",
       "      <td>POINT (-89.95508 38.87055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>1374073512</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.520279</td>\n",
       "      <td>-90.058060</td>\n",
       "      <td>555.110840</td>\n",
       "      <td>POINT (-90.05806 38.52028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>1374073812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SW NE SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.575832</td>\n",
       "      <td>-90.105003</td>\n",
       "      <td>409.501556</td>\n",
       "      <td>POINT (-90.10500 38.57583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1374073912</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>413.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.528660</td>\n",
       "      <td>-90.244118</td>\n",
       "      <td>410.597595</td>\n",
       "      <td>POINT (-90.24412 38.52866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>427.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.640568</td>\n",
       "      <td>-90.051552</td>\n",
       "      <td>431.323914</td>\n",
       "      <td>POINT (-90.05155 38.64057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1378559712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>562.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Interpolated by C. Abert from the 30 meter DEM</td>\n",
       "      <td>38.635914</td>\n",
       "      <td>-89.938217</td>\n",
       "      <td>565.456055</td>\n",
       "      <td>POINT (-89.93822 38.63591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       13626212        201.0     15.0  2.0    N   5.0    W       3.0   \n",
       "1      930917112         73.0     31.0  6.0    N   8.0    W       3.0   \n",
       "2      930921712         75.0     25.0  6.0    N   9.0    W       3.0   \n",
       "3      930921812        295.0      6.0  5.0    N   8.0    W       3.0   \n",
       "4      930921912       2195.0     23.0  5.0    N   8.0    W       3.0   \n",
       "...          ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "8145  1374073512         52.0     23.0  1.0    N   9.0    W       3.0   \n",
       "8146  1374073812         70.0     33.0  2.0    N   9.0    W       3.0   \n",
       "8147  1374073912         31.0     19.0  1.0    N  10.0    W       3.0   \n",
       "8148  1374794512         61.0     12.0  2.0    N   9.0    W       3.0   \n",
       "8149  1378559712          NaN     12.0  2.0    N   8.0    W       3.0   \n",
       "\n",
       "      QUARTERS  ELEVATION ELEVREF  COUNTY_CODE  \\\n",
       "0     NE NW NW      591.0     nan         27.0   \n",
       "1          nan      537.0      GL        119.0   \n",
       "2           SE      532.0      GL        119.0   \n",
       "3     N2 SW NW      526.0      GL        119.0   \n",
       "4           SE      507.0      GL        119.0   \n",
       "...        ...        ...     ...          ...   \n",
       "8145       nan        NaN     nan        163.0   \n",
       "8146  SW NE SW        NaN     nan        163.0   \n",
       "8147       nan      413.0      DM        163.0   \n",
       "8148        NW      427.0      GL        163.0   \n",
       "8149       nan      562.0      DM        163.0   \n",
       "\n",
       "                                          ELEVSOURCE   LATITUDE  LONGITUDE  \\\n",
       "0                                                nan  38.733337 -89.933357   \n",
       "1                                                nan  38.930069 -90.030655   \n",
       "2                                                nan  38.941998 -90.045364   \n",
       "3                                                nan  38.918377 -90.038200   \n",
       "4                                                nan  38.870552 -89.955078   \n",
       "...                                              ...        ...        ...   \n",
       "8145                                             nan  38.520279 -90.058060   \n",
       "8146                                             nan  38.575832 -90.105003   \n",
       "8147                                             nan  38.528660 -90.244118   \n",
       "8148                                             nan  38.640568 -90.051552   \n",
       "8149  Interpolated by C. Abert from the 30 meter DEM  38.635914 -89.938217   \n",
       "\n",
       "         ELEV_FT                    geometry  \n",
       "0     580.419373  POINT (-89.93336 38.73334)  \n",
       "1     529.981140  POINT (-90.03065 38.93007)  \n",
       "2     530.172913  POINT (-90.04536 38.94200)  \n",
       "3     520.954590  POINT (-90.03820 38.91838)  \n",
       "4     507.976868  POINT (-89.95508 38.87055)  \n",
       "...          ...                         ...  \n",
       "8145  555.110840  POINT (-90.05806 38.52028)  \n",
       "8146  409.501556  POINT (-90.10500 38.57583)  \n",
       "8147  410.597595  POINT (-90.24412 38.52866)  \n",
       "8148  431.323914  POINT (-90.05155 38.64057)  \n",
       "8149  565.456055  POINT (-89.93822 38.63591)  \n",
       "\n",
       "[8150 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData = w4h.coords2Geometry(df=headerData, xCol='LONGITUDE', yCol='LATITUDE', crs='EPSG:4269')\n",
    "#headerData['geometry']=headerData['GEOMETRY'].copy() #old code\n",
    "headerDataClip = w4h.clipHeader2StudyArea(studyarea=studyAreaIN, headerdata=headerData, headerCRS='EPSG:4269')\n",
    "headerData = headerDataClip.copy()\n",
    "headerData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove data from downholeData table that does not have location information (Since we would not know where to put it anyway)\n",
    "\n",
    "This should also essentially \"clip\" the downholeData to the study area, since only study area wells remain in headerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2998078 records removed without location information.\n",
      "56331 wells remain from 7188 located wells in study area.\n"
     ]
    }
   ],
   "source": [
    "downholeData = w4h.removeNonlocatedData(downholeData, headerData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove headerData rows without surface elevation information (this currently clips data from outside Illinois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>201.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NE NW NW</td>\n",
       "      <td>591.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.733337</td>\n",
       "      <td>-89.933357</td>\n",
       "      <td>580.419373</td>\n",
       "      <td>POINT (-89.93336 38.73334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930917112</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>537.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.930069</td>\n",
       "      <td>-90.030655</td>\n",
       "      <td>529.981140</td>\n",
       "      <td>POINT (-90.03065 38.93007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930921712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>532.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.941998</td>\n",
       "      <td>-90.045364</td>\n",
       "      <td>530.172913</td>\n",
       "      <td>POINT (-90.04536 38.94200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930921812</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N2 SW NW</td>\n",
       "      <td>526.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.918377</td>\n",
       "      <td>-90.038200</td>\n",
       "      <td>520.954590</td>\n",
       "      <td>POINT (-90.03820 38.91838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930921912</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>507.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.870552</td>\n",
       "      <td>-89.955078</td>\n",
       "      <td>507.976868</td>\n",
       "      <td>POINT (-89.95508 38.87055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>1374073512</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.520279</td>\n",
       "      <td>-90.058060</td>\n",
       "      <td>555.110840</td>\n",
       "      <td>POINT (-90.05806 38.52028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>1374073812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SW NE SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.575832</td>\n",
       "      <td>-90.105003</td>\n",
       "      <td>409.501556</td>\n",
       "      <td>POINT (-90.10500 38.57583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1374073912</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>413.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.528660</td>\n",
       "      <td>-90.244118</td>\n",
       "      <td>410.597595</td>\n",
       "      <td>POINT (-90.24412 38.52866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>427.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.640568</td>\n",
       "      <td>-90.051552</td>\n",
       "      <td>431.323914</td>\n",
       "      <td>POINT (-90.05155 38.64057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1378559712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>562.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Interpolated by C. Abert from the 30 meter DEM</td>\n",
       "      <td>38.635914</td>\n",
       "      <td>-89.938217</td>\n",
       "      <td>565.456055</td>\n",
       "      <td>POINT (-89.93822 38.63591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       13626212        201.0     15.0  2.0    N   5.0    W       3.0   \n",
       "1      930917112         73.0     31.0  6.0    N   8.0    W       3.0   \n",
       "2      930921712         75.0     25.0  6.0    N   9.0    W       3.0   \n",
       "3      930921812        295.0      6.0  5.0    N   8.0    W       3.0   \n",
       "4      930921912       2195.0     23.0  5.0    N   8.0    W       3.0   \n",
       "...          ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "8145  1374073512         52.0     23.0  1.0    N   9.0    W       3.0   \n",
       "8146  1374073812         70.0     33.0  2.0    N   9.0    W       3.0   \n",
       "8147  1374073912         31.0     19.0  1.0    N  10.0    W       3.0   \n",
       "8148  1374794512         61.0     12.0  2.0    N   9.0    W       3.0   \n",
       "8149  1378559712          NaN     12.0  2.0    N   8.0    W       3.0   \n",
       "\n",
       "      QUARTERS  ELEVATION ELEVREF  COUNTY_CODE  \\\n",
       "0     NE NW NW      591.0     nan         27.0   \n",
       "1          nan      537.0      GL        119.0   \n",
       "2           SE      532.0      GL        119.0   \n",
       "3     N2 SW NW      526.0      GL        119.0   \n",
       "4           SE      507.0      GL        119.0   \n",
       "...        ...        ...     ...          ...   \n",
       "8145       nan        NaN     nan        163.0   \n",
       "8146  SW NE SW        NaN     nan        163.0   \n",
       "8147       nan      413.0      DM        163.0   \n",
       "8148        NW      427.0      GL        163.0   \n",
       "8149       nan      562.0      DM        163.0   \n",
       "\n",
       "                                          ELEVSOURCE   LATITUDE  LONGITUDE  \\\n",
       "0                                                nan  38.733337 -89.933357   \n",
       "1                                                nan  38.930069 -90.030655   \n",
       "2                                                nan  38.941998 -90.045364   \n",
       "3                                                nan  38.918377 -90.038200   \n",
       "4                                                nan  38.870552 -89.955078   \n",
       "...                                              ...        ...        ...   \n",
       "8145                                             nan  38.520279 -90.058060   \n",
       "8146                                             nan  38.575832 -90.105003   \n",
       "8147                                             nan  38.528660 -90.244118   \n",
       "8148                                             nan  38.640568 -90.051552   \n",
       "8149  Interpolated by C. Abert from the 30 meter DEM  38.635914 -89.938217   \n",
       "\n",
       "         ELEV_FT                    geometry  \n",
       "0     580.419373  POINT (-89.93336 38.73334)  \n",
       "1     529.981140  POINT (-90.03065 38.93007)  \n",
       "2     530.172913  POINT (-90.04536 38.94200)  \n",
       "3     520.954590  POINT (-90.03820 38.91838)  \n",
       "4     507.976868  POINT (-89.95508 38.87055)  \n",
       "...          ...                         ...  \n",
       "8145  555.110840  POINT (-90.05806 38.52028)  \n",
       "8146  409.501556  POINT (-90.10500 38.57583)  \n",
       "8147  410.597595  POINT (-90.24412 38.52866)  \n",
       "8148  431.323914  POINT (-90.05155 38.64057)  \n",
       "8149  565.456055  POINT (-89.93822 38.63591)  \n",
       "\n",
       "[8150 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData = headerDataClip.copy()\n",
    "headerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well records removed: 0\n",
      "Number of rows before dropping those without surface elevation information: 8150\n",
      "Number of rows after dropping those without surface elevation information: 8150\n"
     ]
    }
   ],
   "source": [
    "headerData_cleaned = w4h.removenotopo(df=headerData, printouts=True)\n",
    "headerData = headerData_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows from downholeData with no depth information and where depth information is obviously bad (i.e., top depth > bottom depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without record depth information: 56331\n",
      "Number of rows after dropping those without record depth information: 55747\n",
      "Number of well records without formation information deleted: 584\n",
      "Number of rows before dropping those with obviously bad depth information: 56331\n",
      "Number of rows after dropping those with obviously bad depth information: 55725\n",
      "Well records deleted: 606\n"
     ]
    }
   ],
   "source": [
    "#Drop records with no depth information\n",
    "donwholeData = w4h.dropnodepth(downholeData, printouts=True)\n",
    "#Drop records with bad depth information (i.e., top depth > bottom depth) (Also calculates thickness of each record)\n",
    "donwholeData = w4h.dropbaddepth(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records with no FORMATION information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without FORMATION information: 56331\n",
      "Number of rows after dropping those without FORMATION information: 56331\n",
      "Well records deleted: 0\n"
     ]
    }
   ],
   "source": [
    "downholeData = w4h.dropnoformation(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to export this data, to have record of cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>THICKNESS</th>\n",
       "      <th>TOP</th>\n",
       "      <th>BOTTOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>931135312</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>hard gray sandy clayey silt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>931135312</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>hard mottled clayey silt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>931135312</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>stiff black clayey silt</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5776</th>\n",
       "      <td>931135312</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>stiff dark gray silt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>931135312</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>stiff gray clayey silt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56326</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>brown silt (levee fill)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56327</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray clay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56328</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray clay (with thin sand streaks)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56329</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray, fine sand</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56330</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray, mottled with brown clay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17950 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       API_NUMBER     TABLE_NAME                           FORMATION  \\\n",
       "5773    931135312  HWYBRIDGE_LOG         hard gray sandy clayey silt   \n",
       "5774    931135312  HWYBRIDGE_LOG            hard mottled clayey silt   \n",
       "5775    931135312  HWYBRIDGE_LOG             stiff black clayey silt   \n",
       "5776    931135312  HWYBRIDGE_LOG                stiff dark gray silt   \n",
       "5777    931135312  HWYBRIDGE_LOG              stiff gray clayey silt   \n",
       "...           ...            ...                                 ...   \n",
       "56326  1374794512  HWYBRIDGE_LOG             brown silt (levee fill)   \n",
       "56327  1374794512  HWYBRIDGE_LOG                           gray clay   \n",
       "56328  1374794512  HWYBRIDGE_LOG  gray clay (with thin sand streaks)   \n",
       "56329  1374794512  HWYBRIDGE_LOG                     gray, fine sand   \n",
       "56330  1374794512  HWYBRIDGE_LOG       gray, mottled with brown clay   \n",
       "\n",
       "       THICKNESS   TOP  BOTTOM  \n",
       "5773         5.0  34.0    39.0  \n",
       "5774         2.0   7.0     9.0  \n",
       "5775         2.5   0.0     2.5  \n",
       "5776         5.0  11.5    16.5  \n",
       "5777         3.0  21.0    24.0  \n",
       "...          ...   ...     ...  \n",
       "56326        8.0   0.0     8.0  \n",
       "56327        5.0  11.5    16.5  \n",
       "56328        7.5  26.5    34.0  \n",
       "56329        5.0  39.0    44.0  \n",
       "56330        5.0  16.5    21.5  \n",
       "\n",
       "[17950 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData = downholeData[downholeData['TABLE_NAME'] == 'HWYBRIDGE_LOG']\n",
    "downholeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData.reset_index(inplace=True,drop=True)\n",
    "headerData.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#downholeData.to_csv(str(repoDir)+'/out/downholeData_cleaned'+dateSuffix+'.csv',index_label='ID')\n",
    "#headerData.to_csv(str(repoDir)+'/out/headerData_cleaned'+dateSuffix+'.csv',index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outData = pd.merge(left = downholeData, right = headerData, on='API_NUMBER')\n",
    "#downholeData = outData.copy()\n",
    "downholeDataCLEANED = downholeData.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following flags are used to mark the classification method:\n",
    "- 0: Not classified\n",
    "- 1: Specific Search Term Match\n",
    "- 2: [Not defined]\n",
    "- 3: Bedrock classification for obvious bedrock\n",
    "- 4: Wildcard match (startTerm) - no context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : SearchTerms-Specific_2022-11-16_essCols.csv\n",
      "Most Recent version of this file is : SearchTerms-Start.csv\n"
     ]
    }
   ],
   "source": [
    "#Read in dictionary files for downhole data\n",
    "specTermsPATH, startTermsPATH = w4h.searchTermFilePaths(dictdir=str(repoDir)+'/resources/', specStartPattern='*SearchTerms-Specific*', startGlobPattern = '*SearchTerms-Start*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:210: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  d.iloc[:,i] = d.iloc[:,i].astype(dict_termDtypes[d.iloc[:,i].name])\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:210: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  d.iloc[:,i] = d.iloc[:,i].astype(dict_termDtypes[d.iloc[:,i].name])\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:210: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  d.iloc[:,i] = d.iloc[:,i].astype(dict_termDtypes[d.iloc[:,i].name])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>INTERPRETATION</th>\n",
       "      <th>CLASS_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sand, fine gr</td>\n",
       "      <td>SAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sand, fine-large gr</td>\n",
       "      <td>SAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sand, some large gr</td>\n",
       "      <td>SAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toop soil</td>\n",
       "      <td>SOIL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grav in muck</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184290</th>\n",
       "      <td>CRS SAND GRAV AND ROCKS</td>\n",
       "      <td>SAND AND GRAVEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184291</th>\n",
       "      <td>CRS SAND GRAV BOULDERS</td>\n",
       "      <td>SAND AND GRAVEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184292</th>\n",
       "      <td>CRS SAND GRAV CLEAN</td>\n",
       "      <td>SAND AND GRAVEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184293</th>\n",
       "      <td>carbonaceous shale</td>\n",
       "      <td>BEDROCK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184294</th>\n",
       "      <td>unclassified</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184295 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      FORMATION   INTERPRETATION  CLASS_FLAG\n",
       "0                 sand, fine gr             SAND           1\n",
       "1           sand, fine-large gr             SAND           1\n",
       "2           sand, some large gr             SAND           1\n",
       "3                     toop soil             SOIL           1\n",
       "4                  grav in muck           GRAVEL           1\n",
       "...                         ...              ...         ...\n",
       "184290  CRS SAND GRAV AND ROCKS  SAND AND GRAVEL           1\n",
       "184291   CRS SAND GRAV BOULDERS  SAND AND GRAVEL           1\n",
       "184292      CRS SAND GRAV CLEAN  SAND AND GRAVEL           1\n",
       "184293       carbonaceous shale          BEDROCK           1\n",
       "184294             unclassified          UNKNOWN           1\n",
       "\n",
       "[184295 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specTerms = w4h.read_dictionary_terms(dict_file=specTermsPATH)\n",
    "startTerms = w4h.read_dictionary_terms(dict_file=startTermsPATH)\n",
    "oldDictPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\WellData\\Dictionaries\\DICTIONARY_Updated-06-2018.csv\"\n",
    "oldDict = w4h.read_dictionary_terms(dict_file=oldDictPath, cols={'DESCRIPTION':'FORMATION', 'LITHOLOGY':'INTERPRETATION'}, class_flag=1)\n",
    "specTerms = pd.concat([specTerms, oldDict])\n",
    "specTerms.drop_duplicates(subset='FORMATION', inplace=True)\n",
    "specTerms.reset_index(inplace=True, drop=True)\n",
    "specTerms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the dataframes--for the specific search terms, this is the same as classifying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               hard gray sandy clayey silt\n",
      "1                  hard mottled clayey silt\n",
      "2                   stiff black clayey silt\n",
      "3                      stiff dark gray silt\n",
      "4                    stiff gray clayey silt\n",
      "                        ...                \n",
      "17945               brown silt (levee fill)\n",
      "17946                             gray clay\n",
      "17947    gray clay (with thin sand streaks)\n",
      "17948                       gray, fine sand\n",
      "17949         gray, mottled with brown clay\n",
      "Name: FORMATION, Length: 17950, dtype: object\n",
      "0               hard gray sandy clayey silt\n",
      "1                  hard mottled clayey silt\n",
      "2                   stiff black clayey silt\n",
      "3                      stiff dark gray silt\n",
      "4                    stiff gray clayey silt\n",
      "                        ...                \n",
      "17945               brown silt (levee fill)\n",
      "17946                             gray clay\n",
      "17947    gray clay (with thin sand streaks)\n",
      "17948                       gray, fine sand\n",
      "17949         gray, mottled with brown clay\n",
      "Name: FORMATION, Length: 17950, dtype: object\n",
      "0               hard gray sandy clayey silt\n",
      "1                  hard mottled clayey silt\n",
      "2                   stiff black clayey silt\n",
      "3                      stiff dark gray silt\n",
      "4                    stiff gray clayey silt\n",
      "                        ...                \n",
      "17945               brown silt (levee fill)\n",
      "17946                             gray clay\n",
      "17947    gray clay (with thin sand streaks)\n",
      "17948                       gray, fine sand\n",
      "17949         gray, mottled with brown clay\n",
      "Name: FORMATION, Length: 17950, dtype: object\n",
      "Records Classified with full search term: 6844\n",
      "Records Classified with full search term: 38.13% of data\n"
     ]
    }
   ],
   "source": [
    "downholeData= downholeDataCLEANED.copy()\n",
    "downholeData_spec = w4h.specificDefine(downholeData, specTerms, printouts=True)\n",
    "downholeData = downholeData_spec.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with only the records already classified (using the specific search terms in this case, classifiedDF), and one that still needs to be searched (searchDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11106"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifedDF, searchDF = w4h.splitDefined(downholeData)\n",
    "searchDF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do the classification routine on the searchDF database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Term process should be done by 14:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].where(~df['FORMATION'].str.startswith(s,na=False),4,inplace=True)\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['INTERPRETATION'].where(~df['FORMATION'].str.startswith(s,na=False),starterms.loc[i,'INTERPRETATION'],inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records classified with start search term: 558\n",
      "Records classified with start search term: 5.02% of remaining data\n"
     ]
    }
   ],
   "source": [
    "searchDF = w4h.startDefine(df=searchDF, starterms=startTerms, printouts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge specDF and searchDF back together all back in single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData_Terms = w4h.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Terms.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    6844\n",
       "4.0     558\n",
       "Name: CLASS_FLAG, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = downholeData.CLASS_FLAG.value_counts()\n",
    "downholeData.CLASS_FLAG.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export terms that still need to be defined to csv (along with their counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The outdir should be changed so it doesn't clog up the repository\n",
    "#classify.export_toBeDefined(df=downholeData, outdir=str(repoDir)+'/out/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify all  data under depth threshold (default is 550') as bedrock (should not be an issue, but just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records classified as bedrock that were deeper than 550': 0\n",
      "This represents 0.0% of the unclassified data in this dataframe.\n"
     ]
    }
   ],
   "source": [
    "classifedDF, searchDF = w4h.splitDefined(downholeData)\n",
    "searchDF = w4h.depthDefine(searchDF, thresh=550, printouts=True)\n",
    "downholeData_Class = w4h.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Class.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add '0' flag for data still not classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = w4h.fillUnclassified(downholeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    10548\n",
       "1.0     6844\n",
       "4.0      558\n",
       "Name: CLASS_FLAG, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['CLASS_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData.to_csv(r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\WellData\\out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add \"Flag\" for target interpratations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictDir = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\WellDataAutoClassification\\\\SupportingDocs\\\\\"\n",
    "targetInterpDF = w4h.readLithologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = w4h.mergeLithologies(downholedata=downholeData, targinterps=targetInterpDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags used for target classification purposes:\n",
    "- -2: No classification \n",
    "- -1: Classified, not used/not definitive\n",
    "- 0: Classified, not target material\n",
    "- 1: Classified as target material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5171\n",
       "1.0    2220\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all unique wells in downhole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique wells in downholeData: 2006\n"
     ]
    }
   ],
   "source": [
    "#Get Unique well APIs\n",
    "wellsDF = w4h.getUniqueWells(downholeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort dataset by API Number and Depth of top of record (will be easier to do data analysis with records in the correct order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make this into a function?\n",
    "downholeData_sorted = downholeData.sort_values(['API_NUMBER','TOP'])\n",
    "downholeData_sorted.reset_index(inplace=True, drop=True)\n",
    "downholeData_sorted = downholeData_sorted[pd.notna(downholeData_sorted[\"INTERPRETATION\"])]\n",
    "donwholeData.reset_index(inplace=True, drop=True)\n",
    "donwholeData = downholeData_sorted.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bedrock Depth and Layer Thickness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot just to see them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject and align raster grids for surface elevation and bedrock topo (reproject well data too if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inGrids = [bedrockElevGridIN, surfaceElevGridIN]\n",
    "bedrockGrid, surfaceGrid = w4h.alignRasters(unalignedGrids=inGrids, modelgrid=modelGrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(ncols = 2, nrows=1)\n",
    "bedrockGrid.plot(ax=ax[0])\n",
    "surfaceGrid.plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the surface elevation raster and bedrock elevation raster to get depth to bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driftThickGrid, layerThickGrid = w4h.get_drift_thick(surface=surfaceGrid, bedrock=bedrockGrid, noLayers=9, plotData=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sample each well point (headerData) to get layer thickness, surface elevation, and bedrock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEDROCK_ELEV_FT sampling should be done by 14:29\n",
      "SURFACE_ELEV_FT sampling should be done by 14:29\n",
      "BEDROCK_DEPTH_FT sampling should be done by 14:29\n",
      "LAYER_THICK_FT sampling should be done by 14:29\n"
     ]
    }
   ],
   "source": [
    "headerData = w4h.sample_raster_points(raster=bedrockGrid, ptDF=headerData, newColName='BEDROCK_ELEV_FT')\n",
    "#headerData['BEDROCK_ELEV_M'] = headerData['BEDROCK_ELEV_FT']* 0.3048\n",
    "\n",
    "headerData = w4h.sample_raster_points(raster=surfaceGrid, ptDF=headerData, newColName='SURFACE_ELEV_FT')\n",
    "#headerData['SURFACE_ELEV_M'] = headerData['SURFACE_ELEV_FT']* 0.3048\n",
    "\n",
    "headerData = w4h.sample_raster_points(raster=driftThickGrid, ptDF=headerData, newColName='BEDROCK_DEPTH_FT')\n",
    "#headerData['BEDROCK_DEPTH_M'] = headerData['BEDROCK_DEPTH_FT']* 0.3048\n",
    "\n",
    "headerData = w4h.sample_raster_points(raster=layerThickGrid, ptDF=headerData, newColName='LAYER_THICK_FT')\n",
    "#headerData['LAYER_THICK_M'] = headerData['LAYER_THICK_FT']* 0.3048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate  all layer depths/elevations at all wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerData = w4h.get_layer_depths(well_metadata=headerData, no_layers=9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Data from downhole and headerData to enable further calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = downholeData_sorted.copy()\n",
    "downholeData_layerInfo = w4h.merge_tables(data_df=downholeData, header_df=headerData,on='API_NUMBER', how='inner', auto_pick_cols=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the top and bottom elevation for each well record in downholeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = downholeData_layerInfo.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate target thickness in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5171\n",
       "1.0    2220\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donwholeData['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf = w4h.layer_target_thick(downholeData_layerInfo, layers=9, outfile_prefix='CoarseFine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate thickness values in each layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each layer and interpolate (use same parameters (?))\n",
    "\n",
    "Ensure rasters align (are co-registered) with grid\n",
    "\n",
    "Export to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_data = w4h.layer_interp(points=resdf, layers=9, grid=modelGrid, method='lin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_layers(layer_data, filepath, format):\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data \n",
    "downhole_bedrockDepth_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\Downhole_BedrockPicks.csv',index_label=\"ID\")\n",
    "wPermits_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\wPermits_BedrockPicks.csv',index_label=\"ID\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "1eab39f8790fa4ef06ab4ebada9c1405c2ef16219adfedb21e90bf3fb356ecb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
