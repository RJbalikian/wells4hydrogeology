{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{Fill in with information about this notebook}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np #Data manipulation\n",
    "import pandas as pd #Point data manipulation and organization\n",
    "import xarray as xr #Raster data manipulation and organization\n",
    "\n",
    "import pathlib  #For filepaths, io, etc.\n",
    "import os       #For several system-based commands\n",
    "import datetime #For manipulation of time data, including file creation/modification times\n",
    "import json     #For dictionary io, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt #For plotting and data vizualization\n",
    "import geopandas as gpd         #For organization and manipulation of vector data in space (study area and some data points)\n",
    "import rioxarray as rxr         #For orgnaization and manipulation of raster data\n",
    "import shapely                  #For converting coordinates to point geometry\n",
    "\n",
    "#Scripts with functions made for this specific application\n",
    "from lib import readData    #For reading data \n",
    "from lib import mapping     #For geospatial data manipulation\n",
    "from lib import cleanData   #For cleaning well data\n",
    "from lib import classify    #For classifying well data\n",
    "from lib import exportData  #For exporting data\n",
    "from lib import layers\n",
    "\n",
    "#Variables needed throughout, best to just assign now\n",
    "todayDate, dateSuffix = readData.getCurrentDate() \n",
    "repoDir = pathlib.Path(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set up filepaths\n",
    "- Read in data from:\n",
    "    - downholeData table (from database)\n",
    "    - headerData table (from database)\n",
    "    - xyzData file (from previously carried out work) (will eventually make this updateable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "Most Recent version of this file is : ISGS_HEADER_2023-01-06.txt\n",
      "Most Recent version of this file is : xyzData.csv\n",
      "Using the following files:\n",
      "\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_HEADER_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\xyzData.csv\n",
      "Downhole Data has 3054409 valid well records.\n",
      "Header Data has 636855 unique wells with valid location information.\n"
     ]
    }
   ],
   "source": [
    "directoryDir = r'\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\\\'[:-1]\n",
    "downholeDataPATH, headerDataPATH, xyzInPATH  = readData.filesSetup(db_dir=directoryDir)\n",
    "\n",
    "#Functions to read data into dataframes. Also excludes extraneous columns, and drops header data with no location information\n",
    "headerDataIN, downholeDataIN = readData.readRawTxtData(downholefile=downholeDataPATH, headerfile=headerDataPATH) \n",
    "xyzDataIN = readData.readXYZData(xyzfile=xyzInPATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define datatypes (doing this during the read in process has presented issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\readData.py:125: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:,i] = dfIN.iloc[:,i].astype(dtypes[dfIN.iloc[:,i].name])\n"
     ]
    }
   ],
   "source": [
    "#Define datatypes, to read into defineDataTypes() function\n",
    "##EVENTUALLY, MAKE THIS A FILE IN THE RES FOLDER TO READ IN\n",
    "#downholeDataDTYPES = {'ID':np.uint32, \"API_NUMBER\":np.uint64,\"TABLE_NAME\":str,\"WHO\":str,\"INTERPRET_DATE\":str,\"FORMATION\":str,\"THICKNESS\":np.float64,\"TOP\":np.float64,\"BOTTOM\":np.float64}\n",
    "#headerDataDTYPES = {'ID':np.uint32,'API_NUMBER':np.uint64,\"TDFORMATION\":str,\"PRODFORM\":str,\"TOTAL_DEPTH\":np.float64,\"SECTION\":np.float64,\"TWP\":np.float64,\"TDIR\":str,\"RNG\":np.float64,\"RDIR\":str,\"MERIDIAN\":np.float64,\"FARM_NAME\":str,\"NSFOOT\":np.float64,\"NSDIR\":str,\"EWFOOT\":np.float64,\"EWDIR\":str,\"QUARTERS\":str,\"ELEVATION\":np.float64,\"ELEVREF\":str,\"COMP_DATE\":str,\"STATUS\":str,\"FARM_NUM\":str,\"COUNTY_CODE\":np.float64,\"PERMIT_NUMBER\":str,\"COMPANY_NAME\":str,\"COMPANY_CODE\":str,\"PERMIT_DATE\":str,\"CORNER\":str,\"LATITUDE\":np.float64,\"LONGITUDE\":np.float64,\"ENTERED_BY\":str,\"UPDDATE\":str,\"ELEVSOURCE\":str, \"ELEV_FT\":np.float64}\n",
    "#xyzDataDTYPES = {'ID':np.uint64, 'API_NUMBER':np.uint64, \"LATITUDE\":np.float64, \"LONGITUDE\":np.float64, \"ELEV_FT\":np.float64}\n",
    "\n",
    "#Define datatypes of each column of the new dataframes\n",
    "downholeDataIN = readData.defineDataTypes(downholeDataIN, dtypeFile='downholeDataTypes.txt')\n",
    "headerDataIN = readData.defineDataTypes(headerDataIN, dtypeFile='headerDataTypes.txt')\n",
    "xyzDataIN = readData.defineDataTypes(xyzDataIN, dtypeFile='xyzDataTypes.txt')\n",
    "\n",
    "#Make a copy of the data so raw data is preserved while we work with the rest of the data\n",
    "downholeData = downholeDataIN.copy()\n",
    "headerData = headerDataIN.copy()\n",
    "xyzData = xyzDataIN.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in Control points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED CODE HERE FOR ADDING IN CONTROL Wells MANUALLY\n",
    "#Add control headerInfo\n",
    "#Add control description info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Elevation Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract elevation data from consistent elevation dataset for all wells (lidar or other statewide DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, get wells with updated xyz info\n",
    "    #Check first if xyzData needs to be updated with locations (?)\n",
    "    #Check which wells in headerData don't have associated lidar data\n",
    "\n",
    "#statewideLidar =  ow\n",
    "#mapping.rastertoPoints_extract()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge elevation data with headerData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWells = headerData['API_NUMBER'].unique()\n",
    "#xyzData['UniqueWells'] = uniqueWells\n",
    "\n",
    "headerData = mapping.addElevtoHeader(xyzData, headerData)\n",
    "##NEED TO UPDATE THIS TO WORK WITH DATA WITH NO XYZ ELEVATION DATA FROM LIDAR\n",
    "#Change xyz column name to indicate lidar\n",
    "#Use order of preference: lidar, headerData table?/30/10m DEM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's clean up records in the data without the necessary information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip data from outside Study Area"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "studyAreaPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESL_StudyArea_5mi.shp\"\n",
    "studyAreaIN, saExtent = mapping.readStudyArea(studyAreaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\geopandas\\array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>201.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NE NW NW</td>\n",
       "      <td>591.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.733337</td>\n",
       "      <td>-89.933357</td>\n",
       "      <td>580.419373</td>\n",
       "      <td>POINT (-89.93336 38.73334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930917112</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>537.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.930069</td>\n",
       "      <td>-90.030655</td>\n",
       "      <td>529.981140</td>\n",
       "      <td>POINT (-90.03065 38.93007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930921712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>532.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.941998</td>\n",
       "      <td>-90.045364</td>\n",
       "      <td>530.172913</td>\n",
       "      <td>POINT (-90.04536 38.94200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930921812</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N2 SW NW</td>\n",
       "      <td>526.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.918377</td>\n",
       "      <td>-90.038200</td>\n",
       "      <td>520.954590</td>\n",
       "      <td>POINT (-90.03820 38.91838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930921912</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>507.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.870552</td>\n",
       "      <td>-89.955078</td>\n",
       "      <td>507.976868</td>\n",
       "      <td>POINT (-89.95508 38.87055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>1374073512</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.520279</td>\n",
       "      <td>-90.058060</td>\n",
       "      <td>555.110840</td>\n",
       "      <td>POINT (-90.05806 38.52028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>1374073812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SW NE SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.575832</td>\n",
       "      <td>-90.105003</td>\n",
       "      <td>409.501556</td>\n",
       "      <td>POINT (-90.10500 38.57583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1374073912</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>413.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.528660</td>\n",
       "      <td>-90.244118</td>\n",
       "      <td>410.597595</td>\n",
       "      <td>POINT (-90.24412 38.52866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>427.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.640568</td>\n",
       "      <td>-90.051552</td>\n",
       "      <td>431.323914</td>\n",
       "      <td>POINT (-90.05155 38.64057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1378559712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>562.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Interpolated by C. Abert from the 30 meter DEM</td>\n",
       "      <td>38.635914</td>\n",
       "      <td>-89.938217</td>\n",
       "      <td>565.456055</td>\n",
       "      <td>POINT (-89.93822 38.63591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       13626212        201.0     15.0  2.0    N   5.0    W       3.0   \n",
       "1      930917112         73.0     31.0  6.0    N   8.0    W       3.0   \n",
       "2      930921712         75.0     25.0  6.0    N   9.0    W       3.0   \n",
       "3      930921812        295.0      6.0  5.0    N   8.0    W       3.0   \n",
       "4      930921912       2195.0     23.0  5.0    N   8.0    W       3.0   \n",
       "...          ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "8145  1374073512         52.0     23.0  1.0    N   9.0    W       3.0   \n",
       "8146  1374073812         70.0     33.0  2.0    N   9.0    W       3.0   \n",
       "8147  1374073912         31.0     19.0  1.0    N  10.0    W       3.0   \n",
       "8148  1374794512         61.0     12.0  2.0    N   9.0    W       3.0   \n",
       "8149  1378559712          NaN     12.0  2.0    N   8.0    W       3.0   \n",
       "\n",
       "      QUARTERS  ELEVATION ELEVREF  COUNTY_CODE  \\\n",
       "0     NE NW NW      591.0     nan         27.0   \n",
       "1          nan      537.0      GL        119.0   \n",
       "2           SE      532.0      GL        119.0   \n",
       "3     N2 SW NW      526.0      GL        119.0   \n",
       "4           SE      507.0      GL        119.0   \n",
       "...        ...        ...     ...          ...   \n",
       "8145       nan        NaN     nan        163.0   \n",
       "8146  SW NE SW        NaN     nan        163.0   \n",
       "8147       nan      413.0      DM        163.0   \n",
       "8148        NW      427.0      GL        163.0   \n",
       "8149       nan      562.0      DM        163.0   \n",
       "\n",
       "                                          ELEVSOURCE   LATITUDE  LONGITUDE  \\\n",
       "0                                                nan  38.733337 -89.933357   \n",
       "1                                                nan  38.930069 -90.030655   \n",
       "2                                                nan  38.941998 -90.045364   \n",
       "3                                                nan  38.918377 -90.038200   \n",
       "4                                                nan  38.870552 -89.955078   \n",
       "...                                              ...        ...        ...   \n",
       "8145                                             nan  38.520279 -90.058060   \n",
       "8146                                             nan  38.575832 -90.105003   \n",
       "8147                                             nan  38.528660 -90.244118   \n",
       "8148                                             nan  38.640568 -90.051552   \n",
       "8149  Interpolated by C. Abert from the 30 meter DEM  38.635914 -89.938217   \n",
       "\n",
       "         ELEV_FT                    geometry  \n",
       "0     580.419373  POINT (-89.93336 38.73334)  \n",
       "1     529.981140  POINT (-90.03065 38.93007)  \n",
       "2     530.172913  POINT (-90.04536 38.94200)  \n",
       "3     520.954590  POINT (-90.03820 38.91838)  \n",
       "4     507.976868  POINT (-89.95508 38.87055)  \n",
       "...          ...                         ...  \n",
       "8145  555.110840  POINT (-90.05806 38.52028)  \n",
       "8146  409.501556  POINT (-90.10500 38.57583)  \n",
       "8147  410.597595  POINT (-90.24412 38.52866)  \n",
       "8148  431.323914  POINT (-90.05155 38.64057)  \n",
       "8149  565.456055  POINT (-89.93822 38.63591)  \n",
       "\n",
       "[8150 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData = mapping.coords2Geometry(df=headerData, xCol='LONGITUDE', yCol='LATITUDE', crs='EPSG:4269')\n",
    "#headerData['geometry']=headerData['GEOMETRY'].copy() #old code\n",
    "headerDataClip = mapping.clipHeader2StudyArea(studyarea=studyAreaIN, headerdata=headerData, headerCRS='EPSG:4269')\n",
    "headerData = headerDataClip.copy()\n",
    "headerData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove data from downholeData table that does not have location information (Since we would not know where to put it anyway)\n",
    "\n",
    "This should also essentially \"clip\" the downholeData to the study area, since only study area wells remain in headerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2998078 records removed without location information.\n",
      "56331 wells remain from 7188 located wells in study area.\n"
     ]
    }
   ],
   "source": [
    "downholeData = cleanData.removeNonlocatedData(downholeData, headerData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove headerData rows without surface elevation information (this currently clips data from outside Illinois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>201.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NE NW NW</td>\n",
       "      <td>591.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.733337</td>\n",
       "      <td>-89.933357</td>\n",
       "      <td>580.419373</td>\n",
       "      <td>POINT (-89.93336 38.73334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930917112</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>537.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.930069</td>\n",
       "      <td>-90.030655</td>\n",
       "      <td>529.981140</td>\n",
       "      <td>POINT (-90.03065 38.93007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930921712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>532.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.941998</td>\n",
       "      <td>-90.045364</td>\n",
       "      <td>530.172913</td>\n",
       "      <td>POINT (-90.04536 38.94200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930921812</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N2 SW NW</td>\n",
       "      <td>526.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.918377</td>\n",
       "      <td>-90.038200</td>\n",
       "      <td>520.954590</td>\n",
       "      <td>POINT (-90.03820 38.91838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930921912</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>507.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.870552</td>\n",
       "      <td>-89.955078</td>\n",
       "      <td>507.976868</td>\n",
       "      <td>POINT (-89.95508 38.87055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>1374073512</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.520279</td>\n",
       "      <td>-90.058060</td>\n",
       "      <td>555.110840</td>\n",
       "      <td>POINT (-90.05806 38.52028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>1374073812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SW NE SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.575832</td>\n",
       "      <td>-90.105003</td>\n",
       "      <td>409.501556</td>\n",
       "      <td>POINT (-90.10500 38.57583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1374073912</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>413.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.528660</td>\n",
       "      <td>-90.244118</td>\n",
       "      <td>410.597595</td>\n",
       "      <td>POINT (-90.24412 38.52866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>427.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.640568</td>\n",
       "      <td>-90.051552</td>\n",
       "      <td>431.323914</td>\n",
       "      <td>POINT (-90.05155 38.64057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1378559712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>562.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Interpolated by C. Abert from the 30 meter DEM</td>\n",
       "      <td>38.635914</td>\n",
       "      <td>-89.938217</td>\n",
       "      <td>565.456055</td>\n",
       "      <td>POINT (-89.93822 38.63591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       13626212        201.0     15.0  2.0    N   5.0    W       3.0   \n",
       "1      930917112         73.0     31.0  6.0    N   8.0    W       3.0   \n",
       "2      930921712         75.0     25.0  6.0    N   9.0    W       3.0   \n",
       "3      930921812        295.0      6.0  5.0    N   8.0    W       3.0   \n",
       "4      930921912       2195.0     23.0  5.0    N   8.0    W       3.0   \n",
       "...          ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "8145  1374073512         52.0     23.0  1.0    N   9.0    W       3.0   \n",
       "8146  1374073812         70.0     33.0  2.0    N   9.0    W       3.0   \n",
       "8147  1374073912         31.0     19.0  1.0    N  10.0    W       3.0   \n",
       "8148  1374794512         61.0     12.0  2.0    N   9.0    W       3.0   \n",
       "8149  1378559712          NaN     12.0  2.0    N   8.0    W       3.0   \n",
       "\n",
       "      QUARTERS  ELEVATION ELEVREF  COUNTY_CODE  \\\n",
       "0     NE NW NW      591.0     nan         27.0   \n",
       "1          nan      537.0      GL        119.0   \n",
       "2           SE      532.0      GL        119.0   \n",
       "3     N2 SW NW      526.0      GL        119.0   \n",
       "4           SE      507.0      GL        119.0   \n",
       "...        ...        ...     ...          ...   \n",
       "8145       nan        NaN     nan        163.0   \n",
       "8146  SW NE SW        NaN     nan        163.0   \n",
       "8147       nan      413.0      DM        163.0   \n",
       "8148        NW      427.0      GL        163.0   \n",
       "8149       nan      562.0      DM        163.0   \n",
       "\n",
       "                                          ELEVSOURCE   LATITUDE  LONGITUDE  \\\n",
       "0                                                nan  38.733337 -89.933357   \n",
       "1                                                nan  38.930069 -90.030655   \n",
       "2                                                nan  38.941998 -90.045364   \n",
       "3                                                nan  38.918377 -90.038200   \n",
       "4                                                nan  38.870552 -89.955078   \n",
       "...                                              ...        ...        ...   \n",
       "8145                                             nan  38.520279 -90.058060   \n",
       "8146                                             nan  38.575832 -90.105003   \n",
       "8147                                             nan  38.528660 -90.244118   \n",
       "8148                                             nan  38.640568 -90.051552   \n",
       "8149  Interpolated by C. Abert from the 30 meter DEM  38.635914 -89.938217   \n",
       "\n",
       "         ELEV_FT                    geometry  \n",
       "0     580.419373  POINT (-89.93336 38.73334)  \n",
       "1     529.981140  POINT (-90.03065 38.93007)  \n",
       "2     530.172913  POINT (-90.04536 38.94200)  \n",
       "3     520.954590  POINT (-90.03820 38.91838)  \n",
       "4     507.976868  POINT (-89.95508 38.87055)  \n",
       "...          ...                         ...  \n",
       "8145  555.110840  POINT (-90.05806 38.52028)  \n",
       "8146  409.501556  POINT (-90.10500 38.57583)  \n",
       "8147  410.597595  POINT (-90.24412 38.52866)  \n",
       "8148  431.323914  POINT (-90.05155 38.64057)  \n",
       "8149  565.456055  POINT (-89.93822 38.63591)  \n",
       "\n",
       "[8150 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData =headerDataClip.copy()\n",
    "headerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well records removed: 0\n",
      "Number of rows before dropping those without surface elevation information: 8150\n",
      "Number of rows after dropping those without surface elevation information: 8150\n"
     ]
    }
   ],
   "source": [
    "headerData_cleaned = cleanData.removenotopo(df=headerData, printouts=True)\n",
    "headerData = headerData_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows from downholeData with no depth information and where depth information is obviously bad (i.e., top depth > bottom depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without record depth information: 56331\n",
      "Number of rows after dropping those without record depth information: 55747\n",
      "Number of well records without formation information deleted: 584\n",
      "Number of rows before dropping those with obviously bad depth information: 56331\n",
      "Number of rows after dropping those with obviously bad depth information: 55725\n",
      "Well records deleted: 606\n"
     ]
    }
   ],
   "source": [
    "#Drop records with no depth information\n",
    "donwholeData = cleanData.dropnodepth(downholeData, printouts=True)\n",
    "#Drop records with bad depth information (i.e., top depth > bottom depth) (Also calculates thickness of each record)\n",
    "donwholeData = cleanData.dropbaddepth(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records with no FORMATION information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without FORMATION information: 56331\n",
      "Number of rows after dropping those without FORMATION information: 56331\n",
      "Well records deleted: 0\n"
     ]
    }
   ],
   "source": [
    "downholeData = cleanData.dropnoformation(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to export this data, to have record of cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData.reset_index(inplace=True,drop=True)\n",
    "headerData.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#downholeData.to_csv(str(repoDir)+'/out/downholeData_cleaned'+dateSuffix+'.csv',index_label='ID')\n",
    "#headerData.to_csv(str(repoDir)+'/out/headerData_cleaned'+dateSuffix+'.csv',index_label='ID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following flags are used to mark the classification method:\n",
    "- 0: Not classified\n",
    "- 1: Specific Search Term Match\n",
    "- 2: Wildcard match (startTerm) - no context\n",
    "- 3: Bedrock classification for obvious bedrock\n",
    "- 4: Wildcard match (startTerm) - with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : SearchTerms-Specific_2022-11-16_essCols.csv\n",
      "Most Recent version of this file is : SearchTerms-Start.csv\n"
     ]
    }
   ],
   "source": [
    "#Read in dictionary files for downhole data\n",
    "specTermsPATH, startTermsPATH = readData.searchTermFilePaths(dictdir=str(repoDir)+'/res/', specStartPattern='*SearchTerms-Specific*', startGlobPattern = '*SearchTerms-Start*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\readData.py:155: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  specTerms.iloc[:,i] = specTerms.iloc[:,i].astype(specTermsDtypes[specTerms.iloc[:,i].name])\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\readData.py:156: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  startTerms.iloc[:,i] = startTerms.iloc[:,i].astype(startTermsDtypes[startTerms.iloc[:,i].name])\n"
     ]
    }
   ],
   "source": [
    "specTerms, startTerms = readData.readSearchTerms(specfile=specTermsPATH, startfile=startTermsPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the dataframes--for the specific search terms, this is the same as classifying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Classified with full search term: 25280\n",
      "Records Classified with full search term: 44.88% of data\n"
     ]
    }
   ],
   "source": [
    "downholeData_spec = classify.specificDefine(downholeData, specTerms, printouts=True)\n",
    "downholeData = downholeData_spec.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with only the records already classified (using the specific search terms in this case, classifiedDF), and one that still needs to be searched (searchDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31051"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifedDF, searchDF = classify.splitDefined(downholeData)\n",
    "searchDF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do the classification routine on the searchDF database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Term process should be done by 15:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].where(~df['FORMATION'].str.startswith(s,na=False),4,inplace=True)\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['INTERPRETATION'].where(~df['FORMATION'].str.startswith(s,na=False),starterms.loc[i,'INTERPRETATION'],inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records classified with start search term: 3876\n",
      "Records classified with start search term: 12.48% of remaining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEDROCK_FLAG'] = df[\"INTERPRETATION\"] == 'BEDROCK'\n"
     ]
    }
   ],
   "source": [
    "searchDF = classify.startDefine(df=searchDF, starterms=startTerms, printouts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge specDF and searchDF back together all back in single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData_Terms = classify.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Terms.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export terms that still need to be defined to csv (along with their counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The outdir should be changed so it doesn't clog up the repository\n",
    "#classify.export_toBeDefined(df=downholeData, outdir=str(repoDir)+'/out/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify all  data under depth threshold (default is 550') as bedrock (should not be an issue, but just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    500\n",
      "Name: CLASS_FLAG, dtype: int64\n",
      "test\n",
      "Records classified as bedrock that were deeper than 550': 500\n",
      "This represents 1.84% of the unclassified data in this dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].mask(df['TOP']>thresh, 3 ,inplace=True) #Add a Classification Flag of 3 (bedrock b/c it's deepter than 550') to all records where the top of the interval is >550'\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\lib\\classify.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEDROCK_FLAG'].mask(df['TOP']>thresh, True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "classifedDF, searchDF = classify.splitDefined(downholeData)\n",
    "searchDF = classify.depthDefine(searchDF, thresh=550, printouts=True)\n",
    "downholeData_Class = classify.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Class.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add '0' flag for data still not classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = classify.fillUnclassified(downholeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    26675\n",
       "1.0    25280\n",
       "4.0     3876\n",
       "3.0      500\n",
       "Name: CLASS_FLAG, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['CLASS_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add \"Flag\" for target interpratations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictDir = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\WellDataAutoClassification\\\\SupportingDocs\\\\\"\n",
    "targetInterpDF = readData.readLithologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTERPRETATION</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEDROCK</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIRECLAY</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VOID</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLAY AND STONE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIRT AND BEDROCK</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIRT AND STONE</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRAVEL AND STONE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOULDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOULDERS AND CLAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GRAVEL WITH BOULDERS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CLAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DIRT AND CLAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CLAY AND GRAVEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CLAY WITH GRAVEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MUD AND GRAVEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CLAY AND SAND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CLAY WITH SAND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MUD AND SAND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CLAY WITH GRAVEL SEAMS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CLAY WITH SAND STREAKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FILL</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DRIFT</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MUD</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DIRT AND GRAVEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GRAVEL WITH SAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GRAVEL AND CLAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GRAVEL WITH CLAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GRAVEL WITH CLAY STREAKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MARL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ORGANIC MATERIAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DIRT AND SAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SAND AND CLAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SAND WITH CLAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SAND AND GRAVEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SAND WITH GRAVEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SAND WITH CLAY STREAKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SILT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SILT AND GRAVEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SILT AND SAND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SILT WITH SAND SEAMS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DIRT</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SOIL</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>DoNotUse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              INTERPRETATION    TARGET\n",
       "0                    BEDROCK  DoNotUse\n",
       "1                   FIRECLAY  DoNotUse\n",
       "2                       VOID  DoNotUse\n",
       "3             CLAY AND STONE         0\n",
       "4           DIRT AND BEDROCK  DoNotUse\n",
       "5             DIRT AND STONE  DoNotUse\n",
       "6           GRAVEL AND STONE         1\n",
       "7                    BOULDER         1\n",
       "8          BOULDERS AND CLAY         0\n",
       "9       GRAVEL WITH BOULDERS         1\n",
       "10                      CLAY         0\n",
       "11             DIRT AND CLAY         0\n",
       "12           CLAY AND GRAVEL         0\n",
       "13          CLAY WITH GRAVEL         0\n",
       "14            MUD AND GRAVEL         0\n",
       "15             CLAY AND SAND         0\n",
       "16            CLAY WITH SAND         0\n",
       "17              MUD AND SAND         0\n",
       "18    CLAY WITH GRAVEL SEAMS         0\n",
       "19    CLAY WITH SAND STREAKS         0\n",
       "20                      FILL  DoNotUse\n",
       "21                     DRIFT  DoNotUse\n",
       "22                       MUD  DoNotUse\n",
       "23           DIRT AND GRAVEL         1\n",
       "24                    GRAVEL         1\n",
       "25          GRAVEL WITH SAND         1\n",
       "26           GRAVEL AND CLAY         0\n",
       "27          GRAVEL WITH CLAY         0\n",
       "28  GRAVEL WITH CLAY STREAKS         0\n",
       "29                      MARL         0\n",
       "30          ORGANIC MATERIAL         0\n",
       "31             DIRT AND SAND         1\n",
       "32                      SAND         1\n",
       "33             SAND AND CLAY         0\n",
       "34            SAND WITH CLAY         0\n",
       "35           SAND AND GRAVEL         1\n",
       "36          SAND WITH GRAVEL         1\n",
       "37    SAND WITH CLAY STREAKS         0\n",
       "38                      SILT         0\n",
       "39           SILT AND GRAVEL         0\n",
       "40             SILT AND SAND         0\n",
       "41      SILT WITH SAND SEAMS         0\n",
       "42                      DIRT  DoNotUse\n",
       "43                      SOIL  DoNotUse\n",
       "44                   UNKNOWN  DoNotUse"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetInterpDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = classify.mergeLithologies(downholedata=downholeData, targinterps=targetInterpDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags used for target classification purposes:\n",
    "- -2: No classification \n",
    "- -1: Classified, not used/not definitive\n",
    "- 0: Classified, not target material\n",
    "- 1: Classified as target material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    25089\n",
       "1.0     4025\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all unique wells in downhole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique wells in downholeData: 7188\n"
     ]
    }
   ],
   "source": [
    "#Get Unique well APIs\n",
    "wellsDF = classify.getUniqueWells(downholeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort dataset by API Number and Depth of top of record (will be easier to do data analysis with records in the correct order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>THICKNESS</th>\n",
       "      <th>TOP</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>INTERPRETATION</th>\n",
       "      <th>CLASS_FLAG</th>\n",
       "      <th>BEDROCK_FLAG</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay brown</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>CLAY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay gray sandy, soft</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay gray, sticky</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay dark brown, wood</td>\n",
       "      <td>6.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>shale gray sandy hard</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>BEDROCK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56326</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>brown and gray silty clay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>SILT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56327</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray clay (with thin sand streaks)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56328</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>blue-gray clay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56329</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray, fine sand</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56330</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>brown and gray, fine to coarse, sand</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56331 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       API_NUMBER     TABLE_NAME                             FORMATION  \\\n",
       "0        13626212    WFORMATIONS                            clay brown   \n",
       "1        13626212    WFORMATIONS                 clay gray sandy, soft   \n",
       "2        13626212    WFORMATIONS                     clay gray, sticky   \n",
       "3        13626212    WFORMATIONS                 clay dark brown, wood   \n",
       "4        13626212    WFORMATIONS                 shale gray sandy hard   \n",
       "...           ...            ...                                   ...   \n",
       "56326  1374794512  HWYBRIDGE_LOG             brown and gray silty clay   \n",
       "56327  1374794512  HWYBRIDGE_LOG    gray clay (with thin sand streaks)   \n",
       "56328  1374794512  HWYBRIDGE_LOG                        blue-gray clay   \n",
       "56329  1374794512  HWYBRIDGE_LOG                       gray, fine sand   \n",
       "56330  1374794512  HWYBRIDGE_LOG  brown and gray, fine to coarse, sand   \n",
       "\n",
       "       THICKNESS   TOP  BOTTOM INTERPRETATION  CLASS_FLAG  BEDROCK_FLAG  \\\n",
       "0           20.0   0.0    20.0           CLAY         1.0         False   \n",
       "1           20.0  20.0    40.0            NaN         0.0         False   \n",
       "2            4.0  40.0    44.0            NaN         0.0         False   \n",
       "3            6.0  44.0    50.0            NaN         0.0         False   \n",
       "4           64.0  50.0   114.0        BEDROCK         1.0          True   \n",
       "...          ...   ...     ...            ...         ...           ...   \n",
       "56326        5.0  21.5    26.5           SILT         1.0         False   \n",
       "56327        7.5  26.5    34.0            NaN         0.0         False   \n",
       "56328        5.0  34.0    39.0            NaN         0.0         False   \n",
       "56329        5.0  39.0    44.0            NaN         0.0         False   \n",
       "56330       17.0  44.0    61.0            NaN         0.0         False   \n",
       "\n",
       "       TARGET  \n",
       "0         0.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         0.0  \n",
       "...       ...  \n",
       "56326     0.0  \n",
       "56327     NaN  \n",
       "56328     NaN  \n",
       "56329     NaN  \n",
       "56330     NaN  \n",
       "\n",
       "[56331 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData_sorted = downholeData.sort_values(['API_NUMBER','TOP'])\n",
    "downholeData_sorted.reset_index(inplace=True, drop=True)\n",
    "downholeData_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bedrock Depth and Layer Thickness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in/Define Model Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGridPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\grid_625_raster.tif\"\n",
    "modelGrid = mapping.readModelGrid(studyArea=studyAreaIN, gridpath=modelGridPath, nodataval=0, readGrid=True, clip2SA=True, gridcrs='EPSG:26715', studyAreacrs='EPSG:26715')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in surface elevation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaceElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ILStateLidar_ClipExtentESL.tif\"\n",
    "surfaceElevGridIN = mapping.readSurfaceGrid(surfaceelevpath=surfaceElevPath, useWCS=False, studyArea=studyAreaIN, clip2SA=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in bedrock elevation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrockElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESLBedrock.tif\"\n",
    "bedrockElevGridIN=mapping.readBedrockGrid(bedrockelevpath=bedrockElevPath, studyArea=studyAreaIN, clip2SA=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot just to see them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(ncols = 2, nrows=1)\n",
    "#bedrockElevGridIN.plot(ax=ax[0])\n",
    "#surfaceElevGridIN.plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject and align raster grids for surface elevation and bedrock topo (reproject well data too if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inGrids = [bedrockElevGridIN, surfaceElevGridIN]\n",
    "bedrockGrid, surfaceGrid = mapping.alignRasters(unalignedGrids=inGrids, modelgrid=modelGrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(ncols = 2, nrows=1)\n",
    "bedrockGrid.plot(ax=ax[0])\n",
    "surfaceGrid.plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the surface elevation raster and bedrock elevation raster to get depth to bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driftThickGrid, layerThickGrid = mapping.getDriftThick(surface=surfaceGrid, bedrock=bedrockGrid, noLayers=9, plotData=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sample each well point (headerData) to get layer thickness, surface elevation, and bedrock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEDROCK_ELEV_FT sampling should be done by 15:33\n",
      "SURFACE_ELEV_FT sampling should be done by 15:33\n",
      "BEDROCK_DEPTH_FT sampling should be done by 15:34\n",
      "LAYER_THICK_FT sampling should be done by 15:34\n"
     ]
    }
   ],
   "source": [
    "headerData = mapping.rastertoPoints_sample(raster=bedrockGrid, ptDF=headerData, newColName='BEDROCK_ELEV_FT')\n",
    "#headerData['BEDROCK_ELEV_M'] = headerData['BEDROCK_ELEV_FT']* 0.3048\n",
    "\n",
    "headerData = mapping.rastertoPoints_sample(raster=surfaceGrid, ptDF=headerData, newColName='SURFACE_ELEV_FT')\n",
    "#headerData['SURFACE_ELEV_M'] = headerData['SURFACE_ELEV_FT']* 0.3048\n",
    "\n",
    "headerData = mapping.rastertoPoints_sample(raster=driftThickGrid, ptDF=headerData, newColName='BEDROCK_DEPTH_FT')\n",
    "#headerData['BEDROCK_DEPTH_M'] = headerData['BEDROCK_DEPTH_FT']* 0.3048\n",
    "\n",
    "headerData = mapping.rastertoPoints_sample(raster=layerThickGrid, ptDF=headerData, newColName='LAYER_THICK_FT')\n",
    "#headerData['LAYER_THICK_M'] = headerData['LAYER_THICK_FT']* 0.3048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate  all layer depths/elevations at all wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "noLayers = 9\n",
    "for layer in range(0, noLayers): #For each layer\n",
    "    #Make column names\n",
    "    depthColName  = 'DEPTH_FT_LAYER'+str(layer+1)\n",
    "    #depthMcolName = 'Depth_M_LAYER'+str(layer) \n",
    "\n",
    "    #Calculate depth to each layer at each well, in feet and meters\n",
    "    headerData[depthColName]  = headerData['LAYER_THICK_FT'] * layer\n",
    "    #headerData[depthMcolName] = headerData[depthColName] * 0.3048\n",
    "\n",
    "for layer in range(0, noLayers): #For each layer\n",
    "    elevColName = 'ELEV_FT_LAYER'+str(layer+1)\n",
    "    #elevMColName = 'ELEV_M_LAYER'+str(layer)\n",
    "        \n",
    "    headerData[elevColName]  = headerData['SURFACE_ELEV_FT'] - headerData['LAYER_THICK_FT'] * layer\n",
    "    #headerData[elevMColName]  = headerData['SURFACE_ELEV_M'] - headerData['LAYER_THICK_M'] * layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Data from downhole and headerData to enable further calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = downholeData_sorted.copy()\n",
    "headerJoinCols = ['API_NUMBER', 'LATITUDE', 'LONGITUDE', 'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'ELEV_FT', 'BEDROCK_ELEV_FT', 'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2', 'DEPTH_FT_LAYER3','DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5', 'DEPTH_FT_LAYER6','DEPTH_FT_LAYER7','DEPTH_FT_LAYER8','DEPTH_FT_LAYER9','geometry']\n",
    "downholeData_layerInfo = layers.mergeTables(leftTable=downholeData, rightTable=headerData, rightCols=headerJoinCols, onCol='API_NUMBER', how='inner')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the top and bottom elevation for each well record in downholeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>THICKNESS</th>\n",
       "      <th>TOP</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>INTERPRETATION</th>\n",
       "      <th>CLASS_FLAG</th>\n",
       "      <th>BEDROCK_FLAG</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>...</th>\n",
       "      <th>DEPTH_FT_LAYER1</th>\n",
       "      <th>DEPTH_FT_LAYER2</th>\n",
       "      <th>DEPTH_FT_LAYER3</th>\n",
       "      <th>DEPTH_FT_LAYER4</th>\n",
       "      <th>DEPTH_FT_LAYER5</th>\n",
       "      <th>DEPTH_FT_LAYER6</th>\n",
       "      <th>DEPTH_FT_LAYER7</th>\n",
       "      <th>DEPTH_FT_LAYER8</th>\n",
       "      <th>DEPTH_FT_LAYER9</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay brown</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>CLAY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.621148</td>\n",
       "      <td>21.242296</td>\n",
       "      <td>31.863445</td>\n",
       "      <td>42.484592</td>\n",
       "      <td>53.105740</td>\n",
       "      <td>63.726891</td>\n",
       "      <td>74.348038</td>\n",
       "      <td>84.969185</td>\n",
       "      <td>POINT (2877068.410 2079989.645)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay gray sandy, soft</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.621148</td>\n",
       "      <td>21.242296</td>\n",
       "      <td>31.863445</td>\n",
       "      <td>42.484592</td>\n",
       "      <td>53.105740</td>\n",
       "      <td>63.726891</td>\n",
       "      <td>74.348038</td>\n",
       "      <td>84.969185</td>\n",
       "      <td>POINT (2877068.410 2079989.645)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay gray, sticky</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.621148</td>\n",
       "      <td>21.242296</td>\n",
       "      <td>31.863445</td>\n",
       "      <td>42.484592</td>\n",
       "      <td>53.105740</td>\n",
       "      <td>63.726891</td>\n",
       "      <td>74.348038</td>\n",
       "      <td>84.969185</td>\n",
       "      <td>POINT (2877068.410 2079989.645)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>clay dark brown, wood</td>\n",
       "      <td>6.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.621148</td>\n",
       "      <td>21.242296</td>\n",
       "      <td>31.863445</td>\n",
       "      <td>42.484592</td>\n",
       "      <td>53.105740</td>\n",
       "      <td>63.726891</td>\n",
       "      <td>74.348038</td>\n",
       "      <td>84.969185</td>\n",
       "      <td>POINT (2877068.410 2079989.645)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13626212</td>\n",
       "      <td>WFORMATIONS</td>\n",
       "      <td>shale gray sandy hard</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>BEDROCK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.621148</td>\n",
       "      <td>21.242296</td>\n",
       "      <td>31.863445</td>\n",
       "      <td>42.484592</td>\n",
       "      <td>53.105740</td>\n",
       "      <td>63.726891</td>\n",
       "      <td>74.348038</td>\n",
       "      <td>84.969185</td>\n",
       "      <td>POINT (2877068.410 2079989.645)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56326</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>brown and gray silty clay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>SILT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.706272</td>\n",
       "      <td>29.412544</td>\n",
       "      <td>44.118816</td>\n",
       "      <td>58.825089</td>\n",
       "      <td>73.531357</td>\n",
       "      <td>88.237633</td>\n",
       "      <td>102.943909</td>\n",
       "      <td>117.650177</td>\n",
       "      <td>POINT (2843331.687 2046568.660)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56327</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray clay (with thin sand streaks)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.706272</td>\n",
       "      <td>29.412544</td>\n",
       "      <td>44.118816</td>\n",
       "      <td>58.825089</td>\n",
       "      <td>73.531357</td>\n",
       "      <td>88.237633</td>\n",
       "      <td>102.943909</td>\n",
       "      <td>117.650177</td>\n",
       "      <td>POINT (2843331.687 2046568.660)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56328</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>blue-gray clay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.706272</td>\n",
       "      <td>29.412544</td>\n",
       "      <td>44.118816</td>\n",
       "      <td>58.825089</td>\n",
       "      <td>73.531357</td>\n",
       "      <td>88.237633</td>\n",
       "      <td>102.943909</td>\n",
       "      <td>117.650177</td>\n",
       "      <td>POINT (2843331.687 2046568.660)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56329</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>gray, fine sand</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.706272</td>\n",
       "      <td>29.412544</td>\n",
       "      <td>44.118816</td>\n",
       "      <td>58.825089</td>\n",
       "      <td>73.531357</td>\n",
       "      <td>88.237633</td>\n",
       "      <td>102.943909</td>\n",
       "      <td>117.650177</td>\n",
       "      <td>POINT (2843331.687 2046568.660)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56330</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>HWYBRIDGE_LOG</td>\n",
       "      <td>brown and gray, fine to coarse, sand</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.706272</td>\n",
       "      <td>29.412544</td>\n",
       "      <td>44.118816</td>\n",
       "      <td>58.825089</td>\n",
       "      <td>73.531357</td>\n",
       "      <td>88.237633</td>\n",
       "      <td>102.943909</td>\n",
       "      <td>117.650177</td>\n",
       "      <td>POINT (2843331.687 2046568.660)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56331 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       API_NUMBER     TABLE_NAME                             FORMATION  \\\n",
       "0        13626212    WFORMATIONS                            clay brown   \n",
       "1        13626212    WFORMATIONS                 clay gray sandy, soft   \n",
       "2        13626212    WFORMATIONS                     clay gray, sticky   \n",
       "3        13626212    WFORMATIONS                 clay dark brown, wood   \n",
       "4        13626212    WFORMATIONS                 shale gray sandy hard   \n",
       "...           ...            ...                                   ...   \n",
       "56326  1374794512  HWYBRIDGE_LOG             brown and gray silty clay   \n",
       "56327  1374794512  HWYBRIDGE_LOG    gray clay (with thin sand streaks)   \n",
       "56328  1374794512  HWYBRIDGE_LOG                        blue-gray clay   \n",
       "56329  1374794512  HWYBRIDGE_LOG                       gray, fine sand   \n",
       "56330  1374794512  HWYBRIDGE_LOG  brown and gray, fine to coarse, sand   \n",
       "\n",
       "       THICKNESS   TOP  BOTTOM INTERPRETATION  CLASS_FLAG  BEDROCK_FLAG  \\\n",
       "0           20.0   0.0    20.0           CLAY         1.0         False   \n",
       "1           20.0  20.0    40.0            NaN         0.0         False   \n",
       "2            4.0  40.0    44.0            NaN         0.0         False   \n",
       "3            6.0  44.0    50.0            NaN         0.0         False   \n",
       "4           64.0  50.0   114.0        BEDROCK         1.0          True   \n",
       "...          ...   ...     ...            ...         ...           ...   \n",
       "56326        5.0  21.5    26.5           SILT         1.0         False   \n",
       "56327        7.5  26.5    34.0            NaN         0.0         False   \n",
       "56328        5.0  34.0    39.0            NaN         0.0         False   \n",
       "56329        5.0  39.0    44.0            NaN         0.0         False   \n",
       "56330       17.0  44.0    61.0            NaN         0.0         False   \n",
       "\n",
       "       TARGET  ...  DEPTH_FT_LAYER1  DEPTH_FT_LAYER2  DEPTH_FT_LAYER3  \\\n",
       "0         0.0  ...              0.0        10.621148        21.242296   \n",
       "1         0.0  ...              0.0        10.621148        21.242296   \n",
       "2         0.0  ...              0.0        10.621148        21.242296   \n",
       "3         0.0  ...              0.0        10.621148        21.242296   \n",
       "4         0.0  ...              0.0        10.621148        21.242296   \n",
       "...       ...  ...              ...              ...              ...   \n",
       "56326     0.0  ...              0.0        14.706272        29.412544   \n",
       "56327     0.0  ...              0.0        14.706272        29.412544   \n",
       "56328     0.0  ...              0.0        14.706272        29.412544   \n",
       "56329     0.0  ...              0.0        14.706272        29.412544   \n",
       "56330     0.0  ...              0.0        14.706272        29.412544   \n",
       "\n",
       "       DEPTH_FT_LAYER4  DEPTH_FT_LAYER5  DEPTH_FT_LAYER6  DEPTH_FT_LAYER7  \\\n",
       "0            31.863445        42.484592        53.105740        63.726891   \n",
       "1            31.863445        42.484592        53.105740        63.726891   \n",
       "2            31.863445        42.484592        53.105740        63.726891   \n",
       "3            31.863445        42.484592        53.105740        63.726891   \n",
       "4            31.863445        42.484592        53.105740        63.726891   \n",
       "...                ...              ...              ...              ...   \n",
       "56326        44.118816        58.825089        73.531357        88.237633   \n",
       "56327        44.118816        58.825089        73.531357        88.237633   \n",
       "56328        44.118816        58.825089        73.531357        88.237633   \n",
       "56329        44.118816        58.825089        73.531357        88.237633   \n",
       "56330        44.118816        58.825089        73.531357        88.237633   \n",
       "\n",
       "       DEPTH_FT_LAYER8  DEPTH_FT_LAYER9                         geometry  \n",
       "0            74.348038        84.969185  POINT (2877068.410 2079989.645)  \n",
       "1            74.348038        84.969185  POINT (2877068.410 2079989.645)  \n",
       "2            74.348038        84.969185  POINT (2877068.410 2079989.645)  \n",
       "3            74.348038        84.969185  POINT (2877068.410 2079989.645)  \n",
       "4            74.348038        84.969185  POINT (2877068.410 2079989.645)  \n",
       "...                ...              ...                              ...  \n",
       "56326       102.943909       117.650177  POINT (2843331.687 2046568.660)  \n",
       "56327       102.943909       117.650177  POINT (2843331.687 2046568.660)  \n",
       "56328       102.943909       117.650177  POINT (2843331.687 2046568.660)  \n",
       "56329       102.943909       117.650177  POINT (2843331.687 2046568.660)  \n",
       "56330       102.943909       117.650177  POINT (2843331.687 2046568.660)  \n",
       "\n",
       "[56331 rows x 29 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all=''\n",
    "all = downholeData_layerInfo.columns\n",
    "downholeData_layerInfo = downholeData_layerInfo[all]\n",
    "downholeData_layerInfo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work here next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate target thickness in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS CELL MAY NEED TO BE UPDATED!!!!!\n",
    "\n",
    "#Define the function to export the result of thickness of target sediments in each layer\n",
    "def Layers_surfacedown(df, layer = 1):\n",
    "    \n",
    "    #Generate Column names based on (looped) integers\n",
    "    topCol = \"DEPTH_FT_LAYER\"+str(layer)\n",
    "    if layer != 9: #For all layers except the bottom layer....\n",
    "        botCol = \"DEPTH_FT_LAYER\"+str(layer+1) #use the layer below it to \n",
    "    else: #Otherwise, ...\n",
    "        botCol = \"BEDROCK_DEPTH_FT\" #Use the (corrected) bedrock depth\n",
    "\n",
    "    #Divide records into 4 separate categories for ease of calculation, to be joined back together later  \n",
    "        #Category 1: Well interval starts above layer top, ends within model layer\n",
    "        #Category 2: Well interval is entirely contained withing model layer\n",
    "        #Category 3: Well interval starts within model layer, continues through bottom of model layer\n",
    "        #Category 4: well interval begins and ends on either side of model layer (model layer is contained within well layer)\n",
    "\n",
    "    #records1 = intervals that go through the top of the layer and bottom is within layer\n",
    "    records1 = df.loc[(df['TOP'] > df[topCol]) & (df['BOTTOM'] > df[botCol]) & (df['BOTTOM'] <= df[topCol]) & (df['BOTTOM'] <= df['TOP'])].copy() #Find those records\n",
    "    records1['TARG_THICK'] = pd.DataFrame(np.round((records1.loc[:,topCol]-records1.loc[: , 'BOTTOM']) * records1['Target'],3)).copy() #Multiply \"target\" (1 or 0) by length within layer\n",
    "    \n",
    "    #records2 = entire interval is within layer\n",
    "    records2 = df.loc[(df['TOP'] <= df[topCol]) & (df['BOTTOM'] >= df[botCol]) & (df['BOTTOM'] <= df['TOP'])].copy()\n",
    "    records2['TARG_THICK'] = pd.DataFrame(np.round((records2.loc[: , 'TOP'] - records2.loc[: , 'BOTTOM']) * records2['Target'],3)).copy()\n",
    "\n",
    "    #records3 = intervals with top within layer and bottom of interval going through bottom of layer\n",
    "    records3 = df.loc[(df['TOP'] > df[botCol]) & (df['BOTTOM'] < df[botCol]) & (df['TOP'] <= df[topCol]) & (df['BOTTOM'] <= df['TOP'])].copy()\n",
    "    records3['TARG_THICK'] = pd.DataFrame(np.round((records3.loc[: , 'TOP'] - (records3.loc[:,botCol]))*records3['Target'],3)).copy()\n",
    "\n",
    "    #records4 = interval goes through entire layer\n",
    "    records4 = df.loc[(df['TOP'] > df[topCol]) & (df['BOTTOM'] < df[botCol]) & (df['BOTTOM'] <= df['TOP'])].copy()\n",
    "    records4['TARG_THICK'] = pd.DataFrame(np.round((records4.loc[: , topCol]-records4.loc[: , botCol]) * records4['Target'],3)).copy()\n",
    "\n",
    "    \n",
    "    #Put the four calculated record categories back together into single dataframe\n",
    "    res = records1.append(records2).append(records3).append(records4)\n",
    "    \n",
    "    res_df = res.groupby(['API_NUMBER','LATITUDE','LONGITUDE'],as_index=False).sum()#calculate thickness for each well interval in the layer indicated (e.g., if there are two well intervals from same well in one model layer)\n",
    "\n",
    "    res_df['TARG_THICK_PER'] = pd.DataFrame(np.round(res_df['TARG_THICK']/res_df['LyrThick'],3)) #Calculate thickness as percent of total layer thickness\n",
    "    res_df[\"LAYER\"] = layer #Just to have as part of the output file, include the present layer in the file itself as a separate column\n",
    "    res_df = res_df[['API_NUMBER', 'LATITUDE', 'LONGITUDE', 'TOP', 'BOTTOM','SURF_ELEV_ft', topCol,botCol,'LyrThick','TARG_THICK', 'TARG_THICK_PER', 'LAYER']].copy() #Format dataframe for output\n",
    "    \n",
    "    return res, res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res, resdf \u001b[39m=\u001b[39m Layers_surfacedown(downholeData, layer \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[56], line 21\u001b[0m, in \u001b[0;36mLayers_surfacedown\u001b[1;34m(df, layer)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m#Divide records into 4 separate categories for ease of calculation, to be joined back together later  \u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[39m#Category 1: Well interval starts above layer top, ends within model layer\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[39m#Category 2: Well interval is entirely contained withing model layer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[39m#records1 = intervals that go through the top of the layer and bottom is within layer\u001b[39;00m\n\u001b[0;32m     20\u001b[0m records1 \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[(df[\u001b[39m'\u001b[39m\u001b[39mTOP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m df[topCol]) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mBOTTOM\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m df[botCol]) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mBOTTOM\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m df[topCol]) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mBOTTOM\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mTOP\u001b[39m\u001b[39m'\u001b[39m])]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 21\u001b[0m records1[\u001b[39m'\u001b[39m\u001b[39mTARG_THICK\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(np\u001b[39m.\u001b[39mround((records1\u001b[39m.\u001b[39mloc[:,topCol]\u001b[39m-\u001b[39mrecords1\u001b[39m.\u001b[39mloc[: , \u001b[39m'\u001b[39m\u001b[39mBOTTOM\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m*\u001b[39m records1[\u001b[39m'\u001b[39;49m\u001b[39mTarget\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m3\u001b[39m))\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     23\u001b[0m \u001b[39m#records2 = entire interval is within layer\u001b[39;00m\n\u001b[0;32m     24\u001b[0m records2 \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[(df[\u001b[39m'\u001b[39m\u001b[39mTOP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m df[topCol]) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mBOTTOM\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m df[botCol]) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mBOTTOM\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mTOP\u001b[39m\u001b[39m'\u001b[39m])]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Target'"
     ]
    }
   ],
   "source": [
    "res, resdf = Layers_surfacedown(downholeData, layer = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS CELL MAY NEED TO BE UPDATED!!!!!\n",
    "\n",
    "\n",
    "#Define the function to export the result of thickness of target sediments in each layer\n",
    "def Layers_surfacedown(df, layer = 1):\n",
    "    \n",
    "    #Generate Column names based on (looped) integers\n",
    "    topCol = \"ESL_ModelTopoLyrs_\"+str(layer)\n",
    "    if layer != 9: #For all layers except the bottom layer....\n",
    "        botCol = \"ESL_ModelTopoLyrs_\"+str(layer+1) #use the layer below it to \n",
    "    else: #Otherwise, ...\n",
    "        botCol = \"BedrockCorr\" #Use the (corrected) bedrock depth\n",
    "\n",
    "    #Divide records into 4 separate categories for ease of calculation, to be joined back together later  \n",
    "        #Category 1: Well interval starts above layer top, ends within model layer\n",
    "        #Category 2: Well interval is entirely contained withing model layer\n",
    "        #Category 3: Well interval starts within model layer, continues through bottom of model layer\n",
    "        #Category 4: well interval begins and ends on either side of model layer (model layer is contained within well layer)\n",
    "\n",
    "    #records1 = intervals that go through the top of the layer and bottom is within layer\n",
    "    records1 = df.loc[(df['TOP_ELEV_ft'] > df[topCol]) & (df['BOT_ELEV_ft'] > df[botCol]) & (df['BOT_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records1['TARG_THICK'] = pd.DataFrame(np.round((records1.loc[:,topCol]-records1.loc[: , 'BOT_ELEV_ft']) * records1['Target'],3)).copy()\n",
    "    \n",
    "    #records2 = entire interval is within layer\n",
    "    records2 = df.loc[(df['TOP_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] >= df[botCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records2['TARG_THICK'] = pd.DataFrame(np.round((records2.loc[: , 'TOP_ELEV_ft'] - records2.loc[: , 'BOT_ELEV_ft']) * records2['Target'],3)).copy()\n",
    "\n",
    "    #records3 = intervals with top within layer and bottom of interval going through bottom of layer\n",
    "    records3 = df.loc[(df['TOP_ELEV_ft'] > df[botCol]) & (df['BOT_ELEV_ft'] < df[botCol]) & (df['TOP_ELEV_ft'] <= df[topCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records3['TARG_THICK'] = pd.DataFrame(np.round((records3.loc[: , 'TOP_ELEV_ft'] - (records3.loc[:,botCol]))*records3['Target'],3)).copy()\n",
    "\n",
    "    #records4 = interval goes through entire layer\n",
    "    records4 = df.loc[(df['TOP_ELEV_ft'] > df[topCol]) & (df['BOT_ELEV_ft'] < df[botCol]) & (df['BOT_ELEV_ft'] <= df['TOP_ELEV_ft'])].copy()\n",
    "    records4['TARG_THICK'] = pd.DataFrame(np.round((records4.loc[: , topCol]-records4.loc[: , botCol]) * records4['Target'],3)).copy()\n",
    "\n",
    "    \n",
    "    #Put the four calculated record categories back together into single dataframe\n",
    "    res = records1.append(records2).append(records3).append(records4)\n",
    "    \n",
    "    res_df = res.groupby(['API_NUMBER','LATITUDE','LONGITUDE'],as_index=False).sum()#calculate thickness for each well interval in the layer indicated (e.g., if there are two well intervals from same well in one model layer)\n",
    "\n",
    "    res_df['TARG_THICK_PER'] = pd.DataFrame(np.round(res_df['TARG_THICK']/res_df['LyrThick'],3)) #Calculate thickness as percent of total layer thickness\n",
    "    res_df[\"LAYER\"] = layer #Just to have as part of the output file, include the present layer in the file itself as a separate column\n",
    "    res_df = res_df[['API_NUMBER', 'LATITUDE', 'LONGITUDE', 'TOP', 'BOTTOM','SURF_ELEV_ft', 'TOP_ELEV_ft', 'BOT_ELEV_ft',topCol,botCol,'LyrThick','TARG_THICK', 'TARG_THICK_PER', 'LAYER']].copy() #Format dataframe for output\n",
    "    \n",
    "    return res, res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run that function over all the layers, looping through each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL WILL NEED TO BE UPDATED\n",
    "\n",
    "outDIR = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\MetroEast_HydroGeo\\\\CodeOutput\\\\\"+codeTarget+\"\\\\\"\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    res, res_df = Layers_surfacedown(df, layer = i)#Run the function defined above for each layer\n",
    "    outputname = codeTargShort+'Lyr'+str(i)+'.csv' #Create a filename based on the layer and target\n",
    "    res_df.to_csv(outDIR+outputname)  #Export the file to csv\n",
    "    #Could also potentially save these to variables for use in following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate thickness values in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each layer and interpolate (use same parameters (?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure rasters align (are co-registered) with grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data \n",
    "downhole_bedrockDepth_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\Downhole_BedrockPicks.csv',index_label=\"ID\")\n",
    "wPermits_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\wPermits_BedrockPicks.csv',index_label=\"ID\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "1eab39f8790fa4ef06ab4ebada9c1405c2ef16219adfedb21e90bf3fb356ecb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
