{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{Fill in with information about this notebook}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np #Data manipulation\n",
    "import pandas as pd #Point data manipulation and organization\n",
    "import xarray as xr #Raster data manipulation and organization\n",
    "\n",
    "import pathlib  #For filepaths, io, etc.\n",
    "import os       #For several system-based commands\n",
    "import datetime #For manipulation of time data, including file creation/modification times\n",
    "import json     #For dictionary io, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt #For plotting and data vizualization\n",
    "import geopandas as gpd         #For organization and manipulation of vector data in space (study area and some data points)\n",
    "import rioxarray as rxr         #For orgnaization and manipulation of raster data\n",
    "import shapely                  #For converting coordinates to point geometry\n",
    "\n",
    "#Scripts with functions made for this specific application\n",
    "import w4h\n",
    "\n",
    "#Variables needed throughout, best to just assign now\n",
    "todayDate, dateSuffix = w4h.getCurrentDate() \n",
    "repoDir = pathlib.Path(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set up filepaths\n",
    "- Read in data from:\n",
    "    - downholeData table (from database)\n",
    "    - headerData table (from database)\n",
    "    - xyzData file (from previously carried out work) (will eventually make this updateable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "Most Recent version of this file is : ISGS_HEADER_2023-01-06.txt\n",
      "Most Recent version of this file is : xyzData.csv\n",
      "Using the following files:\n",
      "\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_DOWNHOLE_DATA_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\ISGS_HEADER_2023-01-06.txt\n",
      "\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\xyzData.csv\n",
      "Downhole Data has 3054409 valid well records.\n",
      "Header Data has 636855 unique wells with valid location information.\n"
     ]
    }
   ],
   "source": [
    "directoryDir = r'\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\BedrockWellData\\Wells\\RawWellData_OracleDatabase\\TxtData\\\\'[:-1]\n",
    "downholeDataPATH, headerDataPATH, xyzInPATH  = w4h.filesSetup(db_dir=directoryDir)\n",
    "\n",
    "#Functions to read data into dataframes. Also excludes extraneous columns, and drops header data with no location information\n",
    "headerDataIN, downholeDataIN = w4h.readRawTxtData(downholefile=downholeDataPATH, headerfile=headerDataPATH) \n",
    "xyzDataIN = w4h.readXYZData(xyzfile=xyzInPATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define datatypes (doing this during the read in process has presented issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:145: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:,i] = dfIN.iloc[:,i].astype(dtypes[dfIN.iloc[:,i].name])\n"
     ]
    }
   ],
   "source": [
    "#Define datatypes, to read into defineDataTypes() function\n",
    "##EVENTUALLY, MAKE THIS A FILE IN THE RES FOLDER TO READ IN\n",
    "#downholeDataDTYPES = {'ID':np.uint32, \"API_NUMBER\":np.uint64,\"TABLE_NAME\":str,\"WHO\":str,\"INTERPRET_DATE\":str,\"FORMATION\":str,\"THICKNESS\":np.float64,\"TOP\":np.float64,\"BOTTOM\":np.float64}\n",
    "#headerDataDTYPES = {'ID':np.uint32,'API_NUMBER':np.uint64,\"TDFORMATION\":str,\"PRODFORM\":str,\"TOTAL_DEPTH\":np.float64,\"SECTION\":np.float64,\"TWP\":np.float64,\"TDIR\":str,\"RNG\":np.float64,\"RDIR\":str,\"MERIDIAN\":np.float64,\"FARM_NAME\":str,\"NSFOOT\":np.float64,\"NSDIR\":str,\"EWFOOT\":np.float64,\"EWDIR\":str,\"QUARTERS\":str,\"ELEVATION\":np.float64,\"ELEVREF\":str,\"COMP_DATE\":str,\"STATUS\":str,\"FARM_NUM\":str,\"COUNTY_CODE\":np.float64,\"PERMIT_NUMBER\":str,\"COMPANY_NAME\":str,\"COMPANY_CODE\":str,\"PERMIT_DATE\":str,\"CORNER\":str,\"LATITUDE\":np.float64,\"LONGITUDE\":np.float64,\"ENTERED_BY\":str,\"UPDDATE\":str,\"ELEVSOURCE\":str, \"ELEV_FT\":np.float64}\n",
    "#xyzDataDTYPES = {'ID':np.uint64, 'API_NUMBER':np.uint64, \"LATITUDE\":np.float64, \"LONGITUDE\":np.float64, \"ELEV_FT\":np.float64}\n",
    "\n",
    "#Define datatypes of each column of the new dataframes\n",
    "downholeDataIN = w4h.defineDataTypes(downholeDataIN, dtypeFile='downholeDataTypes.txt')\n",
    "headerDataIN = w4h.defineDataTypes(headerDataIN, dtypeFile='headerDataTypes.txt')\n",
    "xyzDataIN = w4h.defineDataTypes(xyzDataIN, dtypeFile='xyzDataTypes.txt')\n",
    "\n",
    "#Make a copy of the data so raw data is preserved while we work with the rest of the data\n",
    "downholeData = downholeDataIN.copy()\n",
    "headerData = headerDataIN.copy()\n",
    "xyzData = xyzDataIN.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import w4h\n",
    "studyAreaPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESL_StudyArea_5mi.shp\"\n",
    "#studyAreaPath = r\"C:\\Users\\balikian\\OneDrive - University of Illinois - Urbana\\Data_OneDrive\\CodesScripts\\MahometBoreholesPolygon.zip\"\n",
    "studyAreaIN = w4h.read_study_area(studyAreaPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in/Define Model Grid, surface elevation grid, and bedrock elevation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGridPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\grid_625_raster.tif\"\n",
    "surfaceElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ILStateLidar_ClipExtentESL.tif\"\n",
    "bedrockElevPath = r\"\\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\Balikian\\ISWS_HydroGeo\\WellDataAutoClassification\\SampleData\\ESLBedrock.tif\"\n",
    "\n",
    "modelGrid = w4h.read_grid(datapath=modelGridPath, grid_type='model', studyArea=studyAreaIN,  read_grid=True, clip2SA=True)#, gridcrs='EPSG:26715', studyAreacrs='EPSG:26715')\n",
    "surfaceElevGridIN = w4h.read_grid(datapath=surfaceElevPath, grid_type='surface', studyArea=studyAreaIN, use_service=False, clip2SA=True)\n",
    "bedrockElevGridIN = w4h.read_grid(datapath=bedrockElevPath, grid_type='bedrock', studyArea=studyAreaIN, use_service=False, clip2SA=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in Control points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED CODE HERE FOR ADDING IN CONTROL Wells MANUALLY\n",
    "#Add control headerInfo\n",
    "#Add control description info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Elevation Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract elevation data from consistent elevation dataset for all wells (lidar or other statewide DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, get wells with updated xyz info\n",
    "    #Check first if xyzData needs to be updated with locations (?)\n",
    "    #Check which wells in headerData don't have associated lidar data\n",
    "\n",
    "#statewideLidar =  ow\n",
    "#mapping.rastertoPoints_extract()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge elevation data with headerData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWells = headerData['API_NUMBER'].unique()\n",
    "#xyzData['UniqueWells'] = uniqueWells\n",
    "\n",
    "headerData = w4h.addElevtoHeader(xyzData, headerData)\n",
    "##NEED TO UPDATE THIS TO WORK WITH DATA WITH NO XYZ ELEVATION DATA FROM LIDAR\n",
    "#Change xyz column name to indicate lidar\n",
    "#Use order of preference: lidar, headerData table?/30/10m DEM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's clean up records in the data without the necessary information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip data from outside Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\anaconda3\\envs\\geospatial38\\lib\\site-packages\\geopandas\\array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>201.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NE NW NW</td>\n",
       "      <td>591.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.733337</td>\n",
       "      <td>-89.933357</td>\n",
       "      <td>580.419373</td>\n",
       "      <td>POINT (-89.93336 38.73334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930917112</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>537.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.930069</td>\n",
       "      <td>-90.030655</td>\n",
       "      <td>529.981140</td>\n",
       "      <td>POINT (-90.03065 38.93007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930921712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>532.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.941998</td>\n",
       "      <td>-90.045364</td>\n",
       "      <td>530.172913</td>\n",
       "      <td>POINT (-90.04536 38.94200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930921812</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N2 SW NW</td>\n",
       "      <td>526.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.918377</td>\n",
       "      <td>-90.038200</td>\n",
       "      <td>520.954590</td>\n",
       "      <td>POINT (-90.03820 38.91838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930921912</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>507.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.870552</td>\n",
       "      <td>-89.955078</td>\n",
       "      <td>507.976868</td>\n",
       "      <td>POINT (-89.95508 38.87055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>1374073512</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.520279</td>\n",
       "      <td>-90.058060</td>\n",
       "      <td>555.110840</td>\n",
       "      <td>POINT (-90.05806 38.52028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>1374073812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SW NE SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.575832</td>\n",
       "      <td>-90.105003</td>\n",
       "      <td>409.501556</td>\n",
       "      <td>POINT (-90.10500 38.57583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1374073912</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>413.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.528660</td>\n",
       "      <td>-90.244118</td>\n",
       "      <td>410.597595</td>\n",
       "      <td>POINT (-90.24412 38.52866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>427.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.640568</td>\n",
       "      <td>-90.051552</td>\n",
       "      <td>431.323914</td>\n",
       "      <td>POINT (-90.05155 38.64057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1378559712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>562.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Interpolated by C. Abert from the 30 meter DEM</td>\n",
       "      <td>38.635914</td>\n",
       "      <td>-89.938217</td>\n",
       "      <td>565.456055</td>\n",
       "      <td>POINT (-89.93822 38.63591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       13626212        201.0     15.0  2.0    N   5.0    W       3.0   \n",
       "1      930917112         73.0     31.0  6.0    N   8.0    W       3.0   \n",
       "2      930921712         75.0     25.0  6.0    N   9.0    W       3.0   \n",
       "3      930921812        295.0      6.0  5.0    N   8.0    W       3.0   \n",
       "4      930921912       2195.0     23.0  5.0    N   8.0    W       3.0   \n",
       "...          ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "8145  1374073512         52.0     23.0  1.0    N   9.0    W       3.0   \n",
       "8146  1374073812         70.0     33.0  2.0    N   9.0    W       3.0   \n",
       "8147  1374073912         31.0     19.0  1.0    N  10.0    W       3.0   \n",
       "8148  1374794512         61.0     12.0  2.0    N   9.0    W       3.0   \n",
       "8149  1378559712          NaN     12.0  2.0    N   8.0    W       3.0   \n",
       "\n",
       "      QUARTERS  ELEVATION ELEVREF  COUNTY_CODE  \\\n",
       "0     NE NW NW      591.0     nan         27.0   \n",
       "1          nan      537.0      GL        119.0   \n",
       "2           SE      532.0      GL        119.0   \n",
       "3     N2 SW NW      526.0      GL        119.0   \n",
       "4           SE      507.0      GL        119.0   \n",
       "...        ...        ...     ...          ...   \n",
       "8145       nan        NaN     nan        163.0   \n",
       "8146  SW NE SW        NaN     nan        163.0   \n",
       "8147       nan      413.0      DM        163.0   \n",
       "8148        NW      427.0      GL        163.0   \n",
       "8149       nan      562.0      DM        163.0   \n",
       "\n",
       "                                          ELEVSOURCE   LATITUDE  LONGITUDE  \\\n",
       "0                                                nan  38.733337 -89.933357   \n",
       "1                                                nan  38.930069 -90.030655   \n",
       "2                                                nan  38.941998 -90.045364   \n",
       "3                                                nan  38.918377 -90.038200   \n",
       "4                                                nan  38.870552 -89.955078   \n",
       "...                                              ...        ...        ...   \n",
       "8145                                             nan  38.520279 -90.058060   \n",
       "8146                                             nan  38.575832 -90.105003   \n",
       "8147                                             nan  38.528660 -90.244118   \n",
       "8148                                             nan  38.640568 -90.051552   \n",
       "8149  Interpolated by C. Abert from the 30 meter DEM  38.635914 -89.938217   \n",
       "\n",
       "         ELEV_FT                    geometry  \n",
       "0     580.419373  POINT (-89.93336 38.73334)  \n",
       "1     529.981140  POINT (-90.03065 38.93007)  \n",
       "2     530.172913  POINT (-90.04536 38.94200)  \n",
       "3     520.954590  POINT (-90.03820 38.91838)  \n",
       "4     507.976868  POINT (-89.95508 38.87055)  \n",
       "...          ...                         ...  \n",
       "8145  555.110840  POINT (-90.05806 38.52028)  \n",
       "8146  409.501556  POINT (-90.10500 38.57583)  \n",
       "8147  410.597595  POINT (-90.24412 38.52866)  \n",
       "8148  431.323914  POINT (-90.05155 38.64057)  \n",
       "8149  565.456055  POINT (-89.93822 38.63591)  \n",
       "\n",
       "[8150 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData = w4h.coords2Geometry(df=headerData, xCol='LONGITUDE', yCol='LATITUDE', crs='EPSG:4269')\n",
    "#headerData['geometry']=headerData['GEOMETRY'].copy() #old code\n",
    "headerDataClip = w4h.clipHeader2StudyArea(studyarea=studyAreaIN, headerdata=headerData, headerCRS='EPSG:4269')\n",
    "headerData = headerDataClip.copy()\n",
    "headerData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove data from downholeData table that does not have location information (Since we would not know where to put it anyway)\n",
    "\n",
    "This should also essentially \"clip\" the downholeData to the study area, since only study area wells remain in headerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2998078 records removed without location information.\n",
      "56331 wells remain from 7188 located wells in study area.\n"
     ]
    }
   ],
   "source": [
    "downholeData = w4h.removeNonlocatedData(downholeData, headerData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove headerData rows without surface elevation information (this currently clips data from outside Illinois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API_NUMBER</th>\n",
       "      <th>TOTAL_DEPTH</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>TWP</th>\n",
       "      <th>TDIR</th>\n",
       "      <th>RNG</th>\n",
       "      <th>RDIR</th>\n",
       "      <th>MERIDIAN</th>\n",
       "      <th>QUARTERS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>ELEVREF</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>ELEVSOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13626212</td>\n",
       "      <td>201.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NE NW NW</td>\n",
       "      <td>591.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.733337</td>\n",
       "      <td>-89.933357</td>\n",
       "      <td>580.419373</td>\n",
       "      <td>POINT (-89.93336 38.73334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930917112</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>537.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.930069</td>\n",
       "      <td>-90.030655</td>\n",
       "      <td>529.981140</td>\n",
       "      <td>POINT (-90.03065 38.93007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930921712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>532.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.941998</td>\n",
       "      <td>-90.045364</td>\n",
       "      <td>530.172913</td>\n",
       "      <td>POINT (-90.04536 38.94200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930921812</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N2 SW NW</td>\n",
       "      <td>526.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.918377</td>\n",
       "      <td>-90.038200</td>\n",
       "      <td>520.954590</td>\n",
       "      <td>POINT (-90.03820 38.91838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930921912</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>507.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>119.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.870552</td>\n",
       "      <td>-89.955078</td>\n",
       "      <td>507.976868</td>\n",
       "      <td>POINT (-89.95508 38.87055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>1374073512</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.520279</td>\n",
       "      <td>-90.058060</td>\n",
       "      <td>555.110840</td>\n",
       "      <td>POINT (-90.05806 38.52028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>1374073812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SW NE SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.575832</td>\n",
       "      <td>-90.105003</td>\n",
       "      <td>409.501556</td>\n",
       "      <td>POINT (-90.10500 38.57583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1374073912</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>413.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.528660</td>\n",
       "      <td>-90.244118</td>\n",
       "      <td>410.597595</td>\n",
       "      <td>POINT (-90.24412 38.52866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>1374794512</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>427.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>38.640568</td>\n",
       "      <td>-90.051552</td>\n",
       "      <td>431.323914</td>\n",
       "      <td>POINT (-90.05155 38.64057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1378559712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>562.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Interpolated by C. Abert from the 30 meter DEM</td>\n",
       "      <td>38.635914</td>\n",
       "      <td>-89.938217</td>\n",
       "      <td>565.456055</td>\n",
       "      <td>POINT (-89.93822 38.63591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      API_NUMBER  TOTAL_DEPTH  SECTION  TWP TDIR   RNG RDIR  MERIDIAN  \\\n",
       "0       13626212        201.0     15.0  2.0    N   5.0    W       3.0   \n",
       "1      930917112         73.0     31.0  6.0    N   8.0    W       3.0   \n",
       "2      930921712         75.0     25.0  6.0    N   9.0    W       3.0   \n",
       "3      930921812        295.0      6.0  5.0    N   8.0    W       3.0   \n",
       "4      930921912       2195.0     23.0  5.0    N   8.0    W       3.0   \n",
       "...          ...          ...      ...  ...  ...   ...  ...       ...   \n",
       "8145  1374073512         52.0     23.0  1.0    N   9.0    W       3.0   \n",
       "8146  1374073812         70.0     33.0  2.0    N   9.0    W       3.0   \n",
       "8147  1374073912         31.0     19.0  1.0    N  10.0    W       3.0   \n",
       "8148  1374794512         61.0     12.0  2.0    N   9.0    W       3.0   \n",
       "8149  1378559712          NaN     12.0  2.0    N   8.0    W       3.0   \n",
       "\n",
       "      QUARTERS  ELEVATION ELEVREF  COUNTY_CODE  \\\n",
       "0     NE NW NW      591.0     nan         27.0   \n",
       "1          nan      537.0      GL        119.0   \n",
       "2           SE      532.0      GL        119.0   \n",
       "3     N2 SW NW      526.0      GL        119.0   \n",
       "4           SE      507.0      GL        119.0   \n",
       "...        ...        ...     ...          ...   \n",
       "8145       nan        NaN     nan        163.0   \n",
       "8146  SW NE SW        NaN     nan        163.0   \n",
       "8147       nan      413.0      DM        163.0   \n",
       "8148        NW      427.0      GL        163.0   \n",
       "8149       nan      562.0      DM        163.0   \n",
       "\n",
       "                                          ELEVSOURCE   LATITUDE  LONGITUDE  \\\n",
       "0                                                nan  38.733337 -89.933357   \n",
       "1                                                nan  38.930069 -90.030655   \n",
       "2                                                nan  38.941998 -90.045364   \n",
       "3                                                nan  38.918377 -90.038200   \n",
       "4                                                nan  38.870552 -89.955078   \n",
       "...                                              ...        ...        ...   \n",
       "8145                                             nan  38.520279 -90.058060   \n",
       "8146                                             nan  38.575832 -90.105003   \n",
       "8147                                             nan  38.528660 -90.244118   \n",
       "8148                                             nan  38.640568 -90.051552   \n",
       "8149  Interpolated by C. Abert from the 30 meter DEM  38.635914 -89.938217   \n",
       "\n",
       "         ELEV_FT                    geometry  \n",
       "0     580.419373  POINT (-89.93336 38.73334)  \n",
       "1     529.981140  POINT (-90.03065 38.93007)  \n",
       "2     530.172913  POINT (-90.04536 38.94200)  \n",
       "3     520.954590  POINT (-90.03820 38.91838)  \n",
       "4     507.976868  POINT (-89.95508 38.87055)  \n",
       "...          ...                         ...  \n",
       "8145  555.110840  POINT (-90.05806 38.52028)  \n",
       "8146  409.501556  POINT (-90.10500 38.57583)  \n",
       "8147  410.597595  POINT (-90.24412 38.52866)  \n",
       "8148  431.323914  POINT (-90.05155 38.64057)  \n",
       "8149  565.456055  POINT (-89.93822 38.63591)  \n",
       "\n",
       "[8150 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerData = headerDataClip.copy()\n",
    "headerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well records removed: 0\n",
      "Number of rows before dropping those without surface elevation information: 8150\n",
      "Number of rows after dropping those without surface elevation information: 8150\n"
     ]
    }
   ],
   "source": [
    "headerData_cleaned = w4h.removenotopo(df=headerData, printouts=True)\n",
    "headerData = headerData_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows from downholeData with no depth information and where depth information is obviously bad (i.e., top depth > bottom depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without record depth information: 56331\n",
      "Number of rows after dropping those without record depth information: 55747\n",
      "Number of well records without formation information deleted: 584\n",
      "Number of rows before dropping those with obviously bad depth information: 56331\n",
      "Number of rows after dropping those with obviously bad depth information: 55725\n",
      "Well records deleted: 606\n"
     ]
    }
   ],
   "source": [
    "#Drop records with no depth information\n",
    "donwholeData = w4h.dropnodepth(downholeData, printouts=True)\n",
    "#Drop records with bad depth information (i.e., top depth > bottom depth) (Also calculates thickness of each record)\n",
    "donwholeData = w4h.dropbaddepth(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records with no FORMATION information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping those without FORMATION information: 56331\n",
      "Number of rows after dropping those without FORMATION information: 56331\n",
      "Well records deleted: 0\n"
     ]
    }
   ],
   "source": [
    "downholeData = w4h.dropnoformation(downholeData, printouts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to export this data, to have record of cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData.reset_index(inplace=True,drop=True)\n",
    "headerData.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#downholeData.to_csv(str(repoDir)+'/out/downholeData_cleaned'+dateSuffix+'.csv',index_label='ID')\n",
    "#headerData.to_csv(str(repoDir)+'/out/headerData_cleaned'+dateSuffix+'.csv',index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outData = pd.merge(left = downholeData, right = headerData, on='API_NUMBER')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following flags are used to mark the classification method:\n",
    "- 0: Not classified\n",
    "- 1: Specific Search Term Match\n",
    "- 2: Wildcard match (startTerm) - no context\n",
    "- 3: Bedrock classification for obvious bedrock\n",
    "- 4: Wildcard match (startTerm) - with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent version of this file is : SearchTerms-Specific_2022-11-16_essCols.csv\n",
      "Most Recent version of this file is : SearchTerms-Start.csv\n"
     ]
    }
   ],
   "source": [
    "#Read in dictionary files for downhole data\n",
    "specTermsPATH, startTermsPATH = w4h.searchTermFilePaths(dictdir=str(repoDir)+'/resources/', specStartPattern='*SearchTerms-Specific*', startGlobPattern = '*SearchTerms-Start*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:175: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  specTerms.iloc[:,i] = specTerms.iloc[:,i].astype(specTermsDtypes[specTerms.iloc[:,i].name])\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\read.py:176: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  startTerms.iloc[:,i] = startTerms.iloc[:,i].astype(startTermsDtypes[startTerms.iloc[:,i].name])\n"
     ]
    }
   ],
   "source": [
    "specTerms, startTerms = w4h.readSearchTerms(specfile=specTermsPATH, startfile=startTermsPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the dataframes--for the specific search terms, this is the same as classifying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Classified with full search term: 25280\n",
      "Records Classified with full search term: 44.88% of data\n"
     ]
    }
   ],
   "source": [
    "downholeData_spec = w4h.specificDefine(downholeData, specTerms, printouts=True)\n",
    "downholeData = downholeData_spec.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with only the records already classified (using the specific search terms in this case, classifiedDF), and one that still needs to be searched (searchDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31051"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifedDF, searchDF = w4h.splitDefined(downholeData)\n",
    "searchDF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do the classification routine on the searchDF database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Term process should be done by 11:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].where(~df['FORMATION'].str.startswith(s,na=False),4,inplace=True)\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['INTERPRETATION'].where(~df['FORMATION'].str.startswith(s,na=False),starterms.loc[i,'INTERPRETATION'],inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records classified with start search term: 3876\n",
      "Records classified with start search term: 12.48% of remaining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEDROCK_FLAG'] = df[\"INTERPRETATION\"] == 'BEDROCK'\n"
     ]
    }
   ],
   "source": [
    "searchDF = w4h.startDefine(df=searchDF, starterms=startTerms, printouts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge specDF and searchDF back together all back in single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData_Terms = w4h.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Terms.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export terms that still need to be defined to csv (along with their counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The outdir should be changed so it doesn't clog up the repository\n",
    "#classify.export_toBeDefined(df=downholeData, outdir=str(repoDir)+'/out/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify all  data under depth threshold (default is 550') as bedrock (should not be an issue, but just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    500\n",
      "Name: CLASS_FLAG, dtype: int64\n",
      "test\n",
      "Records classified as bedrock that were deeper than 550': 500\n",
      "This represents 1.84% of the unclassified data in this dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLASS_FLAG'].mask(df['TOP']>thresh, 3 ,inplace=True) #Add a Classification Flag of 3 (bedrock b/c it's deepter than 550') to all records where the top of the interval is >550'\n",
      "c:\\Users\\riley\\LocalData\\Github\\wells4hydrogeology\\w4h\\classify.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEDROCK_FLAG'].mask(df['TOP']>thresh, True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "classifedDF, searchDF = w4h.splitDefined(downholeData)\n",
    "searchDF = w4h.depthDefine(searchDF, thresh=550, printouts=True)\n",
    "downholeData_Class = w4h.remergeData(classifieddf=classifedDF, searchdf=searchDF)\n",
    "downholeData = downholeData_Class.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add '0' flag for data still not classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = w4h.fillUnclassified(downholeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    26675\n",
       "1.0    25280\n",
       "4.0     3876\n",
       "3.0      500\n",
       "Name: CLASS_FLAG, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['CLASS_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add \"Flag\" for target interpratations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictDir = \"\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\ISWS_HydroGeo\\\\WellDataAutoClassification\\\\SupportingDocs\\\\\"\n",
    "targetInterpDF = w4h.readLithologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = w4h.mergeLithologies(downholedata=downholeData, targinterps=targetInterpDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags used for target classification purposes:\n",
    "- -2: No classification \n",
    "- -1: Classified, not used/not definitive\n",
    "- 0: Classified, not target material\n",
    "- 1: Classified as target material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    25089\n",
       "1.0     4025\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all unique wells in downhole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique wells in downholeData: 7188\n"
     ]
    }
   ],
   "source": [
    "#Get Unique well APIs\n",
    "wellsDF = w4h.getUniqueWells(downholeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort dataset by API Number and Depth of top of record (will be easier to do data analysis with records in the correct order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make this into a function?\n",
    "downholeData_sorted = downholeData.sort_values(['API_NUMBER','TOP'])\n",
    "downholeData_sorted.reset_index(inplace=True, drop=True)\n",
    "downholeData_sorted = downholeData_sorted[pd.notna(downholeData_sorted[\"INTERPRETATION\"])]\n",
    "donwholeData.reset_index(inplace=True, drop=True)\n",
    "donwholeData = downholeData_sorted.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bedrock Depth and Layer Thickness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot just to see them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject and align raster grids for surface elevation and bedrock topo (reproject well data too if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inGrids = [bedrockElevGridIN, surfaceElevGridIN]\n",
    "bedrockGrid, surfaceGrid = w4h.alignRasters(unalignedGrids=inGrids, modelgrid=modelGrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(ncols = 2, nrows=1)\n",
    "bedrockGrid.plot(ax=ax[0])\n",
    "surfaceGrid.plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the surface elevation raster and bedrock elevation raster to get depth to bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driftThickGrid, layerThickGrid = w4h.get_drift_thick(surface=surfaceGrid, bedrock=bedrockGrid, noLayers=9, plotData=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sample each well point (headerData) to get layer thickness, surface elevation, and bedrock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEDROCK_ELEV_FT sampling should be done by 11:43\n",
      "SURFACE_ELEV_FT sampling should be done by 11:43\n",
      "BEDROCK_DEPTH_FT sampling should be done by 11:43\n",
      "LAYER_THICK_FT sampling should be done by 11:43\n"
     ]
    }
   ],
   "source": [
    "headerData = w4h.sample_raster_points(raster=bedrockGrid, ptDF=headerData, newColName='BEDROCK_ELEV_FT')\n",
    "#headerData['BEDROCK_ELEV_M'] = headerData['BEDROCK_ELEV_FT']* 0.3048\n",
    "\n",
    "headerData = w4h.sample_raster_points(raster=surfaceGrid, ptDF=headerData, newColName='SURFACE_ELEV_FT')\n",
    "#headerData['SURFACE_ELEV_M'] = headerData['SURFACE_ELEV_FT']* 0.3048\n",
    "\n",
    "headerData = w4h.sample_raster_points(raster=driftThickGrid, ptDF=headerData, newColName='BEDROCK_DEPTH_FT')\n",
    "#headerData['BEDROCK_DEPTH_M'] = headerData['BEDROCK_DEPTH_FT']* 0.3048\n",
    "\n",
    "headerData = w4h.sample_raster_points(raster=layerThickGrid, ptDF=headerData, newColName='LAYER_THICK_FT')\n",
    "#headerData['LAYER_THICK_M'] = headerData['LAYER_THICK_FT']* 0.3048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate  all layer depths/elevations at all wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerData = w4h.get_layer_depths(well_metadata=headerData, no_layers=9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Data from downhole and headerData to enable further calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = downholeData_sorted.copy()\n",
    "headerJoinCols = ['API_NUMBER', 'LATITUDE', 'LONGITUDE', 'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'ELEV_FT', 'BEDROCK_ELEV_FT', 'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT', 'LAYER_THICK_FT', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2', 'DEPTH_FT_LAYER3','DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5', 'DEPTH_FT_LAYER6','DEPTH_FT_LAYER7','DEPTH_FT_LAYER8','DEPTH_FT_LAYER9','geometry']\n",
    "downholeData_layerInfo = w4h.mergeTables(leftTable=downholeData, rightTable=headerData, rightCols=headerJoinCols, onCol='API_NUMBER', how='inner')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the top and bottom elevation for each well record in downholeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downholeData = downholeData_layerInfo.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate target thickness in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['API_NUMBER', 'TABLE_NAME', 'FORMATION', 'THICKNESS', 'TOP', 'BOTTOM',\n",
       "       'INTERPRETATION', 'CLASS_FLAG', 'BEDROCK_FLAG', 'TARGET', 'LATITUDE',\n",
       "       'LONGITUDE', 'LONGITUDE_PROJ', 'LATITUDE_PROJ', 'ELEV_FT',\n",
       "       'BEDROCK_ELEV_FT', 'SURFACE_ELEV_FT', 'BEDROCK_DEPTH_FT',\n",
       "       'LAYER_THICK_FT', 'DEPTH_FT_LAYER1', 'DEPTH_FT_LAYER2',\n",
       "       'DEPTH_FT_LAYER3', 'DEPTH_FT_LAYER4', 'DEPTH_FT_LAYER5',\n",
       "       'DEPTH_FT_LAYER6', 'DEPTH_FT_LAYER7', 'DEPTH_FT_LAYER8',\n",
       "       'DEPTH_FT_LAYER9', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downholeData_layerInfo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "layer_target_thick() got an unexpected keyword argument 'export_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resdf \u001b[39m=\u001b[39m w4h\u001b[39m.\u001b[39;49mlayer_target_thick(downholeData_layerInfo, layers\u001b[39m=\u001b[39;49m\u001b[39m9\u001b[39;49m, export_dir\u001b[39m=\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mriley\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mLocalData\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mTemp\u001b[39;49m\u001b[39m'\u001b[39;49m, outfile_prefix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCoarseFine\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: layer_target_thick() got an unexpected keyword argument 'export_dir'"
     ]
    }
   ],
   "source": [
    "resdf = w4h.layer_target_thick(downholeData_layerInfo, layers=9, export_dir=r'C:\\Users\\riley\\LocalData\\Temp', outfile_prefix='CoarseFine')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work here next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate thickness values in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each layer and interpolate (use same parameters (?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dataset = w4h.layer_interp(points, grid, kind, layers, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure rasters align (are co-registered) with grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data \n",
    "downhole_bedrockDepth_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\Downhole_BedrockPicks.csv',index_label=\"ID\")\n",
    "wPermits_XYZ.to_csv('\\\\\\\\isgs-sinkhole\\\\geophysics\\\\Balikian\\\\BedrockWellData\\\\Wells\\\\ProcessedWellData\\\\wPermits_BedrockPicks.csv',index_label=\"ID\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raster38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "eacfbd7833b09ac8bfcf3597a4f98d1ccaa412ac01c00d3f955e77aac9f1d08d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
